
\chapter{Diamond, andthen, dagger}\label{chapter2}

\begin{parsec}{1730}%
\begin{point}{10}%
In the previous chapter and in \cite{bram}
    we have studied categorical properties of von Neumann algebras.
In this chapter we change pace:
    we study categories that resemble the
    category of von Neumann algebras.
The goal of this line of study is to identify
    axioms which uniquely pick out the category of von Neumann algebras.
We do not reach this ambitious goal ---
    instead we will build up to a characterization of
    the existence of a unique $\dagger$-structure
    on the pure maps of a von Neumann algebras-like category.
\end{point}
\begin{point}{20}%
As a basic axiom we will require the categories we consider to be
    effectuses (which will be defined in \sref{dfn-effectus}).
For us the definition of an effectus will play a similar role
    to that of a topological space for a geometer.
In many applications,
    general topological spaces on their own are of little interest:
    the axioms are so weak that there are
    many (for the application) pathological examples.
    These weak axioms, however, are very expressive in the sense
    that they allow for the definition of many useful notions.
    Herein lies the strength of topological spaces ---
    as a stepping stone:
    many important classes of mathematical spaces
    are just plain topological spaces with a few additional axioms.
Similarly, there will be many pathological effectuses.
Their use for us lies in their expressiveness.
\end{point}
\begin{point}{30}%
Before we dive into effectuses,
    we need to learn about effect algebras (and related structures),
    which were introduced by mathematical physicists as
    a generalization of Boolean algebra to study fuzzy predicates
    in quantum mechanics.
For us, effectuses are the
    categorical counterpart of effect algebras.\footnote{Effect
    algebroids~\cite{roumen,roumen2016cohomology} are a different
    categorification with applications in cohomology.}
After this, we continue with a brief, but thorough development
    of the basic theory of effectuses.
There is a lot more to say about effectuses
    (see \cite{effintro}), which has been omitted
    to avoid straining the reader.
    We will indulge, however,
    in one tangent,
    which can be skipped:
    the study of abstract convex sets in
    \S\ref{more-aconvm}.
For the moment, think of an effectus as a generalization
    of the opposite category of von Neumann algebras:
    the objects represent the physical systems
    (or data types, if you like)
    and the maps represent the physical processes
    (or properly typed programs).
\end{point}
\begin{point}{40}%
The first two axioms we add on top of those of an effectus
    are the existence of quotients and comprehension.
It's helpful to discuss the origin of these axioms.
It started with the desire to axiomatize categorically
    the sequential product on a von Neumann algebra~$\scrA$,
    that is the operation~$\andthen{a}{b} \equiv  \sqrt{a} b \sqrt{a}$,
    which represents sequential measurement
    of first~$a$ \emph{andthen} $b$.
The sequential product is a quantum mechanical generalization
    of classical conjunction (logical `and').
In  contrast to the tame~$\wedge$ in a Boolean algebras,
    the sequential product does not obey a lot of insightful
    formulas.
The sequential product as a binary operation
        has received quite some attention \cite{gudder2008characterization,gheondea2004sequential,gudder2001sequential,li2011sequential,gudder2005open,shen2009not,gudder2005uniqueness,jun2009remarks,weihua2009uniqueness,tkadlec2008atomic,jia2010entropy,arias2004almost}.
We approach the sequential product in a rather different way:
    we take a step back and
    consider the map~$\asrt_a(b) \equiv  \andthen{a}{b}$
        for fixed~$a$.  ($\asrt_a$ is named after the \texttt{assert} statement
                    used in many programming languages,
                    see~\sref{asrt-remarks}.)
    This map~$\asrt_a$ factors in two:
\begin{equation*}
    \xymatrix@C+2pc@R-2pc{
        \scrA \ar[r]^\pi & \ceil{a} \scrA \ceil{a} \ar[r]^\xi
        & \scrA \\
        b \ar@{|->}[r] & \ceil{a}b\ceil{a}
            \ar@{|->}[r] & \sqrt{a}b\sqrt{a}.
    }
\end{equation*}
It turned out that both~$\pi$ and~$\xi$ have
    nice and dual (in a sense) defining universal properties
    which can be expressed in an effectus:
    $\pi$ is a comprehension and~$\xi$ is a quotient.\footnote{%
            Beware: an effectus quotient is not the same thing
        as a von Neumann-algebra quotient.}
\end{point}
\begin{point}{50}%
The existence of quotients and comprehension in some effectus~$C$
    is interesting on its own, but with
    two additional axioms (the existence of images and
    preservation of images under orthocomplementation),
    we get a surprisingly firm handle
    on the \emph{possibilistic} side of~$C$,
    by means of the existence
    of a certain functor~$(\ )_\diamond\colon C \to \mathsf{OMLat}$
        to the category of orthomodular lattices.
In the guiding example of von Neumann algebras,
    we have~$f_\diamond = g_\diamond$
        if and only
    there are no post-measurement~$a$ and initial state~$\omega$
    that can determine with certainty
    whether~$f$ or~$g$ has been performed.\footnote{%
    In symbols: $
    f_\diamond = g_\diamond \iff 
\bigl(\forall a,\omega.\  \omega(f(a))  =  0 \ \Leftrightarrow\ \omega(g(a))  =  0\bigr).$}
With this functor we can introduce several
    possibilistic notions of which~$\diamond$-adjoint
    and~$\diamond$-positive are the most important.
Because of the central role of~$\diamond$,
    we call an effectus with these axioms 
    a~$\diamond$-effectus.
\end{point}
\begin{point}{60}%
The axioms of a~$\diamond$-effectus do not force
    any coherence between the quotients and comprehension.
This has been a roadblock to the axiomatization
    of the sequential product for quite a while.
The key insight was the following:
    the map~$\asrt_a$ (i.e.~$b\mapsto \andthen{a}{b}$)
    is the unique~$\diamond$-positive map on~$\scrA$
    with~$\asrt_a(1) = a$.
We turn this theorem into an axiom:
    an~$\&$-effectus is
    a~$\diamond$-effectus
    where there are such unique~$\diamond$-positive maps~$\asrt_a$
    and where an additional polar decomposition axiom holds.
In an~$\&$-effectus, the predicates on an object carry a canonical
    binary operation~$\&$
    which is the intended sequential product in
    the case of von Neumann algebras.
\end{point}
\begin{point}{70}[pure-effectus]%
In an effectus, we call a map pure if it can be written
    as the composition of quotients and comprehensions.
In~\sref{paschke-pure} we saw that in the case of von Neumann algebras,
    a map is pure (in this sense) if and only if the corresponding Paschke
    embedding is surjective.
In particular, the pure maps~$\scrB(\scrH) \to \scrB(\scrK)$
    are exactly of the form~$\ad_v$
        (for bounded operators~$v\colon \scrK \to \scrH$)
    which carry a~$\dagger$-structure,
    namely~$(\ad_v)^\dagger = \ad_{v^*}$.
This begs the question: can we define a~$\dagger$ on all pure maps
    in an~$\&$-effectus?
The main result of this chapter
    is Theorem~\sref{dagger-theorem},
    which gives  necessary and sufficient conditions
    for an~$\&$-effectus
    to have a well-behaved~$\dagger$-structure on its pure maps.
After this apogee,
    we tie up some lose ends
    and discuss how these
    structures compare to those already known in the literature.
\end{point}
\end{parsec}
\section{Effect algebras and related structures}
\begin{parsec}{1740}%
\begin{point}{10}%
Before we turn to effectuses,
    it is convenient to introduce some lesser-known algebraic structures
    of which the effect algebra is the most important.
It will turn out that the set of predicates associated to an object in
    an effectus can be arranged into an effect algebra.
In this way, effect algebras play the same role
    for effectuses as Heyting algebras for toposes.
    First, we will recall the definition of partial commutative monoid (PCM)
    --- as later in \sref{cho-thm} 
    we will see that the partial maps between
    two objects in an effectus can be arranged into a PCM.
\end{point}
\begin{point}{20}[dfn-pcm]{Definition}%
    A \Define{partial commutative monoid} (\Define{PCM})~$M$
        \index{PCM}
        is a set~$M$ together with distinguished element~$0 \in M$
        and a partial binary operation~$\ovee$ such that
        for all~$a,b,c \in M$ 
        --- writing~$a \perp b$ whenever~$a \ovee b$ is defined
        --- we have
\begin{enumerate}
    \item \emph{(partial commutativity)}
        if $a \perp b$, then~$b \perp a$ and~$a \ovee b = b \ovee a$;
    \item \emph{(partial associativity)}
        if $a \perp b$ and~$a \ovee b \perp c$,
        then~$b \perp c$, ~$a \perp b \ovee c$
            and~$(a \ovee b) \ovee c = a \ovee (b \ovee c)$ \emph{and}
    \item \emph{(zero)}
        $0 \perp a$ and~$0 \ovee a = a$.
\end{enumerate}
A map~$f\colon M \to N$
    between PCMs~$M$ and~$N$
    is called an \Define{PCM homomorphism}
    \index{PCM!homomorphism}
    if for all~$a, b \in E$
    with~$a \perp b$,
    we have~$f(a) \perp f(b)$
    and~$f(a) \ovee f(b) = f(a \ovee b)$.
Write~$\Define{\textsf{PCM}}$ for the category
    \index{\textsf{PCM}}
    of PCMs with these homomorphisms. (Cf.~\cite{corefl,Wehrung2017})

For~$a,b$ in a PCM~$M$,
    we say~$\Define{a \leq b}$
    \index{*leq@$\leq$!in PCM/EA}
    iff~$a \ovee c = b$ for some~$c \in M$.
\end{point}
\begin{point}{30}[pcm-preorder]{Exercise}%
Show a PCM is preordered by~$\leq$.
\end{point}
\begin{point}{40}%
The partial commutativity and associativity of a PCM
    ensure that a sum only depends on which elements
    occur (and how often), instead of their order.
Formally:
    if~$(\cdots( x_1 \ovee x_2) \ovee \cdots) \ovee x_n$
    exists some~$x_1, \ldots, x_n$ in some PCM, then so
    does~$(\cdots( x_{\pi(1)} \ovee x_{\pi(2)}) \ovee \cdots) \ovee x_{\pi(n)}$
    for any permutation~$\pi$ of~$\{1,\ldots,n\}$ and
\begin{equation*}
    (\cdots( x_1 \ovee x_2) \ovee \cdots) \ovee x_n
    \ = \ (\cdots( x_{\pi(1)} \ovee x_{\pi(2)}) \ovee \cdots) \ovee x_{\pi(n)}.
\end{equation*}
    Thus parantheses are superfluous and we will often leave them out:
    \begin{equation*}
        \bigovee^n_{i=1} x_i \ \equiv \ \Define{x_1 \ovee \cdots \ovee x_n}
        \ \equiv\ 
    (\cdots( x_1 \ovee x_2) \ovee \cdots) \ovee x_n.
    \end{equation*}
\end{point}
\spacingfix{}
\end{parsec}

\begin{parsec}{1750}%
\begin{point}{10}[dfn-ea]{Definition}%
A PCM~$E$ together with distinguished element~$1 \in E$
    is called an \Define{effect algebra} (\Define{EA}) \cite{ea}
    \index{EA}
    \index{effect algebra}
    provided that
\begin{enumerate}
\item
    \emph{(orthocomplement)}
    for every~$a$
    there is a unique~$\Define{a^\perp}$
        \index{orthocomplement!in an effect algebra}
        \index{*perp@$(\ )^\perp$!element effect algebra}
   with~$a \ovee a^\perp = 1$ \emph{and}
\item
    \emph{(zero--one)}
    if~$a \perp 1$, then~$a = 0$.
\end{enumerate}
A map~$f\colon E \to F$
between effect algebras~$E$ and~$F$
is called an \Define{effect algebra homomorphism}
    \index{effect algebra!homomorphism}
if it is a PCM homomorphism that preserves~$1$;
    concretely:
\begin{enumerate}
    \item \emph{(additive)}
    $a \perp b$ implies $f(a) \perp f(b)$ and~$f(a)\ovee f(b) = f(a\ovee b)$
        \emph{and}
    \item \emph{(unital)}
    $f(1) = 1$.
\end{enumerate}
(It follows that~$f(0)=0$ and~$f(a^\perp) = f(a)^\perp$. See~\sref{exc-eamorphism}.)
Write~$\Define{\textsf{EA}}$
    \index{\textsf{EA}}
    for the category
    of effect algebras with these homomorphisms.
A subset~$D \subseteq E$ is a \Define{sub-effect algebra}
    \index{effect algebra!sub-} of~$E$
    if~$0,1 \in D$ and for any~$a,b \in D$
    with~$a\perp b$, we have~$a \ovee b \in D$
    and~$a^\perp \in D$.
\end{point}
\begin{point}{20}[eaexamples]{Examples}%
There are many examples of effect algebras
    --- we only give a few.
\begin{enumerate}
\item
The unit interval
$[0,1]$ with partial addition is an effect algebra ---
i.e.:~$x \perp y$
        whenever~$x +y \leq 1$ and then $x \ovee y = x + y$,
        $x^\perp = 1-x$.
\item
Generalizing the previous:
if~$G$ is an ordered group
with distinguished element~$1$,
then the order interval~$[0,1]_G \equiv \{x;\ x\in G;\ 0 \leq x\leq 1\}$
is an effect algebra
with~$x \perp y$ whenever~$x +y \leq 1$;
$x \ovee y = x + y$ and~$x^\perp = 1-x$.
\item
In particular,
    if~$\scrA$ is any von Neumann algebra,
    then the set of \Define{effects}~$[0,1]_\scrA$
        \index{effects}
        \index{*01@$[0,1]_\scrA$}
    forms an effect algebra
    with~$a \perp b$ whenever~$a +b \leq 1$;
    $a \ovee b = a + b$ and~$a^\perp = 1-a$.
The `effect' in effect algebra originates from this example.
\item
Any orthomodular lattice~$L$ (defined in \sref{dfn-orthomodular-lattice})
    is an effect algebra
    with the same orthocomplement,
    $x \perp y$ whenever~$x \leq y^\perp$
    and~$x \ovee y = x \vee y$.  (See e.g.~\cite[prop.~27]{basmsc}.)
\item
In particular,
    any Boolean algebra~$L$
    is an effect algebra
    with complement as orthocomplement,
    ~$x \perp y$ whenever~$x \wedge y = 0$ and
    $x \ovee y = x \vee y $.
\item
The one-element Boolean algebra~$1 \equiv \{0=1\}$
    is the final object in \textsf{EA}
    and the two-element Boolean algebra~$2 \equiv \{0,1\}$
    is the initial object in \textsf{EA}.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{30}[ea-product]{Exercise}%
Let~$E$ and~$F$ be effect algebras.
First show that the cartesian product~$E \times F$
    is an effect algebra with componentwise operations.
Show that this is in fact the categorical product of~$E$ and~$F$
    in \textsf{EA}.
(The category \textsf{EA} is in fact complete and cocomplete;
    for this and more categorical properties,
        see \cite{corefl}.)
\end{point}
\begin{point}{40}[ea-redund]{Exercise}%
There is a small redundancy in our definition of effect algebra:
show that the zero axiom ($x \ovee 0 = x$)
follows from the remaining axioms (partial commutativity,
partial associativity, orthocomplement and zero--one.)
\end{point}
\begin{point}{50}[eabasics]{Proposition}%
In any effect algebra~$E$ with~$a,b,c\in E$, we have
\begin{enumerate}
    \item \emph{(involution)}
        $a^{\perp\perp} = a$;
    \item
        $1^\perp= 0$ and~$0^\perp = 1$;
    \item \emph{(positivity)}
        if~$a\ovee b = 0$, then~$a = b= 0$;
    \item \emph{(cancellation)}
        if~$a\ovee c = b\ovee c$, then~$a = b$;
    \item the relation  $\leq$ (from \sref{dfn-pcm}) partially orders~$E$;
    \item $a \leq b$ if and only if $b^\perp \leq a^\perp$;
    \item if~$a \leq b$ and~$b \perp c$, then~$a \perp c$
        and~$a \ovee c \leq b \ovee c$ \emph{and}
    \item $a \perp b$ if and only if~$a \leq b^\perp$.
\end{enumerate}
\spacingfix{}
\begin{point}{60}{Proof}%
(These proofs are well-known,
    see for instance~\cite{dvurecenskij2013new}.)
By partial commutativity and definition
of orthocomplement both~$a^\perp \ovee a = 1$
and~$a^\perp \ovee  a^{\perp\perp} = 1$.
So by uniqueness of orthocomplement,
    we must have~$a= a^{\perp\perp}$, which is point 1.
Clearly~$0 \ovee 1 = 1$,
    so~$1^\perp = 0$ and~$0^\perp = 1$,
    which is point 2.
For point 3, assume~$a \ovee b = 0$.
Then~$a \ovee b \perp 1$
    and so by partial associativity~$b \perp 1$.
    By zero--one, we get~$b = 0$.
    Similarly~$a=0$, which shows point 3.
For point 4, assume~$ a \ovee c = b \ovee c$.
From partial associativity and commutativity, we get
$ ((a \ovee b)^\perp\ovee a) \ovee c = 
    ((a \ovee b)^\perp\ovee a) \ovee b  =  1$
and so by uniqueness of
orthocomplement~$c = ((a\ovee b)^\perp\ovee a)^\perp = b$,
    which is point~4.
By \sref{pcm-preorder},
    we only need to show that~$\leq$ is antisymmetric
    for point~5.
So assume~$a \leq b$ and~$b \leq a$
    for some~$a,b\in E$.
Pick~$c,d \in E$ with~$a \ovee c = b$ and~$b \ovee d = a$.
Then~$a = (a \ovee c) \ovee d = a \ovee (c \ovee d)$.
By cancellation~$c \ovee d = 0$.
So by positivity~$c = d= 0$.
Hence~$a = b$.
For point 6, assume~$a\leq b$.
Pick~$c \in E$ with~$a \ovee c = b$.
Clearly~$a \ovee a^\perp = 1 = b \ovee b^\perp = a \ovee c \ovee b^\perp$,
so by cancellation~$a^\perp = c \ovee b^\perp$,
    which is to say~$b^\perp \leq a^\perp$.
For point 7, assume~$a \leq b$ and~$b \perp c$.
Pick~$d$ with~$a \ovee d = b$.
By partial associativity and commutativity
    we have~$b \ovee c = (a \ovee d) \ovee c = (a \ovee c) \ovee d$,
    so~$a \perp c$ and~$a \ovee c \leq b \ovee c$.
For point 8, first assume~$a \perp b$.
Then~$a \ovee b \ovee (a \ovee b)^\perp = 1 = b \ovee b^\perp$.
So by cancellation~$b^\perp = a \ovee (a \ovee b)^\perp$,
hence~$a \leq b^\perp$.
For the converse, assume~$a \leq b^\perp$.
Then~$a \ovee c = b^\perp$ for some~$c$.
Hence~$a \ovee c \perp b$
    and so  by partial associativity and commutativity,
        we get~$a \perp b$, as desired.
    \qed
\end{point}
\end{point}
\end{parsec}%

\begin{parsec}{1760}%
\begin{point}{10}{Definition}%
Suppose~$E$ is an effect algebra.
Write~$\Define{b \ominus a}$
        \index{*ominus@$\ominus$}
for the (by cancellation) unique element (if it exists)
with~$a \ovee (b \ominus a) = b$.
\end{point}
\begin{point}{20}[exc-dposet]{Exercise*}%
Show that for any effect algebra~$E$, we have
\begin{enumerate}
    \item[(D1)]~$a \ominus b$ is defined if and only if~$b \leq a$;
    \item[(D2)]~$a \ominus b \leq a$ (if defined);
    \item[(D3)]~$a \ominus (a \ominus b) = b$ (if defined) \emph{and}
    \item[(D4)]~if $a \leq b \leq c $,
                then~$c \ominus b \leq c \ominus a$
                and~$(c \ominus a) \ominus (c \ominus b) = b \ominus a$.
\end{enumerate}
\spacingfix{}
\begin{point}{30}%
Let~$E$ be a poset with maximum element~$1$
    and partial binary operation~$\ominus$
    satisfying~(D1)--(D4).
Define~$a \ovee b = c \Leftrightarrow c \ominus b = a$
    and~$a^\perp = 1 \ominus a$.
Show that this turns~$E$ into an effect algebra
    with compatible order and~$\ominus$.
\end{point}
\begin{point}{40}{Remark}%
    Such a structure~$(E,\ominus,1)$ is called a \Define{difference-poset}
    \index{D-poset}
    (\Define{D-poset}) \cite{kopka1994d} and is, as we have just seen,
    an alternative way to axiomatize effect algebras.
\end{point}
\end{point}

\begin{point}{50}[exc-eamorphism]{Exercise}%
Show that for an effect algebra homomorphism~$f\colon E \to F$,
    we have
    \begin{enumerate}
        \item~\emph{(preserves zero)} $f(0) = 0$;
        \item~\emph{(order preserving)} if $a \leq b$, then~$f(a) \leq f(b)$;
        \item~if~$a\ominus b$ is defined,
            then $f(a \ominus b) = f(a) \ominus f(b)$ \emph{and}
        \item consequently~$f(a^\perp) = f(a)^\perp$.
    \end{enumerate}
\spacingfix{}
\end{point}
\end{parsec}

\begin{parsec}{1770}%
\begin{point}{10}%
For real numbers we have~$a + b = \min \{a,b\} + \max \{a, b\}$.
The following is a generalization to effect algebras.
\end{point}
\begin{point}{11}[ea-modularity-prop]{Proposition}%
Suppose~$E$ is an effect algebra.
If the infimum~$a \wedge b$
    exists for some~$a,b \in E$ with~$a \perp b$,
    then their supremum~$a \vee b$ exists as well and
\begin{equation*}
    a \ovee b \ = \ (a \wedge b) \,\ovee\, (a \vee b).
\end{equation*}
\spacingfix{}
\begin{point}{20}[modularity-lemma-proof]{Proof}%
(This result appeared in my master's thesis~\cite[prop.~15]{basmsc}.
    It turns out that it was already proven before
        (in D-poset form) \cite[prop.~1.8.2]{dvurecenskij2013new}.)
The result follows from this lemma:
    if~$(x \ominus c) \wedge (x \ominus d)$ exists,
    then~$c \vee d$ exists as well
    and~$(x \ominus c) \wedge (x \ominus d)
        = x \ominus (c \vee d)$.
Indeed:
\begin{equation*}
    a \wedge b \ = \ 
        ((a \ovee b) \ominus a) \wedge ((a \ovee b) \ominus b) \ = \ 
        (a \ovee b) \ominus (a \vee b)
\end{equation*}
    and so~$(a \wedge b) \ovee (a \vee b) = a \ovee b$, as desired.
\begin{point}{30}%
Now, we prove the lemma.
Assume~$(x \ominus c) \wedge (x \ominus d)$ exists.
Note~$x \ominus c = (x^\perp \ovee c)^\perp$.
As~$z \mapsto z^\perp$ is an order anti-isomorphism,
    we see~$(x^\perp \ovee c) \vee (x^\perp \ovee d)$
        exists and~$(x^\perp \ovee c) \vee (x^\perp \ovee d)
                                    = ((x \ominus c)\wedge (x \ominus d))^\perp$.
Clearly~$ (x^\perp \ovee c) \vee
        (x^\perp \ovee d) \geq x^\perp$.
    Write~$r := ((x^\perp \ovee c) \vee
        (x^\perp \ovee d)) \ominus x^\perp$.
We will show~$r = c \vee d$.
It is easy to see~$r \geq c$ and~$r \geq d$.
Assume~$s$ is any element with~$s \geq c$ and~$s \geq d$.
Note~$x^\perp \ovee s \geq x^\perp \ovee c$
and~$x^\perp \ovee s \geq x^\perp \ovee d$,
    hence~$x^\perp \ovee s \geq (x^\perp \ovee c) \vee (x^\perp \ovee d)$
    and so~$ s \geq  r$.
We have shown~$r = c \vee d$.
Consequently~$ (x \ominus c)\wedge (x \ominus d)
        = ((x^\perp \ovee c) \vee (x^\perp \ovee d))^\perp
        = (r \ovee x^\perp)^\perp = 
            x \ominus (c \vee d) $, as promised. \qed
\end{point}    
\end{point}
\end{point}
\begin{point}{40}[dfn-orthomodular-lattice]{Definition}%
An \Define{ortholattice}~$L$
    \index{ortholattice}
    is a bounded lattice with orthocomplement
    --- that is: it has a minimum~$0$,
    a maximum~$1$
    and a unary operation~$(\ )^\perp$
    satisfying
\begin{multicols}{2}
\begin{enumerate}
\item $a \wedge a^\perp = 0$;
\item $a \vee a^\perp = 1$;
\item $a \leq b  \ \Rightarrow\ b^\perp \leq a^\perp$ and
\item $a^{\perp\perp} = a$.
\end{enumerate}    
\end{multicols}
\noindent An ortholattice is \Define{orthomodular}\index{orthomodular!lattice}
 provided
\begin{equation*}
    a \ \leq \ b \quad \implies \quad a \vee (a^\perp \wedge b) \ =\  b.
\end{equation*}
See, for instance~\cite{kalmbach1983orthomodular,dvurecenskij2013new,birkhoff1936logic}.
\end{point}
\begin{point}{50}{Example}%
The lattice of projections in a von Neumann algebra
    is an orthomodular lattice with
    orthocomplement~$p^\perp \equiv 1 - p$.
\end{point}
\begin{point}{60}[orth-ea-is-orthomodular]{Proposition}%
An effect algebra~$E$
    that is an ortholattice
    is also orthomodular.
\begin{point}{70}{Proof}%
(For a different proof, see \cite[prop.~1.5.8]{dvurecenskij2013new}.)
Assume~$a \leq b$.
We have to show~$a \vee (a^\perp \wedge b) = b$.
Note~$a \wedge (a^\perp \wedge b) \leq a \wedge a^\perp = 0$
and so by \sref{ea-modularity-prop}
we have~$a \vee (a^\perp \wedge b) = a \ovee (a^\perp \wedge b)$.
Thus it is sufficient to prove~$a^\perp \wedge b = b \ominus a$.
Note~$a^\perp = (b \ominus a) \ovee b^\perp$
    and~$b = (b \ominus a) \ovee a$.
Similar to~\sref{modularity-lemma-proof}
    one can show that
\begin{equation*}
    (b \ominus a) \ovee (b^\perp \wedge a)
    \ = \
        ((b \ominus a) \ovee b^\perp) \wedge 
        ((b \ominus a) \ovee a) \ \equiv \ a^\perp \ovee b,
\end{equation*}
but~$b^\perp \wedge a \leq b^\perp \wedge b = 0$
    and so~$a^\perp \ovee b = b\ominus a$, as desired.
\qed
\end{point}
\end{point}
\end{parsec}

\subsection{Effect monoids}
\begin{parsec}{1780}%
\begin{point}{10}%
In \sref{dfn-mandso} we will see that the scalars of an effectus
form an effect monoid:
\end{point}
\begin{point}{20}[dfn-effect-monoid]{Definition}%
An \Define{effect monoid}~$M$ \cite{probdistrconv}
    \index{effect monoid}
    \index{*odot@$\odot$!effect monoid}
    is an effect algebra
    together with a binary operation~$\odot$
    such that for all~$a,b,c,d \in M$, we have
\begin{enumerate}
    \item \emph{(unit)}
    $1 \odot a = a \odot 1 = a$;
\item \emph{(associativity)}
    $(a \odot b) \odot c 
    =a \odot (b \odot c)$ \emph{and}
\item \emph{(distributivity)}
    if~$a \perp b$ and~$c \perp d$,
        then the following sum exists and
        furthermore~$(a \odot c) \ovee (b \odot c) \ovee
            (a \odot d) \ovee (b \odot d) = (a \ovee b) \odot (c \ovee d)$.
\end{enumerate}
(Phrased categorically:
    an effect monoid is a monoid in \textsf{EA}
    with the obvious tensor product
    that relates bimorphisms to morphisms,
    see~\cite{corefl,probdistrconv}.)
An effect monoid~$M$ is said to be \Define{commutative}
    \index{effect monoid!commutative}
    if we have~$a\odot b = b\odot a$ for all~$a,b \in M$.
A map~$f\colon M \to N$ between effect monoids
    is called an \Define{effect monoid homomorphism}
    \index{effect monoid!homomorphism}
    if it is an effect algebra homomorphism
    and furthermore~$f(a \odot b) = f(a) \odot f(b)$
    for all~$a,b \in M$.
\end{point}
\begin{point}{30}[eff-monoid-examples]{Examples}%
Effect monoids are less abundant than effect algebras.
\begin{enumerate}
\item The effect algebra~$[0,1]$
        is a commutative effect monoid with the usual product.
        (This is the only way to turn~$[0,1]$ into an effect monoid
                \cite[prop.~41]{basmsc}.)
\item We saw earlier that every Boolean algebra is an effect algebra
        with~$x \ovee y = x \vee y$ defined iff~$x \wedge y = 0$.
    The Boolean algebra is turned into an effect monoid
        with~$x \odot y \equiv x \wedge y$.
    In fact, every finite (not necessarily commutative) effect monoid
        is of this form \cite[prop.~40]{basmsc} and thus commutative.
\item
    In particular: the two-element Boolean algebra~$2 = {0,1}$
    from~\sref{eaexamples}
    is an effect monoid
        with~$x \odot y = x \wedge y$.
\item There is a non-commutative effect monoid
        based on the lexicographically ordered vector space~$\R^5$,
        see ~\cite[cor.~51]{basmsc}.
\item Let~$M$ be an effect monoid.
    Write~$M^{\mathsf{op}}$
        for the effect monoid~$M$ with the opposite multiplication
            --- that is: $a \odot_M b = b \odot_{M^\mathsf{op}} a$.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{31}[exc-emonzero]{Exercise}%
Show that~$a \odot 0 = a = 0 \odot a$
    for any~$a$ in an effect monoid~$M$.
\begin{point}{40}%
Later, in a tangent,
    we will need the following specific fact about effect monoids.
\end{point}
\end{point}
\begin{point}{50}[emond-lemma-for-conv]{Exercise}%
Assume~$M$ is an effect monoid
with~$a_1, \ldots, a_n, b_1, \ldots, b_n \in M$
such that~$\bigovee_i a_i = 1$
and~$\bigovee_i a_i \odot b_i = 1$.
Prove~$a_i \odot b_i = a_i$ for every~$1 \leq i \leq n$.
\end{point}
\end{parsec}

\subsection{Effect modules}
\begin{parsec}{1790}%
\begin{point}{10}%
We will see that in an effectus,
    the effect monoid of scalars will act on
    every effect algebra of predicates,
    turning them into effect modules (see \sref{dfn-mandso}):
\end{point}
\begin{point}{20}[dfn-effect-module]{Definition}%
Suppose~$M$ is an effect monoid.
An \Define{effect module} $E$ over~$M$ \cite{corefl}
    \index{effect module}
    is an effect algebra together with an operation
            $M \times E \to E$
            denoted by~$(\lambda, a) \mapsto \lambda \cdot a$
    such that for all~$a,b \in E$ and~$\lambda,\mu \in M$, we have
\begin{enumerate}
\item
    $(\lambda \odot \mu) \cdot a = \lambda \cdot (\mu \cdot a)$;
\item
    if~$a \perp b$,
     then~$\lambda \odot a \perp \lambda \odot b$
     and~$(\lambda \odot a) \ovee (\lambda\odot b) = \lambda \odot(a \ovee b)$;
\item
    if~$\lambda \perp \mu$,
     then~$\lambda \odot a \perp \mu \odot a$
     and~$(\lambda \odot a) \ovee (\mu \odot a) = (\lambda \ovee \mu) \odot a$
            \emph{and}
\item
    $1 \odot a = a$.
\end{enumerate}
(Categorically: an effect module over~$M$
    is an~$M$-action.)
An effect algebra homomorphism~$f\colon E \to F$
    between effect modules over~$M$
    is an $M$-\Define{effect module homomorphism}
    \index{effect module!homomorphism}
    provided~$\lambda \cdot f(a) = f(\lambda \cdot a)$
    for all~$\lambda \in M$ and~$a \in E$.
Write~$\Define{\mathsf{EMod}_M}$
    \index{$\mathsf{EMod}_M$}
    for the category of effect modules over~$M$
    with effect module homomorphisms between them.
\end{point}
\begin{point}{30}{Examples}%
There are many effect modules.
\begin{enumerate}
\item
Every effect algebra is an effect module over
    the two-element effect monoid~$2$.
    (In fact $\mathsf{EA} \cong \mathsf{EMod}_{2}$.)
The only effect module up-to-isomorphism over the one-element effect monoid~$1$
    is the one-element effect algebra~$1$ itself.
\item
Effect modules over~$[0,1]$
    are the same thing as
        \Define{convex effect algebras},
        see \cite{gudder1998representation,gudder1999convex}.
        \index{effect algebra!convex}
If~$V$ is an ordered real vector space with order unit~$u$,
        then~$[0,u]$ is an effect module over~$[0,1]$.
In fact, every effect module over~$[0,1]$
    is of this form \cite{gudder1998representation}.
See also \cite[thm.~3]{jacobs2016expectation}
    for the stronger categorical equivalence.
\end{enumerate}
\spacingfix{}
\end{point}
\end{parsec}

\section{Effectuses}
An effectus comes in two guises:
    axiomatizing either a category of total maps
    or a category of partial maps.
We will start off with the total form as it has the simplest axioms.
Later we will prefer to work with the partial form.
\begin{parsec}{1800}%
\begin{point}{10}[dfn-effectus]{Definition}%
A category $C$ is said to be an \Define{effectus in total form}
    \index{effectus!in total form}
    \cite{effintro,newdirections,statesofconvexsets}
    if
\begin{enumerate}
\item $C$ has finite coproducts (hence an initial object~$0$)
        and a final object~$1$;
    \item all diagrams of the following
        \index{kappa@$\kappa_i$, coprojection}
        \index{$[\,\cdot\,,\,\cdot\,]$!cotupling}
        \index{*bang@$"!$, initial/final map}
        form\footnote{%
        We write~$\Define{\kappa_i}$ for coproduct coprojections;
            square brackets~$\Define{[f,g]}$ for coproduct cotupling;
            $\Define{h+k} = [\kappa_1 \after h, \kappa_2 \after k]$
            and~$\Define{!}$ for the unique maps associated to
            either the final object~$1$ or initial object~$0$.} are pullbacks
\begin{equation}\label{pullbacks}
    \vcenter{\xymatrix{
        X+Y \ar[r]^{\id+{!}} \ar[d]_{!+\id} & X+1\ar[d]^{!+\id} \\
    1+Y\ar[r]_{\id+!} & 1+1
}}
    \qquad\qquad
    \vcenter{\xymatrix{
    X \ar[r]^{!} \ar[d]_{\kappa_1} & 1 \ar[d]^{\kappa_1} \\
    X+Y\ar[r]_{{!}+{!}} & 1+1
}}
\end{equation}
\item\label{eff-joint-monicity} and the following two arrows are jointly monic.
    \begin{equation*}
        \xymatrix@C+2pc  {
            1+1+1  \ar@/^/[r]^{[\kappa_1,\kappa_2,\kappa_2]}
                    \ar@/_/[r]_{[\kappa_2,\kappa_1,\kappa_2]} & 1+1
        }
    \end{equation*}
\end{enumerate}
An arrow~$f\colon X \to Y+1$ is called a \Define{partial map} and written
    \index{partial map}
    $f\colon \Define{X \pto Y}$.
    \index{*pto@$\pto$}
\begin{point}{20}%
One with an interest in physics might think of the objects
    of an effectus as physical systems and its arrows as
    the physical operations between them.
    The final object~$1$ is the physical system with a single state.
The coproduct~$X+Y$ is the system that can be prepared as either~$X$ or as~$Y$.
An arrow~$1 \to X$ corresponds to a physical preparation of the system~$X$
    and an arrow~$X \to 1+1$ is a yes--no measurement.
\end{point}
\begin{point}{30}%
In this sense an effectus can be seen as a generalized
        probabilistic theory
        --- not unlike the operational-probabilistic theories (OPT)
        of Chiribella et al \cite{chiribella2010probabilistic}.
There are differences:
for instance, OPTs are equipped with a parallel composition of systems,
     effectuses are not and OPTs always have the unit interval as scalars,
     effectuses might not.
In \cite{tull2016operational} Tull compares effectuses and OPTs.
There are other approaches to categorical probabilistic theories;
 see, for instance~\cite{wilceshortcut,gogioso2017categorical}.
\end{point}
\begin{point}{40}%
Studying programming languages, one would do better thinking of
    the objects of an effectus as data types and
    its arrows as the allowed operations between them (semantics of programs).
The final object~$1$ is the unit data type.
The coproduct~$X + Y$ is the union data type of~$X$ and~$Y$.
An arrow~$1 \to X$ is a value of~$X$
    and an arrow~$X \to 1+1$ is a predicate on~$X$.
\end{point}
\begin{point}{50}[effectus-vn]%
Our main example of an effectus in total form
    is the category~$\op{\vN}$\index{vN@$\vN$}
    of von Neumann algebras with completely positive normal unital
    maps in the opposite direction.
(To see~$\op\vN$ is an effectus in total form,
    adapt the proof of \sref{emod-effectus}.)
The partial maps correspond to
    ncp-maps~$f$ with~$f(1) \leq 1$.
(Equivalently: contractive ncp-maps.)
Some other examples appear later on in
    \sref{emod-effectus}, \sref{exc-dm-effectus},
    \sref{aconvm-is-effectus} and~\sref{effexamplesintro}.
For a comprehensive list of examples, see~\cite{effintro}.
\end{point}
\begin{point}{60}%
Let~$C$ be an effectus in total form.
Given two arrows~$f\colon X \to Y+1$
and~$g \colon Y \to Z+1$ (i.e.~partial maps~$X \pto Y$ and~$Y \pto Z$)
    their composition as partial maps
    is defined as~$g \hafter f \equiv  [g, \kappa_2] \after f$.
Write~$\Define{\Par C}$ for the \Define{category of partial maps},
    \index{ParC@$\Par C$}
    which has the same objects
    as~$C$, but as arrows~$X \to Y$ in~$\Par C$
    we take arrows of the form~$X \to Y+1$ in~$C$,
    which we compose using~$\hafter$
    and with identity on~$X$ in~$\Par C$
    given by~$\kappa_1 \colon X \to X+1$.\footnote{In categorical
            parlance: $\Par C$ is the Kleisli category of
            the monad~$(\ )+1\colon C \to C$.}
The category~$\Par C$ is not an effectus in total form --- instead it
    is an effectus \emph{in partial form}.
\end{point}
\end{point}
\begin{point}{70}[effectus-in-partial-form]{Definition}%
A category~$C$ is called an \Define{effectus in partial form}
    \index{effectus!in partial form}
    \cite{effintro,kentapartial} if
\begin{enumerate}
\item
    $C$ is a finPAC\footnote{Finitarily partially additive category.} \cite{kentapartial} (cf.~\cite{arbib}) --- that is:
    \begin{enumerate}
        \item 
            $C$ has finite coproducts $(+,0)$;
        \item $C$ is $\mathsf{PCM}$-enriched --- that is:
            \begin{enumerate}
            \item
            every homset $C(X,Y)$ has a partial binary operation~$\ovee$
                    and distinguished element~$0 \in C(X,Y)$
                    that turns~$C(X,Y)$ into a partial commutative monoid,
                    see \sref{dfn-pcm};
            \item
            if $f \perp g$ then both
                $(h \after f) \perp (h \after g)$ and
                $(f \after k) \perp (g \after k)$ \emph{and}
            \begin{equation*}
                 h \after (f \ovee g) = 
                (h \after f) \ovee (h \ovee g)\qquad
                (f \ovee g) \after k = 
                (f \after k) \ovee (g \after k)
            \end{equation*}
                for any~$f,g \colon X \to Y$,
                $h\colon Y \to Y'$
                    and~$k \colon X'\to X$ \emph{and}
            \item
                \emph{(zero)}
                $0 \after f = 0$ and $f \after 0 = 0$ for
                    any~$f\colon X \to Y$ \emph{and}
            \end{enumerate}
        \item
            \emph{(compatible sum)}
            for any~$b\colon X \to Y + Y$ we have
            $\pproj_1 \after b \perp \pproj_2 \after b$,
            where~$\Define{\pproj_i}\colon Y + Y \to Y$
            \index{*pproj@$\pproj_i$}
            are \Define{partial projectors}\footnote{%
                Later, in~\sref{coprod-prod},
                    we will use the more slightly more general
                    ${\pproj_1}\colon X_1 + X_2 \to X_1$ and
                    ${\pproj_2}\colon X_1 + X_2 \to X_2$
                    defined by~$\pproj_1 = [\id,0]$
                        and~$\pproj_2 = [0,\id]$.} defined
            \index{partial projectors}
            by~$\pproj_1 \equiv [\id, 0]$
            and~$\pproj_2 \equiv [0, \id]$ \emph{and}
        \item
            \emph{(untying)} if~$f\perp g$,
            then~$\kappa_1\after f \perp \kappa_2 \after g$,
            where~$\kappa_1$ and~$\kappa_2$ are coprojections
            on the same coproduct
            \emph{and}
    \end{enumerate}
    \item it has effects --- that is: there is a distinguished object~$I$
            such that
    \begin{enumerate}
        \item for each object~$X$, the PCM~$C(X,I) \equiv \Define{\Pred X}$
            \index{predX@$\Pred X$}
            is an effect algebra, see \sref{dfn-ea}
            --- in particular~$C(X,I)$
                has a maximum element~$1$;
        \item if~$1 \after f \perp 1 \after g$,
            then~$f \perp g$ \emph{and}
        \item if~$1 \after f = 0$, then~$f = 0$.
    \end{enumerate}
\end{enumerate}
In this setting,
a map~$f\colon X \to Y$ is called \Define{total} if~$1 \after f = 1$.
    \index{total map}
\begin{point}{80}{Remark}%
The untying and zero axioms are redundant: they follows from the others.
We include them, as they are part of the definition of finPAC.
\end{point}
\begin{point}{90}%
At first glance an effectus in partial form seems
    to have a much richer structure than an effectus in total form.
This is not the case ---
    effectuses in total and partial form are two views
    on the same thing \cite{kentapartial,effintro}:
\end{point}
\end{point}
\begin{point}{100}[cho-thm]{Theorem (Cho)}%
Let~$C$ be an effectus in total form
and~$D$ be an effectus in partial form.
\begin{enumerate}
\item
The category~$\Par C$ is an effectus in partial form
        with~$I = 1$.
\item
The total maps of~$D$ form an effectus in total form~$\Tot D$.
\item
    Nothing is lost:
        $\Par (\Tot D) \cong D$ and~$\Tot (\Par C )\cong C$.
\end{enumerate}
\spacingfix{}
\begin{point}{110}%
(The result can be rephrased categorically as
    a 2-equivalence of the 2-category
    of effectuses in partial form and
    the 2-category of effectuses in total form.
    For the details, see~\cite[\S5]{kentapartial}.)
To prove the Theorem
    (in \sref{proof-cho-thm}),
    we need some preparation.
\end{point}
\end{point}
\end{parsec}
\subsection{From partial to total}
\begin{parsec}{1810}%
\begin{point}{10}%
We will first show that the subcategory of
    total maps of an effectus in partial form
    is an effectus in total form.
This proof and especially the demonstration
    that the squares in \eqref{pullbacks} are pullbacks,
    will elucidate the axioms of an effectus in total form
    and will make the proof in the opposite direction more palatable.
\end{point}
\begin{point}{20}[coproj-total]{Lemma}%
In an effectus in partial form,
    coprojections are total.
\begin{point}{30}{Proof}%
    (For the original and different proof see \cite[lem.~4.7(5)]{kentapartial}.)
Let~$\kappa_1 \colon X \to X+Y$ be any coprojection.
We have to show~$1 \after \kappa_1 = 1$.
Note that the first~$1$ denotes the maximum of~$\Pred X+Y$
    and the second the maximum of~$\Pred X$.
    Hence~$1_X = 1_X \after \id_X = (1_X \after [\id_X, 0]) \after \kappa_1
                    \leq 1_{X+Y} \after \kappa_1 \leq 1_X$.
Indeed~$1 \after \kappa_1 = 1$. \qed
\end{point}
\end{point}
\begin{point}{40}[cotupl-pcm]{Proposition}%
In an effectus in partial form,
the cotupling bijection~$(f,g) \mapsto [f,g]$
    is a PCM-isomorphism \cite{effintro }---
    that is:
\begin{enumerate}
\item
    $[f,g] \perp [f',g']$ if and only if
        $f \perp f'$ and~$g \perp g'$;
\item
    if~$[f,g] \perp [f', g']$,
    then~$[f,g] \ovee [f',g'] = [f \ovee f', g\ovee g']$ \emph{and}
\item
    $[0,0] = 0$.
\end{enumerate}
Furthermore~$[1,1]=1$ for maps into~$I$,
so the cotupling map is an effect algebra
isomorphism~$\Pred (X) \times \Pred (Y) \cong \Pred (X+Y) $.
\begin{point}{50}{Proof}%
First we show~$[h,l] = [h,0] \ovee [0,l]$.
By the compatible sum axiom
\begin{equation*}
    [h, 0] \ = \ 
    \pproj_1 \after (h + l)
    \ \perp\  \pproj_2 \after (h + l)
    \ = \ [0, l].
\end{equation*}
By $\mathsf{PCM}$-enrichment
$([h, 0] \ovee [0, l]) \after \kappa_1
         =  ([h, 0] \after \kappa_1) \ovee
        ([0, l] \after \kappa_1)  = h$.
Similarly~$([h, 0] \ovee [0, l]) \after \kappa_2 = l$.
Thus indeed~$[h,l] = [h,0] \ovee [0,l]$.

Assume~$[f,g] \perp [f',g']$.
    By $\mathsf{PCM}$-enrichment
    we have~$f = [f,g] \after \kappa_1 \perp [f',g'] \after \kappa_1 = f'$.
Similarly~$g \perp g'$.
Conversely, assume~$f \perp f'$ and~$g \perp g'$.
Again, by $\mathsf{PCM}$-enrichment~$
[f,0] = f  \after \pproj_1 \perp f' \after \pproj_1 = [f', 0]$
    and~$[f\ovee f', 0 ] = [f,0] \ovee [f', 0]$.
Similarly~$[0,g \ovee g'] = [0,g] \ovee [0,g']$.
Putting it all together:
\begin{align*}
[f, g] \ovee [f', g']
&\ = \ 
 [f, 0] \ovee [0,g] \ovee [f', 0] \ovee [0, g'] \\
 &\ = \ 
 [f\ovee f', 0]\ovee [0, g\ovee g'] \\
 &\ = \ 
 [f\ovee f', g \ovee g'].
\end{align*}
To show cotupling is a PCM-isomorphism,
    it only remains to be shown that~$[0,0]=0$.
As~$0 \after \kappa_1 = 0$
    and~$0 \after \kappa_2 = 0$,
    we indeed have~$0 = [0,0]$.
Similarly by \sref{coproj-total} we have~$1 \after \kappa_1 = 1$
    and~$1 \after \kappa_2 = 1$,
    so~$1 = [1,1]$. \qed
\end{point}
\begin{point}{60}%
The coproduct in an effectus in partial form
is almost a (bi)product:
\end{point}
\end{point}
\begin{point}{70}[coprod-prod]{Proposition}%
In an effectus in partial form, we have a bijective correspondence
\begin{prooftree}
\AxiomC{$h\colon Z \to X+Y$}
\doubleLine
\UnaryInfC{$f\colon Z \to X \quad g\colon Z \to Y \quad 1 \after f \perp 1 \after g$}
\end{prooftree}
as follows \cite[lem.~4.8]{kentapartial}:
\begin{quote}
for every~$f\colon Z \to X$
    and~$g\colon Z \to Y$
    with~$1 \after f \perp 1 \after g$,
    there is a unique map~$\Define{\langle f, g\rangle} \colon Z \to X +Y$
    \index{*langle@$\langle\,\cdot\,,\cdot\,\rangle$!in an effectus}
    such that~$\pproj_1 \after \langle f, g \rangle = f$
    and~$\pproj_2 \after \langle f, g \rangle = g$,
    where~$\pproj_1 = [\id,0]$ and~$\pproj_2=[0,\id]$.
In fact~$\langle f, g\rangle = (\kappa_1 \after f) \ovee (\kappa_2 \after g)$.
\end{quote}
Conversely~$h = \langle \pproj_1 \after h, \pproj_2 \after h \rangle$
    with~$1 \after \pproj_1 \after h \perp 1 \after \pproj_2 \after h$
    for~$h \colon Z \to X+Y$.
\begin{point}{80}{Proof}%
Let~$f\colon Z \to X$ and~$g\colon Z \to Y$ be given
        such that~$1\after f \perp 1\after g$.
By \sref{coproj-total},
we have~$1 \after \kappa_1 \after f = 1 \after f \perp 1 \after g =
        1 \after \kappa_2 \after g$.
Thus~$\kappa_1 \after f \perp \kappa_2 \after g$.
Define~$\langle f, g\rangle = (\kappa_1 \after f) \ovee (\kappa_2 \after g)$.
    By the $\mathsf{PCM}$-enrichedness, we have
\begin{align*}
\pproj_1 \after \langle f, g\rangle 
&\  =\  [\id, 0] \after ((\kappa_1 \after f) \ovee (\kappa_2 \after g)) \\
 &\  =\  ([\id, 0] \after \kappa_1 \after f) \ovee 
    ([\id, 0] \after \kappa_2 \after g) \\
    & \ =\  f \ovee (0 \after g) \ = \ f.
\end{align*}
Similarly~$\pproj_2 \after \langle f, g \rangle = g$.
To show uniqueness, assume~$f = \pproj_1 \after h$
    and~$g = \pproj_2 \after h$ for some
    $h\colon Z \to X+Y$.
Note~$\kappa_1 \after \pproj_1 = [\kappa_1, 0]$
and~$\kappa_2 \after \pproj_2 = [0, \kappa_2]$,
so by~\sref{cotupl-pcm} we have~$(\kappa_1 \after \pproj_1)
    \ovee (\kappa_2 \after \pproj_2) = [\kappa_1, \kappa_2] = \id$,
    hence
\begin{align*}
    \langle f, g\rangle & \ = \ 
    \langle \pproj_1 \after h, \pproj_2 \after h \rangle \\
    & \ = \ (\kappa_1 \after\pproj_1 \after h) 
    \ovee (\kappa_2 \after\pproj_2 \after h)  \\
    & \ = \ ((\kappa_1 \after\pproj_1 )
    \ovee (\kappa_2 \after\pproj_2 ))  \after h \\
    & \ = \   \id \after h \ = \  h,
\end{align*}
which demonstrates uniqueness.

Finally, let~$h\colon Z\to X+Y$ be any map.
We must show that~$h = \langle \pproj_1 \after h, \pproj_2 \after h\rangle$.
Note~$1 \after \pproj_1 = [1,0]$
    and~$1 \after \pproj_2 = [0,1]$.
    So by $\mathsf{PCM}$-enrichment~$1 \after \pproj_1 \after h \perp 1 \after \pproj_2 \after h$ and so~$\pproj_1 \after h \perp \pproj_2 \after h$.
By the previous
$\langle \pproj_1 \after h, \pproj_2 \after h\rangle
= (\kappa_1 \after \pproj_1 \after h) \ovee
 (\kappa_2 \after \pproj_2 \after h) 
 = h $ as desired.\qed
\end{point}
\end{point}

\begin{point}{90}[eff-prod-rules]{Exercise}%
Show that in an effectus in partial form, we have
\begin{enumerate}
    \item~$[a,b] \after \langle f, g \rangle = (a \after f) \ovee (b \after g)$;
    \item~$1 \after \langle f, g\rangle = (1 \after f) \ovee(1 \after g)$;
    \item~$(k+l) \after \langle f, g\rangle
        = \langle k \after f, l \after g \rangle$ \emph{and}
    \item~$\langle f, g\rangle \after k = \langle f \after k,
                                g \after k \rangle$
\end{enumerate}
        assuming~$1 \after f \perp 1 \after g$. \cite{effintro}
\begin{point}{100}{Remark}%
In an effectus in partial form,
    there is a straightforward generalization
    of the bijective correspondence~\sref{coprod-prod} to
\begin{prooftree}
\AxiomC{$h\colon Z \to  X_1 + \cdots + X_n$}
\doubleLine
\UnaryInfC{$f_1\colon Z \to X_1 \ \cdots \  f_n\colon Z \to X_n \quad \bigperp_n  1 \after f_n$}
\end{prooftree}
with~$f_i = \pproj_i \after h$
    and~$h = \langle f_1, \ldots, f_n\rangle \equiv
    (\kappa_1 \after f_1 )\ovee \cdots \ovee (\kappa_n \after f_n)$,
    where~$\pproj_i$ is defined in the obvious way.
The expected generalizations  of the rules in \sref{eff-prod-rules} also hold.
\end{point}
\end{point}

\begin{point}{110}[eff-partial-to-total]{Theorem}%
Let~$C$ be an effectus in partial form.
The category of total maps of~$C$ is an effectus in total form.
    \cite[thm.~4.10]{kentapartial}
\begin{point}{120}{Proof}%
The total maps indeed form a subcategory: $1 \after \id = 1$
    and $1 \after f \after g = 1 \after g = 1$ for composable total~$f,g$.
In \sref{coproj-total} we saw coprojections are total.
By \sref{cotupl-pcm}
    we have~$1 \after [f,g] = [1 \after f, 1 \after g] = [1,1] = 1$
    for total~$f\colon X \to Z$ and~$g\colon Y \to Z$,
    so~$\Tot C$ has binary coproducts.
The unique map~$!\colon 0 \to X$ must be total
    as~$1 \after ! = 1$ is the unique map~$0 \to I$,
    so~$\Tot C$ has initial object~$0$, hence all finite coproducts.
\end{point}
\begin{point}{130}[one-m-is-id]%
To show~$I$ is the final object of~$\Tot C$,
    we need~$\id_I = 1$.
As~$C(I,I)$ is an effect algebra~$1 = \id \ovee \id^\perp$
    for some~$\id^\perp$.
    So by $\mathsf{PCM}$-enrichment~$1 = 1 \after 1 = (1 \after \id) \ovee (1 \after\id^\perp) = 
1 \ovee (1 \after \id^\perp)$.
By the zero--one axiom~$1 \after \id^\perp = 0$.
So~$\id^\perp = 0$ and indeed~$\id = 1$.
To show~$I$ is final in~$\Tot C$, pick any object~$X$ in~$\Tot C$.
We claim~$1 \colon X \to I$ is the unique total map.
Indeed, by the previous $1 = \id_I \after 1 = 1 \after 1$, so~$1$ is total
and if~$h\colon X \to I$ is total, then~$1=1 \after h = \id_I \after h = h$.
\end{point}
\begin{point}{140}%
To show the square on the left of \eqref{pullbacks} is a pullback
    in~$\Tot C$,
let~$f\colon Z \to X+I$ 
and~$g\colon Z \to I+Y$ be total maps
    with~$(\id+1) \after g = (1+\id) \after f$.
By~\sref{coprod-prod}, $f = \langle \alpha, a \rangle$
    and~$g = \langle b, \beta \rangle$
    for some maps~$\alpha\colon Z \to X$, $\beta\colon Z \to Y$
        and~$a,b\colon Z \to I$.
\begin{equation*}
\xymatrix@C+1pc@R-1pc{ 
Z \ar@/^1pc/[rrd]^{\langle\alpha,a \rangle \equiv f}
    \ar@/_1pc/[rdd]_{g \equiv \langle b, \beta\rangle}
    \ar@{.>}[rd]|{\langle \alpha, \beta\rangle}
    \\
    &  X+Y \ar[r]^{\id+1} \ar[d]_{1+\id} & X+I\ar[d]^{1+\id} \\
    &I+Y\ar[r]_{\id+1} & I+I
    }
\end{equation*}
By~\sref{eff-prod-rules},
    we have~$1 = 1 \after f = 1 \after \langle \alpha, a\rangle
                = (1 \after \alpha) \ovee a$
        and so~$a^\perp = 1\after \alpha$.
Similarly~$b^\perp = 1 \after \beta$.
Again, using~\sref{eff-prod-rules},
    we see that
\begin{equation*}
    \langle b, 1 \after \beta \rangle \ =\ 
    (\id + 1) \after \langle b, \beta \rangle \ =\ 
    (\id + 1) \after g \ =\ 
    (1 + \id) \after f
               \  = \ \langle 1 \after \alpha, a\rangle,
\end{equation*}
so~$1 \after \beta = a = (1 \after \alpha)^\perp$,
hence~$1 \after \beta \perp 1 \after \alpha$,
so~$\langle \alpha,\beta\rangle \colon Z \to X+Y$ exists
    and is total as~$1 \after \langle \alpha,\beta\rangle = 
        (1 \after \alpha) \ovee (1 \after \beta) = 1$.
We compute~$(\id + 1) \after \langle\alpha, \beta\rangle = \langle \alpha,
    1 \after \beta\rangle = \langle \alpha, a\rangle = f$.
    Similarly~$(1 + \id) \after \langle \alpha, \beta\rangle = g$.
    Assume~$h\colon Z \to X+Y$ is any map with~$(1 +\id) \after h
        = g$ and~$(\id+1) \after h = f$.
Say~$h = \langle h_1, h_2 \rangle$.
Then~$\langle \alpha, a\rangle = f= (\id + 1)\after h = \langle h_1, 1 \after h_2 \rangle$, so~$\alpha = h_1$. Similarly~$\beta=h_2$.
Thus~$h = \langle \alpha, \beta\rangle$,
    which shows our square is indeed a pullback.
\end{point}
\begin{point}{150}%
To show the square on the right of \eqref{pullbacks} is a pullback
    in~$\Tot C$,
assume (using \sref{coprod-prod})
$\langle \alpha, \beta \rangle\colon Z \to X+Y$
is some total map
with~$(1+1) \after \langle\alpha,\beta\rangle = \kappa_1 \after 1$.
    \begin{equation*}
\xymatrix@C+1pc@R-1pc{ 
    Z \ar@{.>}@/^1pc/[rrd]^{1}
    \ar@/_1pc/[rdd]_{\langle \alpha,\beta\rangle}
    \ar@{.>}[rd]|{\alpha}\\
    &X \ar[r]^{1} \ar[d]_{\kappa_1} & I \ar[d]^{\kappa_1} \\
    &X+Y\ar[r]_{1+1} & I+I
    }
    \end{equation*}
With \sref{eff-prod-rules},
we see~$\langle 1 \after \alpha, 1 \after \beta \rangle
        = (1 + 1) \after \langle \alpha, \beta \rangle
        = \kappa_1 \after 1
        = \langle 1, 0 \rangle$.
So~$\alpha$ is total and~$\beta=0$.
Hence~$\langle \alpha, \beta\rangle = \langle \alpha, 0\rangle
        = \kappa_1 \after \alpha$ as desired.
\end{point}
\begin{point}{160}%
    Finally, to show~$m_1\equiv [\kappa_1,\kappa_2,\kappa_2],
        m_2 \equiv [\kappa_2,\kappa_1,\kappa_2]\colon
    I+I+I \to I+I$ are jointly monic,
    let~$f_1 \equiv \langle a_1,b_1,c_1\rangle,f_2\equiv \langle a_2,b_2,c_2\rangle\colon X\to I+I+I$ be any total maps
    with~$m_1 \after f_1 = m_1 \after f_2$
    and~$m_2 \after f_1 = m_2 \after f_2$.
Then
\begin{equation*}
    a_1 \ = \ [\id, 0, 0] \after f_1
        \ = \ \pproj_1 \after m_1 \after f_1
        \ = \ \pproj_1 \after m_1 \after f_2
        \ = \ a_2.
\end{equation*}
and similarly from the equality involving~$m_2$, we get~$b_1 = b_2$.
As~$f_1$ is total, we have~$1 = 1 \after f_1=  a_1 \ovee b_1 \ovee c_1$,
    so~$c_1 = (a_1 \ovee b_1)^\perp$.
With the same reasoning~$c_2 = (a_2 \ovee b_2)^\perp$.
Thus~$c_1 = c_2$ and so~$f_1 = f_2$, as desired. \qed
\end{point}
\end{point}
\end{parsec}

\subsection{From total to partial}
\begin{parsec}{1820}%
\begin{point}{10}%
Let~$C$ be an effectus in total form.
In this section we will show that~$\Par C$ is an effectus in partial form.
Before we get to work, it is helpful to discuss the axioms
    of an effectus in total form, now we have some experience
    with an effectus in partial form.
\begin{enumerate}
\item
In \sref{coprod-prod} we saw that the coproduct in an effectus
    (in partial form) is almost a biproduct.
This structure is hidden (for the most part)
    in the left pullback square of
    \eqref{pullbacks}, which
    allows the formation of~$\langle \alpha, \beta \rangle$ given
    partial maps~$\alpha,\beta$.
\item
The right pullback square of \eqref{pullbacks}
    is used to extract a total map in~$C$
    from a partial map~$f$ in~$\Par C$ that is total (i.e.~$1 \hafter f = 1$).
        See~\sref{pardp}.
\item
The joint-monicity
    of~$[\kappa_1,\kappa_2,\kappa_2]$
    and~$[\kappa_2,\kappa_1,\kappa_2]$
    will imply the joint monicity of~$\pproj_1$ and $\pproj_2$,
    which is required for uniqueness of the partial sum of partial maps.
        See~\sref{pproj-joint-monicity}.
\end{enumerate}
To prove the theorem, we need to study pullbacks:
    first in any category,
    then in an effectus~$C$ in total form
    and finally in~$\Par C$.
Our proof is different from the original proof of Cho
    by using several more general facts about pullbacks,
    which we will prove next.
\end{point}
\end{parsec}

\begin{parsec}{1830}%
\begin{point}{10}%
    We start with two classic facts about pullbacks.
\end{point}
\begin{point}{20}[exc-jointly-monic-pullback]{Exercise}%
Show that if we have any pullback square --- say
\begin{equation*}
    \vcenter{\vbox{\xymatrix@R-1pc{
        {P\ } \pullback \ar[r]^{m_1} \ar[d]_{m_2}
        & B \ar[d]^f
                \\ {A\ } \ar[r]_{g}
    & X}}} \text{,}
\end{equation*}
then~$m_1$ and~$m_2$ are jointly monic.
\end{point}
\begin{point}{30}[pullback-lemma]{Exercise}%
Prove the \Define{pullback lemma} --- that is:
    \index{pullback lemma}
    if we have a commuting diagram
\begin{equation*}
    \vcenter{\vbox{\xymatrix@R-1pc{
                A \ar[r]^f \ar[d]_k
                & B \ar[r]^g \ar[d]_l
                & C \ar[d]^m
                \\ X \ar[r]_{f'}
                & Y \ar[r]_{g'}
                & Z
    }}} \text{,}
\end{equation*}
then we have the following two implications.
\begin{enumerate}
\item
If the left and right inner squares are pullbacks,
    then so is the outer square.
\item
If the outer square is a pullback
    and~$l$ and~$g$ are jointly monic,
    then the left inner square is a pullback.
\end{enumerate}
\spacingfix{}
\begin{point}{40}{Remark}%
In the literature (e.g.~\cite[III.5 exc.~8]{maclane}),
    one often finds a weaker second implication,
    which assumes that the right square is a pullback.
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{1840}%
\begin{point}{10}%
It is well-known that monos are stable under pullbacks ---
that is:
\begin{equation*}
    \text{if} \quad
    \vcenter{\vbox{\xymatrix@R-1pc{
                {P\ } \pullback \ar[r]^n \ar[d]_g
        & X \ar[d]^f
                \\ {A\ } \ar@{>->}[r]_{m}
    & B}}} ,
    \quad \text{then} \quad
    \vcenter{\vbox{\xymatrix@R-1pc{
                {P\ } \pullback \ar@{>->}[r]^n \ar[d]_g
        & X \ar[d]^f
                \\ {A\ } \ar@{>->}[r]_{m}
    & B}}},
\end{equation*}
    where we used~$\xymatrix@C-1pc{\ar@{>->}[r]&}$ to denote a monic map.
We will need an analogous result for jointly monic maps.
\end{point}
\begin{point}{20}[joint-monicity-stable]{Lemma}%
If the pairs~$(m_1,m_2)$, $(n_1,g_1)$, $(n_2,g_2)$ and~$(h_1,h_2)$
in the following commuting diagram
are jointly monic (for instance: if they span pullback squares),
then~$(n_1 \after h_1, n_2 \after h_2)$ is jointly monic as well.
\begin{equation*}
    \xymatrix@C+1pc{
        P \ar[r]^{h_1} \ar[d]_{h_2}
        &P_1\ar[r]^{n_1} \ar[d]^{g_1}
        &X_1 \ar[d]^{f_1}
        \\ P_2\ar[r]_{g_2} \ar[d]_{n_2}
        & A \ar[r]_{m_1} \ar[d]^{m_2}
        & B_1 
        \\ X_2 \ar[r]_{f_2}
        & B_2
    }
\end{equation*}
\spacingfix{}
\begin{point}{30}{Proof}%
To show joint monicity of~$n_1 \after h_1$ and~$n_2 \after h_2$,
assume~$\alpha_1,\alpha_2  \colon Z \to P$
    are maps with~$
        n_1 \after h_1 \after \alpha_1
        = n_1 \after h_1 \after \alpha_2$
    and~$n_2 \after h_2 \after \alpha_1
        = n_2 \after h_2 \after \alpha_2$.
To start
\begin{equation*}
    m_1 \after g_1 \after h_1 \after \alpha_2
    \ =\  f_1 \after n_1 \after h_1 \after \alpha_2 
    \ =\  f_1 \after n_1 \after h_1 \after \alpha_1 
            \ =\  m_1 \after g_1 \after h_1 \after \alpha_1.
\end{equation*}
Reasoning on the other side of the diagram, we find
\begin{align*}
    m_2 \after g_1 \after h_1 \after \alpha_2
    &\ =\  m_2 \after g_2 \after h_2 \after \alpha_2 \\ 
    &\ =\  f_2 \after n_2 \after h_2 \after \alpha_2 \\ 
    &\ =\  f_2 \after n_2 \after h_2 \after \alpha_1 \\ 
    &\ =\  m_2 \after g_2 \after h_2 \after \alpha_1 \\ 
    &\ =\  m_2 \after g_1 \after h_1 \after \alpha_1.
\end{align*}
So by joint monicity of~$m_1$ and~$m_2$,
    we conclude~$g_1 \after h_1 \after \alpha_2
                = g_1 \after h_1 \after \alpha_1$.
So by the joint monicity of~$n_1$ and~$g_1$
    (and by assumption~$n_1 \after h_1 \after \alpha_2
    = n_1 \after h_1 \after \alpha_1$),
    we conclude~$h_1 \after \alpha_1 = h_1 \after \alpha_2$.
Reasoning in the same way mirrored over the diagonal,
    we find~$h_2 \after \alpha_1 = h_2 \after \alpha_2$.
Thus, by joint monicity of~$h_1$ and~$h_2$, we conclude that~$\alpha_1 = \alpha_2$, as desired. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{1850}%
\begin{point}{10}[tot-pullbacks]{Proposition}%
In an effectus in total form,
    any square of one of the two following forms is a pullback.
\begin{equation*}
    \xymatrix{
        X+A \pullback \ar[r]^{\id+f} \ar[d]_{g + \id}
        & X+B \ar[d]^{g+\id}
        \\ Y+A \ar[r]_{\id+f}
        & Y+B
    } \qquad
    \xymatrix{
        X \pullback \ar[d]_{\kappa_1} \ar[r]^{f}
        & Y \ar[d]^{\kappa_1}
        \\
        X+A \ar[r]_{f+g}
        & Y+B
    }
\end{equation*}
\spacingfix{}
\begin{point}{20}{Proof}%
To start with the left square, consider the following commuting diagram.
\begin{equation*}
    \xymatrix{
        X+A \ar@{}[rd]|{(1)} \ar[r]^{\id+f} \ar[d]_{g + \id}
        & X+B \ar@{}[rd]|{(2)} \ar[d]^{g+\id} \ar[r]^{\id+!}
        & X+1 \ar[d]^{g+\id}
        \\ Y+A \ar@{}[rd]|{(3)} \ar[r]_{\id+f} \ar[d]_{!+\id}
        & Y+B \ar@{}[rd]|{(4)} \ar[r]_{\id+!} \ar[d]^{!+\id}
        & Y+1 \ar[d]^{!+\id}
        \\ 1+A \ar[r]_{\id+f}
        & 1+B \ar[r]_{\id+!}
        & 1+1
    }
\end{equation*}
We want to show (1) is a pullback.
The inner square~(4) and right rectangle~(2,4) are pullbacks by axiom.
Thus the inner square~(2) is also a pullback
    by the pullback lemma, see \sref{pullback-lemma}.
With the same reasoning, we see square (3) is a pullback.
Thus by the pullback lemma, it is sufficient to show that
    left rectangle (1,3) is a pullback.
The left rectangle is indeed a pullback
as both the outer square (1,2,3,4)
    and the right rectangle (2,4) are pullbacks.

For the right square, we consider the following diagram.
\begin{equation*}
    \xymatrix{
         X \ar[r]^f \ar[d]_{\kappa_1}
            %\ar@{}[rd]|{(1)}
        & Y \ar[r]^{!} \ar[d]^{\kappa_1}
            %\ar@{}[rd]|{(2)}
        &1 \ar[d]^{\kappa_1}
        \\ X+A \ar[r]_{f+g}
        & Y+B \ar[r]_{!+!}
        & 1+1
    }
\end{equation*}
The inner right and outer square are pullbacks by axiom.
So the inner left square is also a pullback by the pullback lemma, as desired.
    \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{1860}%
\begin{point}{10}{Definition}%
Assume~$C$ is an effectus in total form.
For a map~$f\colon X \to Y$,
    write~$\Define{\hat{f}} = \kappa_1 \after f \colon X \to Y+1$.
    \index{*hat@$\hat{f}$!in an effectus}
    (This is the Kleisli embedding~$C \to \Par C$.) \cite{kentapartial}
\end{point}
\begin{point}{11}
    (Recall that we use~$f\colon X \pto Y$
        to denote a map~$f\colon X \to Y+1$,
            see~\sref{dfn-effectus}.)
\end{point}
\begin{point}{20}[par-c-coprod]{Exercise}%
Assume~$C$ is an effectus in total form.
Show that if
\begin{equation*}
\kappa_1 \colon X \to X+Y \leftarrow Y \colon \kappa_2
\end{equation*}
    is a coproduct in~$C$, then~
\begin{equation*}
    \hat\kappa_1 \colon X \pto X+Y \pfrom Y \colon \hat\kappa_2
\end{equation*}
    is a coproduct in~$\Par C$.
Show~$0$ is also the initial object of~$\Par C$.
\begin{point}{30}{Beware}%
While cotupling in~$C$ and~$\Par C$ coincide:
$[f,g]_{C} = [f,g]_{\Par C}$
for any (properly typed) partial maps~$f,g$
and $\widehat{f+_C g} = \hat{f} +_{\Par C} \hat{g}$,
    however, in general
    \begin{equation*}
    [\kappa_1 \after f, \kappa_2 \after g] \ =\  f+_C g \ \neq\  f +_{\Par C} g
        \ =\  [[\kappa_1,\kappa_3] \after f,
            [\kappa_2, \kappa_3] \after g].
    \end{equation*}
\end{point}
\end{point}
\spacingfix{}
\begin{point}{40}[par-pullbacks]{Proposition}%
Let~$C$ be an effectus in total form.
Squares of the following form are pullbacks in~$\Par C$.
\begin{equation*}
    \xymatrix{
        X+A \pullback \ar@^{>}[r]^{\id+\hat{f}} \ar@^{>}[d]_{\hat{g} + \id}
        & X+B \ar@^{>}[d]^{\hat{g}+\id}
        \\ Y+A \ar@^{>}[r]_{\id+\hat{f}}
        & Y+B
    } \qquad
    \xymatrix{
        A+X \pullback \ar@^{>}[r]^{\hat{f}+\id} \ar@^{>}[d]_{\pproj_1}
        & B+X \ar@^{>}[d]^{\pproj_1}
        \\ A \ar@^{>}[r]_{\hat{f}}
        & B
    }
\end{equation*}
\spacingfix{}
\begin{point}{50}{Proof}%
(A different proof for the pullback on the right
    is given in \cite[lem.~4.1(5)]{kentapartial}.)
It is sufficient to show that the following squares
    are pullbacks in~$C$.
\begin{equation*}
    \xymatrix{
        X+(A+1) \ar[r]^{\id + (f+\id)} \ar[d]_{g+ \id}
        & X+(B+1) \ar[d]^{g+\id}
        \\ Y+(A+1) \ar[r]_{\id+(f +\id)}
        & Y+(B+1)
    } \qquad
    \xymatrix{
        A+(X+1) \ar[r]^{f+\id} \ar[d]_{\id+!}
        & B+(X+1)  \ar[d]^{\id+!}
        \\ A+1 \ar[r]_{f+\id}
        & B+1
    }
\end{equation*}
These are indeed pullbacks by~\sref{tot-pullbacks}. \qed
\end{point}
\end{point}
\begin{point}{60}[zero-and-one-parc]{Definition}%
Assume~$C$ is an effectus in total form.
For arbitrary objects~$X,Y$ in~$C$,
    write~$\Define{0} \equiv \kappa_2 \after !\colon X \to Y+1$
    and~$\Define{1} \equiv \kappa_1 \after ! \equiv \hat! \colon X \to 1+1$.
    \cite{kentapartial}
\end{point}
\begin{point}{70}[toteff-zero]{Exercise}%
    Show~$0$ is a zero object in~$\Par C$
        with unique zero map
        as in \sref{zero-and-one-parc}.
\end{point}
\begin{point}{80}[pardp]{Proposition}%
Assume~$C$ is an effectus in total form
    and~$f$ is a map in~$\Par C$.
\begin{enumerate}
\item
If~$1 \hafter f = 1$,
    then~$f = \hat{g}$ for a unique~$g$ in~$C$.
\item
If~$1 \hafter f = 0$, then~$f = 0$.
\end{enumerate}
\spacingfix{}
\begin{point}{90}{Proof}%
    (This proof is essentially
        the same as \cite[lem.~4.7(1) \& prop.~4.6]{kentapartial}.)
Both points follow from the right pullback square of~\eqref{pullbacks}
 as follows.
\begin{equation*}
    \xymatrix@R-.8pc{
    X \ar@{.>}[rd]|g
    \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_f
        \\& Y \pullback
        \ar[r]_{!}
        \ar[d]^{\kappa_1}
    & 1
        \ar[d]^{\kappa_1}
    \\& Y+1
        \ar[r]_{!+!}
&1+1
}
\qquad
    \xymatrix@R-.8pc{
        X \ar@{.>}[rd]|{!}
    \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_f
        \\& 1 \pullback
        \ar[r]_{!}
        \ar[d]^{\kappa_2}
    & 1
        \ar[d]^{\kappa_2}
    \\& Y+1
        \ar[r]_{!+!}
&1+1
}
\end{equation*}
If~$1 \hafter f = 1$, then~$(!+!)\after f = \kappa_1 \after !$
    and so there is a unique~$g$ with~$f = \kappa_1 \after g$
    as shown above on the left.
For the other point, if~$1 \hafter f = 0$,
    then~$(!+!)\after f = \kappa_2 \after !$
    and so~$f = \kappa_2 \after !$ as shown above on the right. \qed
\end{point}
\end{point}
\begin{point}{100}[pproj-joint-monicity]{Proposition}%
    Assume~$C$ is an effectus in total form.
    The partial projectors~$\pproj_1 \equiv [\id,0]$
        and~$\pproj_2 \equiv [0, \id]$
        are jointly monic in~$\Par C$.
        \cite[lem.~4.1(4)]{kentapartial}
\begin{point}{110}{Proof}%
    (This is a new proof.)
Consider the following diagram in~$\Par C$.
\begin{equation*}
\xymatrix {
    X+Y \pullback
    \ar@/^1.5pc/[rr]^{\pproj_1}
    \ar@/_3pc/[dd]_{\pproj_2}
        \ar@^{>}[r]^{\id+\hat!}
        \ar@^{>}[d]_{\hat! + \id}
& X+1 \pullback
        \ar@^{>}[r]^{\pproj_1}
        \ar@^{>}[d]^{\hat! + \id}
& X
        \ar@^{>}[d]^{\hat!}
\\ 1+Y \pullback
        \ar@^{>}[r]_{\id+\hat!}
        \ar@^{>}[d]_{\pproj_2}
& 1+1
        \ar@^{>}[r]_{\pproj_1}
        \ar@^{>}[d]^{\pproj_2}
& 1
\\ Y
        \ar@^{>}[r]_{\hat!}
& 1
}
\end{equation*}
This diagram commutes and
    each of the inner squares is a pullback by~\sref{par-pullbacks}.
The maps~$\pproj_1,\pproj_2\colon 1 + 1 \pto 1$
    are jointly monic,
    which is a reformulation
    of the joint monicity axiom of an effectus in total form.
Thus by \sref{joint-monicity-stable}
    the outer~$\pproj_1$ and~$\pproj_2$ are jointly monic. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{1870}%
\begin{point}{10}[eff-total-to-partial]{Theorem}%
If~$C$ is an effectus in total form,
    then~$\Par C$ is an effectus in partial form. \cite[thm.~4.2]{kentapartial}
\begin{point}{20}{Proof}%
In \sref{par-c-coprod}, we saw that~$\Par C$ has finite coproducts.
\begin{point}{30}{$\mathsf{PCM}$-enrichment, I}%
Assume~$f,g \colon X \pto Y$.
We define that~$f \perp g$
    iff there is a \Define{bound}~$b\colon X \pto Y+Y$
    \index{bound}
    with~$\pproj_1 \hafter b = f$
    and~$\pproj_2 \hafter b = g$.
    (By \sref{pproj-joint-monicity}
    this~$b$ is unique if it exists.)
In this case, define~$f \ovee g = \nabla \hafter b$,
where $\Define{\nabla} \equiv [\id,\id]$.
    \index{*nabla@$\nabla$}
We will show~$\ovee$ with~$0$
    as defined in \sref{zero-and-one-parc}
    forms a PCM.
Partial commutativity is obvious.
The map~$\kappa_1 \hafter f\colon X \pto Y+Y$
    is a bound for~$f \perp 0$ and
    so~$f \ovee 0 = \nabla \hafter \kappa_1 \hafter f = f$,
    which shows~$0$
    is indeed a zero for~$\ovee$.
Only partial associativity remains.
Assume~$f \perp g$ via bound~$b$
and~$f \ovee g \perp h$ via bound~$c$.
Note~$\nabla \hafter b = f \ovee g = \pproj_1 \hafter c$
and thus by the right pullback square of \sref{par-pullbacks} (see diagram below),
    there is a unique~$d\colon X \pto (Y+Y)+Y$
    with~$\pproj_1 \hafter d = b$ and~$(\nabla +\id)\hafter d = c$.
\begin{equation*}
    \xymatrix@R-.8pc{
    X \ar@^{.>}[rd]|d
        \ar@/^1pc/[rrd]^c
        \ar@/_1pc/[rdd]_b
        \\& (Y+Y)+Y \pullback
        \ar@^{>}[r]_{\nabla+\id}
        \ar@^{>}[d]^{\pproj_1}
    & Y+Y
        \ar@^{>}[d]^{\pproj_1}
    \\& Y+Y
        \ar@^{>}[r]_{\nabla}
&Y
}
\end{equation*}
The map $(\pproj_2 + \id) \hafter d$
    is a bound for~$g \perp h$,
    indeed:
\begin{align*}
    \pproj_1 \hafter (\pproj_2 + \id) \hafter d
    & \ =\  \pproj_2 \hafter \pproj_1 \hafter d 
    & \pproj_2 \hafter (\pproj_2 + \id) \hafter d
    & \ =\  \pproj_2 \hafter d
    \\
    &\ =\  \pproj_2 \hafter b
    && \ =\  \pproj_2 \hafter (\nabla + \id) \hafter d
    \\
    & \ =\  g
    && \ = \ \pproj_2 \hafter c\\
    &&& \ = \ h.
\end{align*}
We need one more:
    $[\id,\kappa_2]\hafter d$ is a bound for~$f \perp g \ovee h$, indeed
\begin{align*}
    \pproj_1 \hafter [\id,\kappa_2] \hafter d
        & \ = \ \pproj_1 \hafter \pproj_1 \hafter d
    & \pproj_2 \hafter [\id,\kappa_2]\hafter d & \ =\ \nabla \hafter (\pproj_2 + \id) \hafter d \\
        & \ = \ \pproj_1 \hafter b
        && \ =\  g \ovee h \\
        & \ = \ f.
\end{align*}
Finally,
we compute
\begin{equation*}
f \ovee (g \ovee h)
\ = \ \nabla \hafter [\id, \kappa_2] \hafter d
\ = \ \nabla \hafter (\nabla+ \id) \hafter d
\ = \ \nabla \hafter c
\ = \ (f \ovee g) \ovee h,
\end{equation*}
which shows the partial associativity.
Homsets of~$\Par C$ are indeed PCMs.
\end{point}
\begin{point}{40}{$\mathsf{PCM}$-enrichment, II}%
Assume~$f \perp g$ with bound~$b$.
It is easy to see~$b \hafter k$
    is a bound for~$f \hafter k \perp g \hafter k$
    and consequently~$(f \hafter k) \ovee (g \hafter k)
                = \nabla \hafter b \hafter k = 
                (f \ovee g) \hafter k$.
For the other side:
$(h + h) \hafter b$ is a bound for~$h \hafter f \perp h \hafter g$,
    indeed
\begin{align*}
    \pproj_1 \hafter (h+h) \hafter b
    &\ = \ 
    h\hafter \pproj_1 \hafter b \ =\  h \hafter f \\
    \pproj_2 \hafter (h+h) \hafter b
    &\ = \ 
    h\hafter \pproj_2 \hafter b\  =\  h \hafter g.
\end{align*}
And so~$(h \hafter f) \ovee (h \hafter g)
            = \nabla \hafter (h+h) \hafter b
            = h \hafter \nabla \hafter b = h \hafter (f \ovee g)$.
\end{point}
Finally, the zero axiom holds by~\sref{toteff-zero}.
\begin{point}{50}{FinPAC}%
We just saw~$\Par C$ is $\mathsf{PCM}$-enriched.
We already know~$\Par C$ has coproducts.
The compatible sum axiom holds by definition of~$\perp$.
To show~$\Par C$ is a finPAC,
    only the untying axiom remains to be proven.
If~$f \perp g$ with bound~$b$,
then~$(\kappa_1 + \kappa_2) \hafter b$ is a bound for~$\kappa_1 \hafter f
    \perp \kappa_2 \hafter g$,
    which proves the untying axiom.
\end{point}
\begin{point}{60}{Effect algebra of predicates}%
Pick any predicate~$p \colon X \to 1+1$.
We define~$p^\perp = [\kappa_2,\kappa_1]\after p$.
($p^\perp$ is~$p$ with swapped outcomes.)
We compute
\begin{align*}
    \pproj_1 \hafter \hat{p}
    &\ = \ [\id,\kappa_2]\after\kappa_1 \after p
        \  = \ p \\
        \pproj_2 \hafter \hat{p}
    &\ = \ [[\kappa_2, \kappa_1],\kappa_2]\after\kappa_1 \after p
        \  = \ [\kappa_2,\kappa_1]\after p \\
    \nabla \hafter \hat{p}
    &\ = \ [[\kappa_1,\kappa_1],\kappa_2]\after\kappa_1 \after p
        \  = \ \kappa_1 \after ! \ = \ 1.
\end{align*}
So~$\hat{p}$ is a bound for~$p \perp p^\perp$
and~$p \ovee p^\perp = 1$.
To show~$p^\perp$ is the unique orthocomplement,
    assume~$p \ovee q = 1$ for some~$q$ via a bound~$b\colon
        X \pto 1+1$.
Note~$1 \hafter b =\nabla \hafter b = 1$
    and so by \sref{pardp}
    we know~$b = \hat{c}$ for some~$c\colon X \to 1+1$.
    And so~$p = \pproj_1 \hafter b = [\id, \kappa_2]\after \kappa_1 \after c
                    = c$. Hence
\begin{equation*}
q \ =\  \pproj_2 \hafter b \ =\  [[\kappa_2, \kappa_1],\kappa_2] \after
    \kappa_1\after c \ =\  [\kappa_2,\kappa_1]\after p \ =\  p^\perp.
\end{equation*}
To show~$\Pred X$ is an effect algebra,
it only remains to be proven that the zero--one axiom holds.
So assume~$1 \perp p$ via some bound~$b$. We must show~$p=0$.
By the following instance of the right pullback square of~\eqref{pullbacks},
    we see~$b = \kappa_1 \after \kappa_1 \after !$.
\begin{equation*}
    \xymatrix@R-.8pc{
        X \ar@{.>}[rd]|{!}
    \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_b
        \\& 1 \pullback
        \ar@{=}[r]
        \ar[d]^{\kappa_1\after\kappa_1}
    & 1
        \ar[d]^{\kappa_1}
        \\& (1+1)+1
        \ar[r]_{[\id,\kappa_2]}
&1+1
}
\end{equation*}
Hence~$p = \pproj_2 \hafter b = [[\kappa_2,\kappa_1],\kappa_1]\after
                        \kappa_1 \after \kappa_1 \after ! = \kappa_2 \after ! = 0$.
\end{point}
\begin{point}{70}{Final axioms}%
In \sref{pardp} we proved that~$f = 0$ whenever~$1 \hafter f = 0$.
It only remains to be shown that~$f \perp g$
    provided~$1 \hafter f \perp 1 \hafter g$.
Let~$b$ be a bound for~$1 \hafter f \perp 1 \hafter g$.
We apply the right pullback square of \sref{par-pullbacks}
    twice  in succession as follows
    (using~$\pproj_2 \hafter c
                = \pproj_2 \hafter (\hat{!} + \id) \hafter c
                = \pproj_2 \hafter b = 1\hafter g$ for the right one.)
\begin{equation*}
    \xymatrix@R-.8pc{
        X \ar@^{.>}[rd]|{c}
    \ar@/^1pc/[rrd]^{b}
        \ar@/_1pc/[rdd]_f
        \\& Y+1 \pullback
        \ar@^{>}[r]^{\hat! + \id}
        \ar@^{>}[d]^{\pproj_1}
    & 1+1
        \ar@^{>}[d]^{\pproj_1}
        \\& Y
        \ar@^{>}[r]_{\hat!}
&1
} \qquad
    \xymatrix@R-.8pc{
        X \ar@^{.>}[rd]|{d}
    \ar@/^1pc/[rrd]^{c}
        \ar@/_1pc/[rdd]_g
        \\& Y+Y \pullback
        \ar@^{>}[r]^{\id + \hat!}
        \ar@^{>}[d]^{\pproj_2}
    & Y+1
        \ar@^{>}[d]^{\pproj_2}
        \\& Y
        \ar@^{>}[r]_{\hat!}
&1
}
\end{equation*}
Clearly~$\pproj_2 \hafter d = g$
    and~$
    \pproj_1 \hafter d
     =  \pproj_1 \hafter (\id + \hat! )\hafter d
     =  \pproj_1 \hafter c  =  f$, so~$d$ is a bound for~$f \perp g$,
     as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}
\begin{parsec}{1880}%
\begin{point}{10}%
We are ready to show the equivalence of effectuses in partial and total form.
\begin{point}{20}[proof-cho-thm]{Proof of \sref{cho-thm}}%
Let~$C$ and~$D$ be effectuses in total and respectively partial form.
The first point, that~$\Par C$ is an effectus in partial form,
    is shown in \sref{eff-total-to-partial}.
The second point, that~$\Tot D$ is an effectus in total form,
    is shown in \sref{eff-partial-to-total}.
It remains to be shown that nothing is lost.
\begin{point}{30}{$\Par \Tot D \cong D$}%
Let~$D$ be an effectus in partial form.
A map~$f\colon X \to Y$ in~$\Par \Tot D$
    is by definition a map~$f\colon X \to Y+1$
        in~$D$ with~$1 \after f= 1$.
Let~$P \colon \Par \Tot D \to D$
    denote the identity-on-objects map~$f \mapsto \pproj_1 \after f$.
This is a functor: clearly~$P\hat\id = P\kappa_1 = \id $ and
    if~$g\colon Y \to Z$ in~$\Par\Tot D$, then
\begin{align*}
    \pproj_1 \after (g \hafter f) & \ = \ 
    \pproj_1 \after [g, \kappa_2] \after f \\
    & \ = \ [\pproj_1 \after g, \pproj_1 \after \kappa_2] \after f \\
    & \ = \ [\pproj_1 \after g,  0] \after 
                \langle \pproj_1 \after f, \pproj_2 \after f\rangle \\
                & \ = \ \pproj_1 \after g  \after \pproj_1 \after f.
\end{align*}
The functor~$P$ is an isomorphism with inverse~$P' f \equiv \langle f, (1 \after f)^\perp\rangle$.
Indeed, we have
    $P P' f = \pproj_1 \after \langle f, (1 \after f)^\perp \rangle = f $
and
\begin{equation*}
    P' P f  \ =\  \langle \pproj_1 \after f, (1 \after \pproj_1 \after f)^\perp\rangle \ =\  (\kappa_1 \after \pproj_1 \after f) \ovee (\kappa_2 \after \pproj_1 \after f)^\perp\ =\  f.
\end{equation*}
\spacingfix{}
\begin{point}{40}{$\Tot \Par C \cong C$}%
Assume~$C$ is an effectus in total form.
Recall~$1 \hafter \hat{g} = 1$
and~$\smash{\widehat{f \after g}} = \hat{f} \hafter \hat{g}$,
    so~$Q\colon C \to \Tot \Par C$
    given by~$Q g = \hat{g}$ is an identity-on-objects functor.
It is an isomorphism by the first part of \sref{pardp}:
    for every~$f$ in~$\Tot \Par C$,
    there is a unique~$g$ in~$C$
    with~$f = \hat{g}$. \qed
\end{point}
\end{point}
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{1890}%
\begin{point}{10}[distinction-part-tot-eff]{Exercise}%
In this exercise we will
    distinguish effectuses in total and partial form.
\begin{enumerate}
\item
To start, show that the initial object of an effectus in total form is strict
    --- that is: show that any map into~$0$ is an isomorphism.
    (Hint: use the right pullback square of~\sref{tot-pullbacks}
        with~$X=Y=0$.)
\item
Conclude that if~$C$ is both an effectus in total and partial form,
then every object in~$C$ is isomorphic to~$0$.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{20}[eff-convention]{Convention}%
For the remainder of this text, we will work with effectuses in partial form
    and write~$1$ instead of~$I$.
To spare ink, a phrase like ``let $C$ be an \Define{effectus}''
    \index{effectus}
should be read as~``let $C$ be an effectus in partial form''
and simply~``$C$ is an effectus'' means either ``$C$ is an effectus in total form''
    or ``$C$ is an effectus in partial form''.
(In non-trivial cases, this
    is unambiguous, as seen in \sref{distinction-part-tot-eff}.)
As before, when we took the effectus in partial form as base category,
    we will denote partial maps by~$f\colon X \to Y$
    (instead of~$f\colon X \pto Y$)
        and their composition as~$f \after g$
        (instead of~$f \hafter g$).
\end{point}
\end{parsec}

\begin{parsec}{1891}%
\begin{point}{10}[effexamplesintro]{Examples}%
Our main example of an effectus (in total form)
    is the category~$\op\vN$ of von Neumann algebras with
    ncpu-maps between them in the opposite direction,
        see~\sref{effectus-vn}.
Its full subcategory~$\op\CvN$ of commutative von Neumann algebras
    is an effectus as well. \index{CvN@$\CvN$}
\begin{point}{20}%
In~\cite{effintro} several other examples of effectuses are
    discussed in detail:
\begin{enumerate}
\item
    The category~$\op\OUS$ of order unit spaces
        (i.e.~ordered real vector spaces with distinguished order unit)
        with positive unit-preserving linear maps in the opposite
        direction is an effectus (in total form). \index{OUS@$\OUS$}
\item
    A related example is the category~$\op\OUG$ of order unit groups
        (i.e.~ordered abelian groups with distinguished order unit)
        with positive
        unit-preserving homomorphisms in the opposite direction,
        which is also an effectus. \index{OUG@$\OUG$}
\item
    Every extensive category~\cite{carboni1993introduction}
        with final object is an effectus in total form.
    Examples of extensive categories with final object
            include
    \begin{enumerate}
        \item $\SET$, the category
            of sets with maps between them; \index{Set@$\SET$}
        \item $\op\CRng$, the category
            of commutative unit rings with unit-preserving
            homomorphisms between them
            in the opposite direction; \index{CRng@$\CRng$}
        \item $\bCH$, the category of
            compact Hausdorff spaces with continuous maps
            between them; \index{CH@$\bCH$} \emph{and}
    \end{enumerate}
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{30}%
    Together with van de Wetering, we recently investigated~\cite{eja}
    the category~$\op\EJA$ of Euclidean Jordan algebras
    with positive unit-preserving linear maps
    in the opposite direction, which is also an effectus (in total form).
\end{point}
\end{point}
\end{parsec}

\subsection{Predicates, states and scalars}
\begin{parsec}{1900}%
\begin{point}{10}%
We turn to the internal structures of an effectus.~\cite{effintro}
\end{point}
\begin{point}{20}[dfn-mandso]{Definition}%
Let~$C$ be an effectus (in partial form).
\begin{enumerate}
\item
As alluded to in the definition of an effectus in partial form,
a \Define{predicate} on~$X$ is a map~$X \to 1$.
        \index{predicate}
The set of predicates~$\Pred X$ on~$X$ is (by definition of an effectus
    in partial form) an effect algebra.
\item
A \Define{scalar} is a predicate on~$1$; that is, a map~$1 \to 1$.
        \index{scalar}
We write~$\Define{\Scal C} \equiv \Define{M} \equiv \Pred 1$ for the set of scalars.
        \index{$M$}
        \index{ScalC@$\Scal C$}
We multiply two scalars~$\lambda,\mu \colon 1 \to 1$
    simply by composing~$\lambda \odot \mu \equiv \lambda \after \mu$.
As~$1_M = \id_M$ (see \sref{one-m-is-id}) and~$C$ is $\mathsf{PCM}$-enriched,
    the set of scalars~$M$ with~$\odot$
    is an effect monoid,
    see \sref{dfn-effect-monoid}.
\item
A \Define{real effectus} is an effectus
        \index{effectus!real}
where the set of scalars~$M$ is isomorphic (as effect monoid) to~$[0,1]$.
\item
For a scalar~$\lambda\colon 1\to 1$ and a predicate~$p\colon X \to 1$,
we write~$\Define{\lambda \cdot p} \equiv \lambda \after p$.
        \index{*lambdacdot@$\lambda \cdot p$}
Again due to $\mathsf{PCM}$-enrichment and~$1_M = \id_M$,
this scalar multiplication
turns~$\Pred X$ into an~$M$-effect module, see \sref{dfn-effect-module}.
\item
For~$f\colon X \to Y$ in~$C$,
        define~$\Define{\Pred(f)} \colon \Pred Y \to \Pred X$
        \index{Pred@$\Pred(f)$}
    by~$\Pred(f)(p) = p \after f$.
It is easy to see
$\Pred(f)$ is an~$M$-effect module homomorphism
if~$f$ is total
and that, in fact,~$\Pred\colon \Tot C \to \mathsf{EMod}^{\mathsf{op}}_M$
is a functor.
\item
A \Define{substate} on~$X$ is a map~$\omega\colon 1 \to X$.
A \Define{state} is a total substate.
        \index{state}
        \index{state!sub-}
We denote the set of states on~$X$ by~$\Define{\Stat X}$.
        \index{StatX@$\Stat X$}
\item
An effectus~$C$ has \Define{separating predicates}
    \index{separating!predicates}
        if~$\Pred X$ (as a set of maps~$X \to 1$)
        is jointly monic for every~$X$ in~$C$.
    Similarly, an effectus has \Define{separating states}
        \index{separating!states}
        if~$\Stat X$ (as a set of maps~$1 \to X$)
        is jointly epic for every~$X$ in~$C$.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{30}{Examples}%
    The category~$\op\vN$ (see \sref{effectus-vn})
    is a real effectus ($M \cong [0,1]$)
    with separating states and predicates.~\cite{effintro}
The predicates on a von Neumann algebra~$\scrA$
    correspond to the set of effects~$[0,1]_\scrA$
    and~$\Stat \scrA$ can be identified with the convex set of normal states.
\begin{point}{40}%
We briefly cover the examples from~\cite{effintro}
    mentioned in~\sref{effexamplesintro}.
\begin{enumerate}
\item
The category~$\op\OUS$ (see~\sref{effexamplesintro})
    is a real effectus with separating predicates,
    but without seperating states.
    (The states on a single order unit space are separating
        if and only if the order unit space is archimedean.)
A predicate on an order unit space~$X$
    corresponds  to a point~$x \in X$ with~$0 \leq x \leq 1$,
    where~$1$ is the distinguished order unit.
The states are exactly what are called states for order unit spaces
    in the literature.
\item
The category~$\op\OUG$  (see~\sref{effexamplesintro})
    has the two-element effect monoid~$2$ as scalars
        and seperating predicates.
The predicates of an order unit group~$G$ correspond
    to the elements~$x \in G$ with~$0 \leq x \leq 1$,
        where~$1$ is the distinguished order unit.
States on~$G$ correspond to unit-preserving positive
    homomorphisms~$G \to \Z$, which are not separating.
\item
Any extensive category with final object
    (such as~$\SET$, $\op\CRng$ and $\bCH$)
    has as scalars the two-element effect monoid~$2$.
\begin{enumerate}
\item
In~$\SET$ the predicates on a set~$X$ correspond to subsets~$U \subseteq X$
        and are thus separating. States on~$X$ correspond t
        elements~$x \in X$, which are also separating.
\item
In~$\op\CRng$ the predicates on~$R$ correspond to idempotents of~$R$,
    which are not separating.
        States correspond to unit-preserving
            homomorphisms~$R \to \Z$, which are not separating either.
\item
In~$\bCH$ the predicates on~$X$ correspond to clopen subsets~$U \subseteq X$,
    which are not separating.
States correspond on~$X$ correspond to its points~$x \in X$,
    which are separating.
\end{enumerate}
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{50}%
The category~$\op\EJA$ is a real effectus with separating states
    and predicates. The predicates on an Euclidean Jordan algebra (EJA)~$E$
    correspond to its effects; i.e.~the elements~$0 \leq a \leq 1$.
    The states are exactly what are usually considered
    states for EJAs.
\end{point}
\end{point}
\end{parsec}
\begin{parsec}{1910}%
\begin{point}{10}%
Does every effect monoid~$M$ occur as the effect monoid of scalars of some
    effectus?  Does every $M$-effect module occur as
        effect module of predicates?
We will show they do, in the following strong sense.
\end{point}
\begin{point}{20}[emod-effectus]{Theorem}%
    Let~$M$ be any effect monoid.
    The category~$\EMod^{\mathsf{op}}_M$ is an effectus in total form
        with scalars~$M$ and separating predicates.~\cite{effintro}
In fact: every effectus~$C$ in total form
    with scalars~$M$ and separating predicates
    is equivalent to a subcategory of~$\EMod^{\mathsf{op}}_M$.
\begin{point}{30}{Proof}%
To show~$\EMod^{\mathsf{op}}_M$ is an effectus,
    we have to show the dual  axioms for~$\EMod_M$.
\begin{point}{40}{Finite products}%
For every~$M$-effect module~$E$,
    there is a unique $M$-effect module map~$!\colon M \to E$,
    which is given by~$\lambda \mapsto \lambda \cdot 1$.
So~$M$ is the initial object of~$\EMod_M$.
The one-element $M$-effect module~$\{0=1\}$ is the final object.

If~$E$ and $F$ are~$M$-effect modules,
    then the set of pairs~$E \times F$
    with componentwise operations
    is again an~$M$-effect module.
The effect module~$E \times F$
    with obvious projections~$E \xleftarrow{\pi_1} E \times F \xrightarrow{\pi_2} F$
    is the categorical product of~$E$ and~$F$ in~$\EMod_M$
    (as is the case with effect algebras, see \sref{ea-product}).
\end{point}
\begin{point}{50}{Pushout diagrams}%
To show the pushout diagrams corresponding to \eqref{pullbacks} hold,
assume we are given $M$-effect modules~$E,F,G$
    with module maps~$\alpha,\beta,\delta$
    that make the  outer squares of the following diagrams commute.
\begin{equation*}
    \xymatrix{
    G\\
    & E \times F \ar@{.>}[lu]
    & E \times M \ar[l]^{\id\times !}
    \ar@/_1pc/[llu]_{\alpha}
    \\& M \times F \ar[u]_{! \times \id}
    \ar@/^1pc/[luu]^{\beta}
    & M \times M \ar[l]^{\id\times!} \ar[u]_{! \times \id}
    } \qquad
    \xymatrix{
    G\\
    & E \ar@{.>}[lu]
    & M \ar[l]^{!}
    \ar@/_1pc/[llu]_{!}
    \\& E \times F \ar[u]_{\pi_1}
    \ar@/^1pc/[luu]^{\delta}
    & M \times M \ar[l]^{!\times!} \ar[u]_{\pi_1}
    }
\end{equation*}
    We have to show that there are unique dashed arrows (as shown)
    that make these diagrams commute.
We start with the left diagram.
By assumption~$\alpha \after (! \times \id) = \beta \after (\id \times !)$,
    so in particular~$\alpha(1,0) = \beta(1,0)$.
    For any~$(x,y) \in E \times F$,
        we have~$\alpha(x,0) \leq \alpha(1,0) = \beta(1,0)
            \perp \beta(0,1) \geq \beta(0,y)$,
            so~$\alpha(x,0) \perp \beta(0,y)$.
Define~$f\colon E\times F \to G$
    by~$f(x,y) = \alpha(x,0) \ovee \beta(0,y)$.
    It is easy to see~$f$ is (partially) additive
    and~$f(1,1) = \alpha(1,0) \ovee \beta(0,1) = \beta(1,1)=1$,
    so~$f$ is a module map.
We compute
\begin{equation*}
    f(x, \lambda \cdot 1)
\ = \ \alpha(x,0) \ovee \beta(0,\lambda \cdot 1)
\ = \ \alpha(x,0) \ovee \lambda \cdot \alpha(0, 1)
\ = \ \alpha(x,\lambda)
\end{equation*}
and so~$f \after (\id \times !) = \alpha$.
Similarly~$\beta = f \after (! \times \id)$.
It is easy to see~$f$
is the unique map with~$f \after (\id \times !) = \alpha$
and~$\beta = f \after (! \times \id)$
and so the left square of \eqref{pullbacks}
    is a pullback in~$\EMod_M^{\mathsf{op}}$.

Concerning the right diagram:
    as~$\delta \after (!\times!) = ! \after \pi_1$,
    we have~$\delta(\lambda \cdot 1, \mu \cdot 1) = \lambda \cdot 1$
    and so~$\delta(0, y) \leq \delta(0,1) = 0$.
    Hence~$\delta(x,y) = \delta(x,0)$.
Define~$g\colon E \to G$ by~$g(x) = \delta(x,0)$.
Clearly~$g$ is additive, $g(1) = \delta(1,0) = \delta(1,1) = 1$
    and~$\delta = g \after \pi_1$ by definition.
Obviously~$g$ is the unique such map.
Thus the right square of~\eqref{pullbacks}
    is a pullback in~$\EMod_M^{\mathsf{op}}$.
\end{point}
\begin{point}{60}{Joint epicity}%
To show~$\EMod^{\mathsf{op}}_M$ is an effectus,
    it only remains to be shown
    that~$
    \langle \pi_1, \pi_2, \pi_2\rangle,
    \langle \pi_2, \pi_1, \pi_2\rangle\colon M \times M \to M \times M \times M
    $ are jointly epic.
So assume~$f,g\colon M \times M \times M \to E$
    are two $M$-effect module maps
    with~$
        f \after \langle \pi_1,\pi_2,\pi_2\rangle =
        g \after \langle \pi_1,\pi_2,\pi_2\rangle$
        and~$
        f \after \langle \pi_2,\pi_1,\pi_2\rangle =
        g \after \langle \pi_2,\pi_1,\pi_2\rangle$.
From the first equality, it follows that~$f(1,0,0) = g(1,0,0)$.
The other one implies~$f(0,1,0) = g(0,1,0)$.
Thus~$f(0,0,1) = f(1,1,0)^\perp = g(1,1,0)^\perp = g(0,0,1)$.
As for~$(\lambda_1,\lambda_2,\lambda_3) \in M^3$,
we have~$(\lambda_1,\lambda_2,\lambda_3)
            = \lambda_1 \cdot(1,0,0)
                \ovee \lambda_2\cdot (0,1,0)
                \ovee \lambda_3\cdot (0,0,1)$
    we get~$f=g$.
\end{point}
\begin{point}{70}{Representation}%
Let~$C$ be an effectus in total form.
Clearly $\Pred f = \Pred g $ (for~$f,g\colon X \to Y$ in~$C$)
if and only if~$p \after f = (\Pred f)(p)= (\Pred g)(p) = p \after g$
for every~$p \in \Pred X$.
Thus the functor~$\Pred\colon C \to \EMod^{\mathsf{op}}_M$
    is faithful if and only if~$C$ has separating predicates.
So if~$C$ has separating predicates,
    $C$ is equivalent to the subcategory~$\Pred C$
    of~$\EMod_M^{\mathsf{op}}$.
\end{point}
    \qed
\end{point}
\end{point}
\begin{point}{80}[exc-rng-eff]{Exercise}%
    Show that the category~$\op\Rng$ of unit rings \index{Rng@$\Rng$}
    with unit-preserving homomorphisms in the opposite direction
    is an effectus in total form.
\begin{enumerate}
    \item 
        Show that the predicates on a ring~$R$
            correspond to its idempotents;
            that~$p \perp q$ iff~$pq = qp = 0$,
            $p^\perp = 1-p$
            and~$p \ovee q = p+q$.
        (So~$2$ is its effect monoid of scalars.)
        Conclude~$\op\Rng$ does not have separating predicates.
    \item
        Show that there is no unit-preserving
            ring-homomorphism~$\Z_2 \to \Z$.
            Conclude~$\op\Rng$ does not have separating states.
\end{enumerate}
\spacingfix{}
\end{point}
\end{parsec}
\begin{parsec}{1920}%
\begin{point}{10}%
We studied the structure of predicates in an effectus.  What about the states?
They will turn out to form an abstract~$M$-convex set.
Before we define these, we introduce a generalized distribution monad.
\end{point}
\begin{point}{20}{Definition}%
Let~$M$ be an effect monoid
    and~$X$ be any set.
A \Define{formal $M$-convex combination} over~$X$
    \index{convexcombination@(formal) $M$-convex combination}
    is a function~$p\colon X \to M$
    with finite support
    such that~$\bigovee_{x \in X} p(x) = 1$.
We use~$\Define{\lambda_1 \ket{x_1} \ovee \cdots \ovee \lambda_n \ket{x_n}}$
    as a shorthand for the formal $M$-convex combination~$p\colon X \to M$
    given by~$p(x) = \bigovee_{x_i = x} \lambda_i$.
    (So~$p(x_i) = \lambda_i$ if the~$x_i$ are distinct.)
We write~$\Define{\mathcal{D}_M} X$
    \index{$\mathcal{D}_M$}
    for the set of all formal~$M$-convex combinations over~$X$.~\cite{probdistrconv}
\end{point}
\begin{point}{30}[exc-dm-effectus]{Exercise*}%
    In this exercise you study~$\mathcal{D}_M$ as a monad.
    See \cite{probdistrconv,basmsc}.
\begin{enumerate}
\item
For~$f\colon X \to Y$,
    define~$\mathcal{D}_M f \colon \mathcal{D}_M X \to \mathcal{D}_M Y$
    by
    \begin{equation*}
    (\mathcal{D}_M f)(p)(y) \ =\  \bigovee_{x; f(x)=y} p(x).
    \end{equation*}
    (That is: $(\mathcal{D}_M f) (\lambda_1 \ket{x_1} \ovee \cdots
            \ovee \lambda_n \ket{x_n})
            = \lambda_1 \ket{f(x_1)} \ovee \cdots
            \ovee \lambda_n \ket{f(x_n)} $.)
Show that this turns~$\mathcal{D}_M$ into a functor~$\mathsf{Set} \to \mathsf{Set}$.
\item
Define~$\eta \colon X \to \mathcal{D}_M X$
    by~$\eta(x) = 1\ket{x}$
    and~$\mu\colon \mathcal{D}_M \mathcal{D}_M X \to \mathcal{D}_M X$ by
    \begin{equation*}
        \mu(\Phi)(x) \ = \ 
        \bigovee_{\varphi}
        \Phi(\varphi) \odot \varphi(x).
    \end{equation*}
(That is: 
        $\mu (\bigovee_i \sigma_i \ket{\bigovee_j \lambda_{ij} \ket{x_{ij}}})
            = \bigovee_{i,j} (\sigma_i \odot \lambda_{ij})\ket{x_{ij}}$.)\\
Show that~$(\mathcal{D}_M, \eta,\mu)$
    is a monad.
\item
    Show that~$\Kl \mathcal{D}_M$,
    the Kleisli category of~$\mathcal{D}_M$
    (see e.g.~\cite[\S 2.6]{basmsc}),
    is an effectus
    with~$M$ as scalars.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{40}{Definition}%
Let~$X$ be a set together
    with a map~$h\colon \mathcal{D}_M X \to X$.
We say~$(X,h)$ is an \Define{abstract $M$-convex set}
    \index{convex@(abstract) $M$-convex set}
    provided~$h(\ket{x})=x$
    and
\begin{equation}\label{convex-mult}
    h \Bigl( \bigovee_{i,j} \sigma_i \odot \lambda_{ij} \ket{x_{ij}} \Bigr)
    \ = \ 
    h \Bigl( \bigovee_i \sigma_i \, \ket{
        h\bigl(\, \bigovee_j \lambda_{ij} \ket{x_{ij}}\, \bigr)
    } \, \Bigr)
\end{equation}
for every~$\bigovee_i \sigma_i \ket{\bigovee_j \lambda_{ij} \ket{x_{ij}}}$
    in~$\mathcal{D}_M \mathcal{D}_M X$.
(Equivalently: $h \after \mu = h \after \mathcal{D}_M h$
and~$h \after \eta = \id$.)
    We call~$h$ the convex structure on~$X$.
A map~$f\colon X \to Y$
    between abstract~$M$-convex sets
    is \Define{$M$-affine} if
    \index{affine@$M$-affine}
\begin{equation*}
    f \bigl(h_X \bigl(\,\bigovee_i \lambda_i \ket{x_i}\, \bigr)\bigr)
     \ = \ 
     h_Y\bigl(\,\bigovee_i \lambda_i \ket{f(x_i)}\,\bigr)
\end{equation*}
for every~$\bigovee_i \lambda_i \ket{x_i}$ in~$\mathcal{D}_M X$.
(Equivalently: $h_X \after \mathcal{D}_M f = f \after h_Y$.)
Write~$\Define{\AConvM}$ for the category
    \index{AConvM@$\AConvM$}
    of abstract~$M$-convex sets with
    $M$-affine maps between them.
(Equivalently: $\AConvM$
    is the Eilenberg--Moore category
    of the monad~$\mathcal{D}_M$.)
We call an abstract $M$-convex set~$(X,h)$ \Define{cancellative}
    \index{cancellative!$M$-convex set}
provided
\begin{equation*}
    h(\lambda \ket{y} \ovee \lambda^\perp \ket{x_1})\  = \
    h(\lambda \ket{y} \ovee \lambda^\perp \ket{x_2})
    \quad\text{implies}\quad~x_1=x_2
\end{equation*}
    for any~$x_1,x_2,y \in X$ and~$\lambda \in M, \lambda \neq 1$.
\begin{point}{41}{Remark}%
    For an abstract~$[0,1]$-convex set~$(X,h)$,
    binary convex combinations are sufficient:
    for instance, for any~$\lambda \ovee \mu \neq 1$
        and~$x,y,z \in X$ we have
\begin{equation*}
    h \bigl(\lambda \ket{x} \ovee \mu \ket{y} \ovee
        (\lambda \ovee \mu)^\perp \ket{z}\bigr)
        \ = \ 
    h\Bigl(\lambda \ket{x}
        \ovee \lambda^\perp \ket{
            h\bigl( \nicefrac{\mu}{\lambda^\perp} \ket{y}
        \ovee \nicefrac{(\lambda \ovee \mu)^\perp}{\lambda^\perp}
        \ket{z}}\bigr)\Bigr).
\end{equation*}
This reduction to binary convex combinations uses
    the division on~$[0,1]$.
Some effect monoids have a suitable division as well,
        but many do not
    as we will see later on
        in~\sref{dfn-effect-divisoid} and \sref{basic-divisoid-equiv}.
It seems plausible that
    it is impossible to write an arbitrary
    three-element~$M$-convex combination
    over~$\mathcal{D}_M \{x,y,z\}$
    using only binary convex combinations
    in the case that~$M$ is the effect monoid
        on the unit interval of~$C[0,1]$.
I do not have a proof to  back this claim.
\end{point}
\end{point}
\begin{point}{50}{Examples}%
We give some examples of abstract convex sets.
\begin{enumerate}
\item
Every convex subset~$X \subseteq V$
    of some real vector space~$V$
    is a cancellative abstract~$[0,1]$-convex set
    with~$h(\lambda_1 \ket{x_1} \ovee \cdots \ovee \lambda_n \ket{x_n})
            = \lambda_1 x_1 + \cdots + \lambda_n x_n$.
\item
Not every abstract~$[0,1]$-convex set is
    a convex subset of a real vector space.
Consider~$T \subseteq [0,1]^2$
    defined by~$T \equiv \{ (x,y);\ x+y \leq 1\}$.
Say~$(x,y) \sim (x',y')$
    whenever~$x = x'$ and either $x\neq 0$ or~$y=y'$.
This equivalence relation~$\sim$
is a congruence (we will cover these in \sref{aconv-cong})
        for the convex structure on~$T$
    (inherited by~$\R^2$)
    and so~$T /_\sim$ is an abstract~$[0,1]$-convex set.
That is: we start off with a filled triangle
$T \equiv \begin{tikzpicture}[scale=0.2]
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
    \draw (1,0) -- (0,1) ; 
\end{tikzpicture}$,
identify all vertical lines
except for the y-axis
and are left with
$T/_\sim \equiv
\begin{tikzpicture}[scale=0.2]
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}$.
The abstract~$[0,1]$-convex set~$T/_\sim$
    is not cancellative:
\begin{equation*}
    h\Bigl( 
    \frac{1}{2}\ket{\begin{tikzpicture}[scale=0.2]
    \filldraw( 1,0) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}}
\ovee
    \frac{1}{2}\ket{\begin{tikzpicture}[scale=0.2]
    \filldraw( 0,1) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}} \Bigr)
\ = \
    \begin{tikzpicture}[scale=0.2]
    \filldraw( .5,0) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}
\ = \ 
h \Bigl(\frac{1}{2}\ket{\begin{tikzpicture}[scale=0.2]
    \filldraw( 1,0) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}}
\ovee
    \frac{1}{2}\ket{
        \begin{tikzpicture}[scale=0.2]
    \filldraw( 0,.5) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}
}\Bigr), \quad\text{but}\quad
        \begin{tikzpicture}[scale=0.2]
    \filldraw( 0,1) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture} \ \neq \ 
        \begin{tikzpicture}[scale=0.2]
    \filldraw( 0,.5) circle (3pt);
    \draw (0,0) -- (0,1) ; 
    \draw (1,0) -- (0,0) ; 
\end{tikzpicture}.
\end{equation*}
\item
Semilattices are exactly~abstract $2$-convex sets.
    ($2$ is the two-element Effect Monoid,
        see \sref{eff-monoid-examples}.)
Furthermore, every semilattice~$(L, \vee)$
    is an abstract~$[0,1]$-convex set
    with
    \begin{equation*}
    h\bigl(\lambda_1 \ket{x_1} \ovee \cdots \ovee \lambda_n \ket{x_n}\bigr)
        \ =\  \bigvee_{i; \lambda_i \neq 0} x_i.
    \end{equation*}
    A semilattice~$L$ is cancellative as abstract $[0,1]$-convex set
    if and only if~$x=y$ for all~$x,y\in L$.
    See~\cite{neumann1970quasivariety}.
\item
Every cancellative~$[0,1]$-convex set
    is isomorphic to a convex subset of a real vector space.
    See e.g.~\cite[thm.~8]{statesofconvexsets}.
\end{enumerate}
\spacingfix{}
\begin{point}{60}{Remarks}%
The study of
    convex subsets (of real vector spaces)
    as algebraic structures goes back a long time,
        see e.g.~\cite{stone1949postulates,neumann1970quasivariety,flood1981semiconvex,tz2009convex,gudder1979general}.
The more pathological abstract~$[0,1]$-convex sets have been studied before
    under different names:
    they are semiconvex sets in \cite{flood1981semiconvex,swirszcz1975monadic} and
    convex spaces in \cite{tz2009convex}.
The description of convex sets using Eilenberg--Moore algebras is probably
    due to \'Swirszcz \cite{swirszcz1975monadic}.
For the even more exotic abstract~$M$-convex
    sets, see~\cite{effintro} or
        \cite{probdistrconv}.
\end{point}
\end{point}
\begin{point}{70}{Proposition}%
Let~$C$ be an effectus with scalars~$M$.
For any object~$X$, the set of states
$\Stat X$ is an abstract $M^{\mathsf{op}}$-convex set
with~$h\colon \mathcal{D}_{M^{\mathsf{op}}} \Stat X \to \Stat X$
    defined by
    $h\bigl( \lambda_1 \ket{\varphi_1} \ovee \cdots \ovee \lambda_n \ket{\varphi_n} \bigr)
     =  [\varphi_1, \ldots, \varphi_n] \after \langle
                    \lambda_1, \ldots, \lambda_n\rangle$.
Furthermore,
    for any total map~$f\colon X \to Y$,
    the map~$ (\Stat f)(\varphi) \ = \ f \after \varphi$
    is an~$M^{\mathsf{op}}$-affine map~$\Stat X \to \Stat Y$ yielding a
    functor~$\Stat \colon \Tot C \to \mathsf{AConv}_{M^{\mathsf{op}}}$.~\cite{effintro}
\begin{point}{80}{Proof}%
Clearly~$h(\ket{\varphi}) = \varphi$.
To show the other axiom~\eqref{convex-mult},
assume we have any~$\bigovee^n_{i=1} \sigma_i \ket{\bigovee^{m_i}_{j=1} \lambda_{ij} \ket{\varphi_{ij}}}$
in~$\mathcal{D}_{M^\mathsf{op}} \mathcal{D}_{M^{\mathsf{op}}} \Stat X$.
Write~$\lambda_i \equiv \langle\lambda_{i1}, \ldots, \lambda_{im_i}\rangle$
and $\varphi_i \equiv [\varphi_{i1}, \ldots, \varphi_{i{m_i}}]$.
Then
\begin{align*}
    h \Bigl( \bigovee_i \sigma_i \, \ket{
        h\bigl(\, \bigovee_j \lambda_{ij} \ket{\varphi_{ij}}\, \bigr)
    } \, \Bigr)
    &\ = \ 
    [\varphi_1 \after \lambda_1, \ldots, 
    \varphi_n \after \lambda_n] \after \langle
    \sigma_1, \ldots, \sigma_n
    \rangle
    \\ & \ = \ 
    \bigovee_{i} \varphi_i \after \lambda_i \after \sigma_i
    \\ & \ = \ 
    \bigovee_{i} \bigl(\bigovee_j \varphi_{ij} \after \lambda_{ij}\bigr) \after \sigma_i
    \\ & \ = \ 
    \bigovee_{i,j} \varphi_{ij} \after (\lambda_{ij} \after \sigma_i)
    \\ & \ = \ 
    \bigovee_{i,j} \varphi_{ij} \after (\sigma_i \odot_{M^{\mathsf{op}}} \lambda_{ij})
    \\ & \ = \ 
    h \Bigl( \bigovee_{i,j} \sigma_i \odot_{M^{\mathsf{op}}} \lambda_{ij} \ket{\varphi_{ij}} \Bigr).
\end{align*}
So~$\Stat X$ is indeed an abstract~$M^{\mathsf{op}}$-convex set.
Let~$f\colon X \to Y$ be any total map.
To show~$\Stat f$ is affine,
it is sufficient to show that
for every~$\bigovee_i \lambda_i \ket{\varphi_i}$
 in~$\mathcal{D}_{M^{\mathsf{op}}}$,
 we have
        $f \after \bigovee_i  \varphi_i \after \lambda_i 
         = 
        \bigovee_i f \after  \varphi_i \after \lambda_i$,
        which is clearly true.
    Functoriality of~$\Stat$ is obvious. \qed
\end{point}
\end{point}
\end{parsec}

\subsection{Effectus of abstract $M$-convex sets}\label{more-aconvm}
\begin{parsec}{1930}%
\begin{point}{10}%
For our next project,
    we indulge ourselves in a tangent:
    we investigate whether the category~$\AConvM$ is an effectus.
We can show it is, if~$M$ has a certain partial division.
Unfortunately it will remain unclear if~$\AConvM$ is an effectus in general.
The case~$M=[0,1]$ is much easier and has already been dealt with
        in \cite{statesofconvexsets}. 
The first step is to study the coproduct in~$\AConvM$.
To construct the coproduct, we will need to know
    about quotients of abstract~$M$-convex sets.
\end{point}
\begin{point}{20}[aconv-cong]{Exercise}%
In this exercise you construct the quotient of an
    abstract~$M$-convex set by a congruence.
Assume~$(X,h)$ is an abstract~$M$-convex set
    and~${\sim} \subseteq X^2$ is an equivalence relation.
Write~$X/_\sim$ for the set of equivalence classes
    of~$\sim$
    and~$q\colon X \to X/_\sim$
    for~$q(x) = [x]_\sim$, where~$[x]_\sim$ is the equivalence class of~$x$.
For~$\varphi,\psi \in \mathcal{D}_M X$,
    we write~$\varphi \sim \psi$
    provided~$(\mathcal{D}_M q)(\varphi) = (\mathcal{D}_M q)(\psi)$.
We say~$\sim$ is a \Define{congruence} for~$(X,h)$
    \index{congruence!$M$-convex set}
if~$\varphi \sim \psi$ implies~$h(\varphi) \sim h(\psi)$.
\begin{enumerate}
\item
Prove that~$q$, $\mathcal{D}_M q$ and~$\mathcal{D}_M \mathcal{D}_M q$
    are all surjective.
\item
Show that the following are equivalent.
\begin{enumerate}
\item
$\sim$ is a congruence.
\item
There is a map~$h_\sim \colon \mathcal{D}_M X/_\sim \to X/_\sim$
    such that~$h_\sim \after \mathcal{D}_M q = q \after h$.
\end{enumerate}
By the previous point $h_\sim$ is unique, if it exists.
\item
Assume~$\sim$ is a congruence.
Use the previous two points to show
\begin{equation*}
h_\sim \after \mathcal{D}_M h_\sim \after \mathcal{D}_M \mathcal{D}_M q
            \ =\  h_\sim \after \mu \after \mathcal{D}_M \mathcal{D}_M q.
\end{equation*}
Conclude that~$(X/_\sim,h_\sim)$ is an abstract~$M$-convex set
    and that the qoutient map~$q\colon X \to X/_\sim$ is~$M$-affine.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{30}[affine-kernel-cong]{Exercise}%
Assume~$f\colon X \to Y$ is an affine map between abstract
    $M$-convex sets.
Show that the kernel~$\{(x,y);\ f(x) = f(y)\}$ of~$f$
    is a congruence.
\end{point}
\begin{point}{40}[least-conv-cong]{Exercise}%
Assume~$(X,h)$ is an abstract~$M$-convex set and~$R \subseteq X^2$
    is some relation.
It is easy to see there is a least congruence containing~$R$.
We need to know a bit more than mere existence.
Write~$R^*$ for the reflexive symmetric transitive closure of~$R$
    (i.e.~the least equivalence relation containing~$R$).

For~$\psi_1,\psi_2 \in \mathcal{D}_M X$,
    we write~$\psi_1 \approx \psi_2$
    if there is a \emph{derivation}: a tuple~$\varphi_1, \ldots, \varphi_n \in \mathcal{D}_M X$
(say~$\varphi_i \equiv \bigovee^{n_i}_{j = 1}  \lambda_{ij}\ket{x_{ij}}$)
such that~$\varphi_1 = \psi_1$, $\varphi_n = \psi_2$ 
    and for each~$1 \leq i<n$ \emph{one} of the following two conditions holds.
\begin{enumerate}
\item
    $n_i = n_{i+1}$
    and for all~$1 \leq j \leq n_i$ we have
    $x_{ij} \mathrel{R^*} x_{(i+1)j}$
    and~$\lambda_{ij}  = \lambda_{(i+1)j}$.
\item
    $h (\varphi_i) = h(\varphi_{i+1})$.
\end{enumerate}
We will show that~$\sim$
    given by~$x \sim y \iff \eta (x) \approx \eta(y)$
    is the least congruence containing~$R$:
\begin{enumerate}
\item
To start, show that~$\eta ( h(\psi)) \approx \psi $
    and so~$\varphi \approx \psi$ implies~$h(\varphi) \sim h(\psi)$.
\item
Show that if~$\varphi \approx \psi$,
    then
    \begin{equation*}
    \mu \Bigl(\lambda_0 \ket{\psi} \ovee \bigovee_{j=1}^n \lambda_j \ket{\chi_j}\Bigr)
    \ \approx  \ 
    \mu \Bigl(\lambda_0 \ket{\varphi} \ovee \bigovee_{j=1}^n \lambda_j \ket{\chi_j}\Bigr).
    \end{equation*}
    for any~$\bigovee_j \lambda_j=1$  in~$M$ and~$\chi_1,\ldots, \chi_n \in \mathcal{D}_M X$.
\item
    Use the previous point to show that~$\varphi \sim \psi$
        implies~$\varphi \approx \psi$.
Conclude~$\sim$ is the smallest congruence containing~$R$.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{50}[aconv-coprod]{Proposition}%
Assume~$(X,h_X)$ and~$(Y,h_Y)$
    are abstract~$M$-convex sets.
    We will construct their coproduct.
Note that~$\mu$ turns~$\mathcal{D}_M (X+Y)$
    into an abstract~$M$-convex set.
Let~$\sim$ denote the least congruence on~$\mathcal{D}_M (X+Y)$
with
\begin{equation}
    (\mathcal{D}_M \kappa_1) (\varphi)
    \ \sim \ \eta(\kappa_1 ( h_X (\varphi)))
    \quad \text{and} \quad
    (\mathcal{D}_M \kappa_2) (\psi)
    \ \sim \ \eta(\kappa_2 ( h_Y (\psi))) \label{congruence-coprod-conv}
\end{equation}
    for all~$\varphi \in \mathcal{D}_M X$
    and~$\psi \in \mathcal{D}_M Y$.
(Alternatively: $\sim$ is the least congruence
    that makes~$\eta \after \kappa_1$ and~$\eta\after\kappa_2$ affine.)
Write~$q\colon \mathcal{D}_M (X+Y) \to C$
    for the quotient of~$\mathcal{D}_M(X+Y)$ by~$\sim$, see~\sref{aconv-cong}.
    Denote the convex structure on~$C$ by~$h$.
Define~$c_1 \colon X \to C$ and~$c_2 \colon Y \to C$
    by~$c_1 \equiv q \after \eta \after \kappa_1$
    and~$c_2 \equiv q \after \eta \after \kappa_2$.

Then: $c_1 \colon X \to C \leftarrow Y \colon c_2$
is a coproduct of~$X$~and~$Y$ in~$\AConvM$.
\begin{point}{60}{Proof}%
We start with the affinity of the coprojections:
\begin{alignat*}{2}
    c_1 \after h_X & \ = \ 
    q \after \eta \after \kappa_1 \after h_X \\
    &\ =\  q \after \mathcal{D}_M \kappa_1
        &\qquad& \text{by dfn.~of~$\sim$}
    \\
    & \ =\  q \after \mu \after \mathcal{D}_M \eta \after \mathcal{D}_M \kappa_1. \\
    & \ =\  \mu \after \mathcal{D}_Mq \after \mathcal{D}_M \eta \after \mathcal{D}_M \kappa_1. \\
    & \ =\  \mu \after \mathcal{D}_M c_1,
\end{alignat*}
so~$c_1$ is affine. With similar reasoning, we see~$c_2$ is affine.
\begin{point}{70}%
Assume~$f\colon X \to Z$ and~$g\colon Y \to Z$
    are two affine maps to some abstract~$M$-convex set~$(Z,h_Z)$.
We want to show~$h_Z \after \mathcal{D}_M [f,g]$
    lifts to~$C$.
With an easy calculation,
    one sees~$h_Z \after \mathcal{D_M} [f,g]$ is affine.
We compute
\begin{align*}
    h_Z \after \mathcal{D}_M [f,g] \after \mathcal{D}_M \kappa_1
     & \ = \ 
    h_Z \after \mathcal{D}_M f \\
     & \ = \ f \after h_X \\
     & \ = \ h_Z \after \eta \after [f,g] \after \kappa_1 \after h_X \\
     & \ = \ h_Z \after \mathcal{D}_M [f,g] \after \eta \after \kappa_1 \after h_X.
\end{align*}
So~$
(\,(\mathcal{D}_M \kappa_1) (\varphi), \,
\ \eta(\kappa_1 ( h_X (\varphi)))\,)$
is in the kernel (see \sref{affine-kernel-cong})
of~$h_Z \after \mathcal{D}_M [f,g]$
for~$\varphi \in \mathcal{D}_M$.
Similarly~$(\,(\mathcal{D}_M \kappa_2) (\psi), \,
\ \eta(\kappa_2 ( h_Y (\psi)))\,)$
is also in the kernel of~$h_Z \after \mathcal{D}_M [f,g]$
for all~$\psi \in \mathcal{D}_M$.

As kernels of affine maps are congruences
    and~$\sim$ is the least congruence that contains these pairs,
    we conclude~$\sim$ is a subset of the kernel
    of~$h_Z \after \mathcal{D}_M [f,g]$.
Thus there is a unique affine~$k\colon C \to Z$
    fixed by~$k \after q = h_Z \after \mathcal{D}_M [f,g]$.
Now
\begin{align*}
    k \after c_1 
    &\ = \ k \after q \after \eta \after \kappa_1 \\
    &\ = \ h_Z \after \mathcal{D}_M [f,g]
                            \after \eta\after \kappa_1 \\
    &\ = \ h_Z \after \eta \after  [f,g]
                            \after \kappa_1 \\
    &\ = \  f
\end{align*}
and similarly~$k \after c_2 = g$.
\end{point}
\begin{point}{80}%
Only uniqueness of~$k$ remains.
So assume~$k'\colon C \to Z$ is an affine map
    such that~$k' \after c_1 = f$
    and~$k' \after c_2 = g$.
We turn the wheel:
\begin{align*}
    k' \after q
    & \ = \ k' \after q \after \mu \after \mathcal{D}_M \eta \\
    & \ = \ k' \after h \after \mathcal{D}_M (q \after \eta) \\
    & \ = \ h_Z \after \mathcal{D}_M (k' \after q \after \eta) \\
    & \ = \ h_Z \after \mathcal{D}_M 
    [ k' \after q \after \eta \after \kappa_1,
    k' \after q \after \eta \after \kappa_2]  \\
    & \ = \ h_Z \after \mathcal{D}_M 
    [ k' \after c_1,
    k' \after c_2]  \\
    & \ = \ h_Z \after \mathcal{D}_M [ f, g] \\
    & \ = \ k \after q.
\end{align*}
So~$k = k'$ by surjectivity of~$q$. \qed
\end{point}
\end{point}
\begin{point}{90}[elements-coprod-conv]{Remark}%
The existence of coproducts of abstract~$M$-convex sets already
    follows from the more general theorem of Linton \cite{linton}.
    (Cf.~\cite{barr}.)
However, for the results in the remainder of this section we need to know
    more about the coproduct than Linton's construction provides.

By our construction, we know that
    every~$z \in X+Y$
    is of the
    form
\begin{equation*}
    z \ =\  h 
    \Bigl( \bigovee^n_{i=1} \lambda_i \ket{c_1(x_i)}
    \ovee \bigovee^m_{i=1} \sigma_i \ket{c_2(y_i)} \Bigr)
\end{equation*}
for some~$\lambda_i,\sigma_i \in M $, 
$x_i \in X$ and~$y_i \in Y$.
In general these are not unique.
Indeed
using \sref{least-conv-cong}, we see that
\begin{equation*}
     h 
     \Bigl( \bigovee^n_{i=1} \lambda_i \ket{c_1(x_i)}
     \ovee \bigovee^m_{i=1} \sigma_i \ket{c_2(y_i)} \Bigr) 
     \ = \ 
     h 
     \Bigl( \bigovee^{n'}_{i=1} \lambda'_i \ket{c_1(x'_i)}
     \ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{c_2(y'_i)} \Bigr)
\end{equation*}
iff there is a \emph{derivation}~$\Phi_1, \ldots, \Phi_l \in \mathcal{D}^2_M(X+Y)$,
say $\Phi_i \equiv \bigovee_j \zeta_{ij} \ket{\varphi_{ij}}$,
with
\begin{equation*}
\Phi_1 \ =\  
\ket {\bigovee^n_{i=1} \lambda_i \ket{\kappa_1(x_i)}
\ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_2(y_i)}}
, \quad
 \Phi_l \ =\  
 \ket {\bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_1(x_i)}
 \ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_2(y_i)}}
\end{equation*}
and for each~$1 \leq i < l$ either
\begin{enumerate}
    \item $\mu(\Phi_i) = \mu(\Phi_{i+1})$
        or
    \item
        for each~$j$ we have~$\zeta_{ij} = \zeta_{(i+1)j}$
        and one of the following.
        \begin{enumerate}
        \item
    $\varphi_{ij} = \varphi_{(i+1)j}$.
\item
    $\varphi_{ij} = (\mathcal{D}_M\kappa_1) (\chi)$
and~$\varphi_{(i+1)j} = (\mathcal{D}_M\kappa_1) (\chi')$
        for some~$\chi,\chi' \in \mathcal{D}_M X$
        with~$h_X( \chi) = h_X(\chi')$.
\item
    $\varphi_{ij} = (\mathcal{D}_M\kappa_2) (\chi)$
and~$\varphi_{(i+1)j} = (\mathcal{D}_M\kappa_2) (\chi')$
        for some~$\chi,\chi' \in \mathcal{D}_M Y$
        with~$h_Y( \chi) = h_Y(\chi')$.
        \end{enumerate}
\end{enumerate}
\end{point}
\end{point}
\spacingfix{}
\begin{point}{100}[n-times-one-aconvm]{Exercise}%
Show that the one-element set is an abstract~$M$-convex set
    and, in fact, the final object of~$\AConvM$.
Moreover, show that in~$\AConvM$
\begin{equation*}
    n \cdot 1 \ \equiv \ \underbrace{1 + \cdots + 1}_{\text{$n$ times}}
    \ \cong \ \mathcal{D}_M \{1, \ldots, n\}.
\end{equation*}
(You might want to use that~$\mathcal{D}_M$, as a left-adjoint,
    preserves coproducts.)
\end{point}
\end{parsec}

\begin{parsec}{1940}%
\begin{point}{10}[aconvalmosteffectus]{Proposition}%
The category~$\AConvM$ obeys all the axioms of an effectus in total
form except perhaps for the left pullback square of~\eqref{pullbacks}.
\begin{point}{20}{Proof}%
In \sref{aconv-coprod} we proved~$\AConvM$ has binary coproducts
    and in \sref{n-times-one-aconvm}
    that the one-element set~$1$ is its final object.
As~$\mathcal{D}_M \emptyset = \emptyset$,
    the empty set is trivially also an abstract~$M$-convex set
    and in fact the initial object of~$\AConvM$.
\end{point}
\begin{point}{30}%
We continue with joint monicity
    of~$[\kappa_1,\kappa_2,\kappa_2],
    [\kappa_2,\kappa_1,\kappa_2]\colon 1+1+1 \to 1+1$.
We can represent the convex set~$1+1+1$
    as the set of triples~$(a,b,c) \in M^3$
    with~$a\ovee b \ovee c = 1$
    with the obvious convex structure,
    cf.~\sref{n-times-one-aconvm}.
Similarly, we identify~$1+1$
    with pairs~$(a,a^\perp) \in M^2$.
    The maps at hand are given by
\begin{equation}\label{conv-jointly-monic}
    (a,b,c) \ \mapsto\  (a , b\ovee c)\quad \text{and} \quad
    (a,b,c) \ \mapsto\  (b, a\ovee c).
\end{equation}
Assume~$
(a, b \ovee c) = 
(a', b' \ovee c') $
and
$(b, a \ovee c) = 
(b', a' \ovee c') $
for~$a,a',b,b',c,c' \in M$ with~$a \ovee b \ovee c= 1$
and~$a' \ovee b' \ovee c'= 1$.
Then clearly~$a=a'$,~$b=b'$
    and so~$c = (a\ovee b)^\perp = (a' \ovee b')^\perp = c'$.
Thus the maps~\eqref{conv-jointly-monic} are jointly injective,
    hence jointly monic.
\end{point}
\begin{point}{40}%
At last, we are ready to prove that the square on the right of \eqref{pullbacks}
    is a pullback diagram in~$\AConvM$.
So assume~$\alpha \colon Z \to X+Y$
    is a map in~$\AConvM$
    with~$(!+!) \after \alpha = \kappa_1 \after !$.
\begin{equation*}
\xymatrix{
    Z \ar@/^1pc/[rrd]^{!}
        \ar@/_1pc/[rdd]_\alpha
        \ar@{.>}[rd]|\gamma\\
        &X \ar[r]^{!} \ar[d]^{\kappa_1}
        & 1\ar[d]^{\kappa_1} \\
        &X+Y\ar[r]_{!+!} & 1+1
    }
\end{equation*}
We have to show~$\alpha = \kappa_1 \after \gamma$,
    for a unique~$\gamma\colon Z \to X+Y$ in~$\AConvM$.
For the moment, assume~$\kappa_1$ is injective.
Then~$\gamma$, if it exists, is unique.
Pick~$z \in Z$.
We know
\begin{equation*}
    \alpha(z) \ =\  h 
    \Bigl( \bigovee^n_{i=1} \lambda_i \ket{\kappa_1(x_i)}
    \ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_2(y_i)} \Bigr)
\end{equation*}
for some~$\lambda_i,\sigma_i \in M $, 
$x_i \in X$ and~$y_i \in Y$,
where~$h$ is the convex structure on~$X+Y$.
As~$(!+!) \after \alpha = ! \after \kappa_1$,
    we must have~$\bigovee_i \sigma_i = 0$
    and so~$\alpha(z) = \kappa_1(x_z)$
    for some~$x_z \in X$.
This~$x_z$ is unique by supposed injectivity of~$\kappa_1$.
    Define~$\gamma(z) = x_z$.
By definition~$\kappa_1 \after \gamma = \alpha$.
To see~$\gamma$ is affine, pick any~$\varphi \in \mathcal{D}_M (Z)$.
We have
$
\kappa_1 ( \gamma ( h_Z (\varphi )))
    = \alpha(h_Z (\varphi))
    = h(\mathcal{D}_M\alpha(\varphi))
    = h(\mathcal{D}_M\kappa_1 ( \mathcal{D}_M \gamma(\varphi)))
    = \kappa_1  (h_X( \mathcal{D}_M \gamma(\varphi)))
$ and
so indeed~$\gamma(h_Z(\varphi)) = h_X(\mathcal{D}_M \gamma (\varphi))$
    --- i.e.~$\gamma$ is affine.
\end{point}
\begin{point}{50}%
Finally, we will show that~$\kappa_1$ is indeed injective.
Assume~$\kappa_1(x_0) = \kappa_1(x'_0)$
for some~$x_0,x'_0 \in X$.
    Let~$\Phi_1, \ldots, \Phi_l \in \mathcal{D}_M^2{(X+Y)}$
    be a derivation
    of~$\kappa_1(x_0) = \kappa_1(x'_0)$
    as in \sref{elements-coprod-conv}.
The remainder of the proof is, in essence, a simple induction
    over~$1 \leq i < l$, which has been complicated
    by a technicality.
Define
\begin{equation*}
    \mathrm{IH}(i) \ \equiv \ \text{``}
    \bigovee_y \mu(\Phi_i)(\kappa_2 (y)) = 0
        \text{ and }
        h_X\Bigl(\bigovee_{x} \mu(\Phi_i)(\kappa_1(x)) \ket{x}\Bigr)
        =    x_0 \text{''}.
\end{equation*}
Clearly~$\mathrm{IH}(1)$ holds
    and if~$\mathrm{IH}(l)$ should hold,
    then~$x_0 = x_0'$ as desired.
So, to prove the inductive step, assume~$\mathrm{IH}(i)$ holds.
There are two possible derivation steps, see \sref{elements-coprod-conv}.
In the first case (i.e.~$\mu(\Phi_i) = \mu(\Phi_{i+1})$)
    it is obvious~$\mathrm{IH}(i+1)$ holds.
So we continue with the other case,
where (among others) we have~$\zeta_{ij} = \zeta_{(i+1)j}$,
    where~$\Phi_i \equiv \bigovee_j \zeta_{ij} \ket{\varphi_{ij}}$.
Without loss of generality, we may assume~$\zeta_{ij} \neq 0$.
For each~$j$ there are three possibilities, see \sref{elements-coprod-conv}.
The third does not occur:
if~$\varphi_{ij_0} = (\mathcal{D}_M \kappa_2) (\chi)$
    for some~$\chi \in \mathcal{D}_M Y$ and~$j_0$,
    then we reach a contradiction:
\begin{equation*}
    0\ = \ 
    \bigovee_y \mu(\Phi_i)(\kappa_2(y))
    \ = \ \bigovee_{y,j} \zeta_{ij} \odot \varphi_{ij}(\kappa_2(y))
    \ \geq \ \bigovee_y \zeta_{ij_0} \odot \chi(y)\  \neq\  0.
\end{equation*}
We are left with two possibilities ---
    to distinguish those,
    write~$j \in J$ if~$\varphi_{ij} = \varphi_{(i+1)j}$
    and~$j \notin J$
    if~$\varphi_{ij} = (\mathcal{D}_M \kappa_1)(\chi)$
    and~$\varphi_{(i+1)j} = (\mathcal{D}_M \kappa_1)(\chi')$
    for some~$\chi,\chi' \in \mathcal{D}_M X$
    with~$h_X (\chi) = h_X(\chi')$.

    We will show the first part of~$\mathrm{IH}(i+1)$.
Pick any~$y \in Y$.
If~$j \in J$, then~$\zeta_{(i+1)j}\odot \varphi_{(i+1)j}(\kappa_2(y))
= \zeta_{ij} \odot \varphi_{ij}(\kappa_2(y)) = 0$.
In the other case, if~$j \notin J$,
then clearly~$\zeta_{(i+1)j}\odot \varphi_{(i+1)j}(\kappa_2(y)) = 0$
    as~$\varphi_{(i+1)j} = (\mathcal{D}_M \kappa_1)(\chi')$.
So, we have~$\bigovee_y \mu(\Phi_{i+1})(\kappa_2(y))
= \bigovee_{y,j} \zeta_{(i+1)j} \odot \varphi_{(i+1)j} (\kappa_2(y)) = 0 $.

Write~$r_{ij} = (\bigovee_x \varphi_{ij}(\kappa_1(x)))^\perp$.
The remainder of the proof is complicated
    by the fact that in general~$r_{ij} \neq 0$.
    We do have~$\bigovee_j \zeta_{ij} \odot r^\perp_{ij} = 1$
        and~$\bigovee_j \zeta_{ij} = 1$
        so by \sref{emond-lemma-for-conv}
        we see~$\zeta_{ij} \odot r^\perp_{ij} = \zeta_{ij}$,
        which  forces~$\zeta_{ij} \odot r_{ij} = 0$.
We compute
\begin{align*}
    h_X\Bigl(\bigovee_x \mu(\Phi_i) (\kappa_1(x)) \ket{x}\Bigr) 
    &\ = \ 
    h_X \Bigl( \bigovee_{x,j} \zeta_{ij} \odot \varphi_{ij}
        (\kappa_1(x)) \ket{x} \Bigr) \\
        &\ = \ 
    h_X \Bigl(
    \bigovee_{j} \zeta_{ij} \odot r_{ij} \ket{x_0} \ovee \bigovee_x
    \zeta_{ij} \odot \varphi_{ij}
        (\kappa_1(x)) \ket{x} \Bigr) \\
        & \ = \ h_X \Bigl(
    \mu\Bigl( \bigovee_j \zeta_{ij} \ket{
        r_{ij} \ket{x_0} \ovee \bigovee_x \varphi_{ij} (\kappa_1 (x)) \ket{x}
    }
    \Bigr)
    \Bigr) \\
        & \ = \ h_X \Bigl(
    \bigovee_j \zeta_{ij} \ket{
        h_X\Bigl(
        r_{ij} \ket{x_0} \ovee \bigovee_x \varphi_{ij} (\kappa_1 (x)) \ket{x}
    \Bigr)
}
    \Bigr).
\end{align*}
So, if we show that for each~$j$,
    we have
\begin{multline}\label{eqkappainj}
        h_X\Bigl(
        r_{ij} \ket{x_0} \, \ovee \,\bigovee_x \varphi_{ij} (\kappa_1 (x)) \ket{x}
    \Bigr) \\
    \  = \  
        h_X\Bigl(
        r_{(i+1)j} \ket{x_0} \,\ovee \,\bigovee_x \varphi_{(i+1)j} (\kappa_1 (x)) \ket{x}
    \Bigr),
\end{multline}
then
\begin{equation*}
    x_0 \ = \ h_X\Bigl(\bigovee_x \mu(\Phi_i) (\kappa_1(x)) \ket{x}\Bigr) 
    \ =\  h_X\Bigl(\bigovee_x \mu(\Phi_{i+1}) (\kappa_1(x)) \ket{x}\Bigr),
\end{equation*}
as desired.
If~$j \in J$,
then~$\varphi_{ij} = \varphi_{(i+1)j}$
and so~$r_{ij} = r_{(i+1)j}$
and obviously~\eqref{eqkappainj}.
So assume~$j \notin J$.
Then clearly~$r_{ij} = 0 = r_{(i+1)j}$
as~$\varphi_{ij} = (\mathcal{D}_M \kappa_1)(\chi))$
    and~$\varphi_{(i+1)j} = (\mathcal{D}_M \kappa_1) (\chi')$.
Now~\eqref{eqkappainj} follows from~$h_X(\chi) = h_X(\chi')$. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{1950}%
\begin{point}{10}%
It is unclear whether the left square of~\eqref{pullbacks}
    is a pullback in~$\AConvM$.
We will see that it is, if we assume that~$M$ has
        a partial division in the following sense.
\end{point}
\begin{point}{20}[dfn-effect-divisoid]{Definition}%
An \Define{effect divisoid}
    \index{effect divisoid}
    is an effect monoid~$M$
    with partial binary operation~$(a,b) \mapsto \rfrac{a}{b}$
    that is defined iff~$a \leq b$ and
        satisfies the following axioms.
\begin{enumerate}
\item~$\rfrac{a}{b}$
        is the unique element of~$M$
        with~$\rfrac{a}{b} \leq \rfrac{b}{b}$
        and~$b\odot \rfrac{a}{b} \ =\  a$
\item~$a \ \leq \ \rfrac{a}{a}$
\item~$\rfrac{(\rfrac{a}{a})}{(\rfrac{a}{a})} \ =\  \rfrac{a}{a}$
\end{enumerate}
\spacingfix{}
\begin{point}{21}{Beware}%
The first axiom might be read as ``$\rfrac{a}{b}$ is defined to be the
    unique element such that (...)'' in which case the definition
    is cyclical and thus problematic.
    What is meant instead is that~$\rfrac{a}{b}$ is
        part of the structure and satisfies
\begin{itemize}
\item $\rfrac{a}{b} \leq \rfrac{b}{b}$
        and~$b\odot \rfrac{a}{b} \ =\  a$ and
\item
        if~$c \leq \rfrac{b}{b}$
        and~$b\odot c \ =\  a$,
        then~$c = \rfrac{a}{b}$
\end{itemize}
for all~$a,b,c \in M$ with~$a\leq b$.
In particular, it is not ruled out
    that there is an effect monoid
    which is an effect divisoid in two different ways.
\end{point}
\begin{point}{30}{Remark}%
The element~$\rfrac{a}{a}$ behaves like a support-projection for~$a$.
\end{point}
\end{point}
\begin{point}{40}[exc-divisoid-basics]{Exercise}%
Show that for an effect divisoid~$M$, the following holds.
\begin{enumerate}
\item
    $\rfrac{0}{0}=0$, $\rfrac{1}{1}=1$, $\rfrac{a}{1}=a$, $\rfrac{a}{a} \odot \rfrac{a}{a} = \rfrac{a}{a}$ and
    $\rfrac{a \odot b}{a} = \rfrac{a}{a }\odot b$.
\item
    For any~$a \leq b \leq c$,
    we have~$\rfrac{b}{c} \odot \rfrac{a}{b} = \rfrac{a}{c}$.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{50}{Examples}%
Almost all effect monoids we encountered
    are effect divisoids.
\begin{enumerate}
\item
The effect monoid~$[0,1]$
    is an effect divisoid with~$\rfrac{a}{b} = \frac{a}{b}$
        if~$b \neq 0$ and~$\rfrac{0}{0}=0$.
With the same partial division, we see the two-element effect monoid~$2$
    is also an effect divisoid.
\item
More interestingly,
    if~$M_1$ and~$M_2$
    are effect divisoids,
    then~$M_1 \times M_2$
    is an effect divisoid
    with~$\rfrac{(a_1,a_2)}{(b_1,b_2)} =
    (\rfrac{a_1}{b_1}, \rfrac{a_2}{b_2})$.
In particular~$[0,1]^n$ is an effect divisoid
    with component-wise partial division.
\item
Later, in \sref{andthen-effect-divisoid},
    we will see that if~$C$ is an~$\&$-effectus,
then~$(\Scal C)^{\mathsf{op}}$ (the scalars with multiplication in the
    opposite direction)
    is an effect divisoid.
\item
If~$M$ is a division effect monoid as in \cite[dfn.~6.3]{kentapartial},
then~$M^{\textrm{op}}$ is an effect divisoid in the obvious way.
\item
The effect monoid on the unit interval of~$C[0,1]$
    is \emph{not} an effect divisoid,
    but the effect monoid on the unit interval of~$L^\infty[0,1]$
    is, see \sref{basic-divisoid-equiv}.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{60}[basic-divisoid-equiv]{Exercise*}%
Let~$X$ be a compact Hausdorff space.
In this exercise you will show
    that the unit interval of~$C(X)$
    is an effect divisoid
    if and only if~$X$
    is \Define{basically disconnected}
    \index{basically disconnected}
    \cite[1H]{gillman2013rings}
    --- that is: if~$\overline{\supp f}$ is open
    for every~$f \in C(X)$.
Equivalently:
$C(X)$ is~$\sigma$-Dedekind complete
    \cite[3N.5]{gillman2013rings},
    which is in turn equivalent to bounded~$\omega$-completeness
    (i.e.~$C(X)$ has suprema, resp.~infima, of
            bounded ascending, resp.~descending, sequences).
\begin{enumerate}
\item
    Suppose the unit interval of~$C(X)$ is an effect divisoid.
        Let~$f \in C(X)$ with~$0 \leq f \leq 1$.
    If~$\overline{\supp f} = X$, then you're done.
        Otherwise pick any~$y \notin \overline{\supp f}$.
    Show, using Urysohn's lemma,
    that there is a~$g \in C(X), 0\leq g \leq \rfrac{f}{f}$
    with~$g(y) = 0$ and $g(x) = 1$ for all~$x \in \overline{\supp f}$.
    Show that this implies~$(\rfrac{f}{f})(y) = 0$
        and so~$\rfrac{f}{f}$ is the characteristic function
    of~$\overline{\supp f}$.  Conclude~$X$ is basically disconnected.
\item
Assume~$X$ is basically disconnected.
Let~$f,g\in C(X)$ with~$0 \leq f \leq g \leq 1$.
For~$n > 0$,
show that~$U_n \equiv \{ x;\ g(x) > \frac{1}{n} \}$
has open closure and so
\begin{equation*}
    h_n \ \equiv \  \begin{cases}
        \frac{f(x)}{g(x)} & x \in \overline{U_n}\\
        0 & \text{otherwise}.
    \end{cases}
\end{equation*}
is continuous.
Note~$h_1 \leq h_2 \leq \ldots \leq 1$
    and define~$\rfrac{f}{g} = \sup_n h_n$.
Show~$\rfrac{f}{f}$ is the characteristic function
    of~$\overline{\supp f}$ and
    $\rfrac{f}{g} \leq \rfrac{g}{g}$.
Prove that this partial division turns the unit interval of~$C(X)$
    into an effect divisoid.
\end{enumerate}
\spacingfix{}

\end{point}
\begin{point}{70}{Proposition}%
If $a \perp b$ and~$a \ovee b \leq c$ in an effect divisoid,
then~$\rfrac{a \ovee b}{c } = \rfrac{a}{c} \ovee \rfrac{b}{c}$.
\begin{point}{80}{Proof}%
We will first show that if~$c \odot a \perp c \odot b$,
    then~$\rfrac{c}{c} \odot a \perp \rfrac{c}{c}\odot b$.
To start,
    note~$c \odot b^\perp \leq c \odot b^\perp \ovee c^\perp
        = (c \odot b)^\perp \leq c \odot a$
        and so
\begin{equation*}
     \rfrac{c \odot a}{c} 
     \ = \ 
            \rfrac{c \odot b^\perp}{c} \odot
            \rfrac{c \odot a}{c \odot b^\perp}
     \ = \ 
            \rfrac{c}{c} \odot b^\perp \odot
            \rfrac{c \odot a}{c \odot b^\perp}
    \ \leq \ \rfrac{c}{c} \odot b^\perp.
\end{equation*}
Hence~$(\rfrac{c}{c}\odot b)^\perp
            \geq \rfrac{c}{c} \odot b^\perp
            \geq \rfrac{c \odot a}{c}
            = \rfrac{c}{c} \odot a $.
    Indeed:~$\rfrac{c}{c}\odot a \perp \rfrac{c}{c} \odot b$.
\begin{point}{90}%
Assume~$a\perp b$ and~$a\ovee b \leq c$. 
Clearly~$c \odot \rfrac{a}{c}  = a \perp b = c \odot \rfrac{b}{c}$.
By our initial lemma, we get
    $\rfrac{a}{c } =
    \rfrac{c}{c} \odot \rfrac{a}{c} \perp
    \rfrac{c}{c} \odot \rfrac{b}{c} =
    \rfrac{b}{c }
$.
Clearly~$c \odot (\rfrac{a}{c} \ovee \rfrac{b}{c}) = a \ovee b$, so
\begin{equation*}
    \rfrac{a \ovee b}{c} \ = \  
    \rfrac{c \odot (\rfrac{a}{c} \ovee \rfrac{b}{c})}{c} \ = \ 
\rfrac{c}{c} \odot (\rfrac{a}{c} \ovee \rfrac{b}{c}) \ = \ 
\rfrac{a}{c} \ovee \rfrac{b}{c},
\end{equation*}
as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{1960}%
\begin{point}{10}%
The following is a generalization
of~\cite[prop.~C.3]{kentapartial}.
See also~\cite[prop.~15]{statesofconvexsets}.
\end{point}
\begin{point}{20}[aconvm-is-effectus]{Theorem}%
If~$M$ is an effect divisoid,
    then~$\AConvM$ is an effectus.
\begin{point}{30}{Proof}%
We only have to show that the square on the left
    of \eqref{pullbacks} is a pullback in~$\AConvM$
    --- the other axioms were proven in \sref{aconvalmosteffectus}.
\begin{equation*}
\xymatrix{
    Z \ar@/^1pc/[rrd]^\beta
        \ar@/_1pc/[rdd]_\alpha
        \ar@{.>}[rd]|\gamma\\
        &X+Y \ar[r]^{\id+!} \ar[d]^{!+\id} & X+1\ar[d]^{!+\id} \\
        &1+Y\ar[r]_{\id+!} & 1+1
    }
\end{equation*}
To this end, assume~$\alpha\colon Z \to X+1$
and~$\beta\colon Z \to Y+1$
are maps in~$\AConvM$
with~$(! + \id) \after \beta = (\id+!)\after \alpha$.
We have to show there is a unique~$\gamma\colon Z \to X+Y$ in~$\AConvM$
with~$(\id+!)\after \gamma =\beta$
and~$(!+\id) \after \gamma =\alpha$.
Pick any~$z \in Z$.
Write~$\cdot$ for the unique element of~$1$.
By construction of the coproduct, see \sref{aconv-coprod},
we have
\begin{align*}
    \alpha(z) &\ =\  h_1\Bigl(\lambda_0 \ket{\kappa_1(\cdot)}
    \ovee \bigovee^n_{i=1} \lambda_i \ket{\kappa_2(y_i)}\Bigr) \\
        \beta(z) &\ =\  h_2 \Bigl(\sigma_0 \ket{\kappa_2(\cdot)}
        \ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)}\Bigr)
\end{align*}
for some~$\lambda_i, \sigma_i \in M$,
    $x_i \in X$ and $y_i \in Y$,
    where~$h_1$ and~$h_2$ are the convex structures
    on~$1+Y$ and~$X+1$, respectively.
Unfolding definitions
    (and identifying~$1+1 \cong M$ via~$\kappa_1 (\cdot) = 1$),
    it is easy to
    see that by assumption
\begin{equation}\label{aconv-epb-ass}
    \bigovee^m_{i=1} \sigma_i \ = \ 
    (!+\id)(\beta(z))  \ = \ 
    (\id + !)(\alpha(z)) \ =\  \lambda_0
    \ = \ \Bigl(\bigovee^n_{i=1} \lambda_i\Bigr)^\perp.
\end{equation}
This suggests the following definition
\begin{equation}\label{aconvmexpuldefgamma}
    \gamma(z) \ = \  h_3 \Bigl(
    \bigovee^n_{i=1} \lambda_i \ket{\kappa_2(y_i)}
        \ovee \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)}\Bigr),
\end{equation}
where~$h_3$ is the convex structure on~$X+Y$.
To show this a proper definition,
let~$n',m'\in \N$, $\lambda'_i, \sigma'_i \in M$,
$x'_i \in X$ and $y'_i \in Y$ be any elements such that
\begin{align*}
    \alpha(z) &\ =\ 
    h_1\Bigl(\lambda'_0 \ket{\kappa_1(\cdot)}
    \ovee \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}\Bigr) \\
        \beta(z) &\ =\  h_2 \Bigl(\sigma'_0 \ket{\kappa_2(\cdot)}
    \ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)}\Bigr).
\end{align*}
\spacingfix{}
\begin{point}{40}%
We have to show
\begin{multline}\label{convexpulgoal}
    h_3 \Bigl(
    \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
    \,\ovee\, \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)}\Bigr) \\
    \ = \ 
    h_3 \Bigl(
    \bigovee^n_{i=1} \lambda_i \ket{\kappa_2(y_i)}
        \,\ovee\, \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)}\Bigr).
\end{multline}
Without loss of generality,
    we may assume~$n,n',m,m' \geq 1$
    (as we allow, for instance,~$\lambda_1=0$).
Due to \eqref{aconv-epb-ass},
 it is clear~$\lambda_0 = \lambda_0'$ and~$\sigma_0=\sigma_0'$.
By \sref{elements-coprod-conv}
    we know there
    are derivations~$\Phi_1, \ldots, \Phi_l \in \mathcal{D}_M^2 (1+Y)$
    and~$\Psi_1, \ldots, \Psi_k \in \mathcal{D}_M^2 (X+1)$,
    say~$\Phi_i \equiv \bigovee_j \zeta_{ij} \ket{\varphi_{ij}}$,
    $\Psi_i \equiv \bigovee_j \xi_{ij} \ket{\psi_{ij}}$
    with
\begin{align*}
    \Phi_1 &\ = \ \ket{\,
    \lambda_0 \ket{\kappa_1(\cdot)}
\ovee \bigovee^{n}_{i=1} \lambda_i \ket{\kappa_2(y_i)} \,} &
    \Phi_l &\ = \ \ket{\,
    \lambda_0 \ket{\kappa_1(\cdot)}
\ovee \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)} \,} \\
    \Psi_1 &\ = \ \ket{\,
    \sigma_0 \ket{\kappa_2(\cdot)}
\ovee \bigovee^{m}_{i=1} \sigma_i \ket{\kappa_1(x_i)} \,} &
    \Psi_k &\ = \ \ket{\,
    \sigma_0 \ket{\kappa_2(\cdot)}
\ovee \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)} \,}.
\end{align*}
We are going to combine the~$\Phi_i$ and~$\Psi_i$
into a single derivation of~\eqref{convexpulgoal}
    by first `applying' the $\Phi_i$ and then
    the~$\Psi_i$.
Define~$\Omega_1, \ldots, \Omega_{l+k} \in \mathcal{D}_M^2 (X+Y)$ by
\begin{align*}
    \Omega_i  &\ = \ \bigovee_j\zeta_{ij} \ket{\omega_{ij}}
        &&\text{for $1 \leq i \leq l$}
    \\
    \Omega_{i+l}  &\ = \ \bigovee_j \xi_{ij} \ket{\omega_{(i+l)j}}
        &&\text{for $1 \leq i \leq k$,}
\end{align*}
where~$\omega_{ij} \in \mathcal{D}_M(X+Y)$
are given by
\begin{align*}
    \omega_{ij} (\kappa_2 (y)) &\ =\ \varphi_{ij}(\kappa_2(y))  \\
    \omega_{ij} (\kappa_1(x)) &\ = \ 
    \varphi_{ij}(\kappa_1(\cdot))\odot
    ( \rfrac{\psi_{11}(\kappa_1(x))}{\lambda_0}
    \ovee r(\kappa_1(x)))
    \\
    \omega_{(i+l)j} (\kappa_1(x)) &\ =\ \psi_{ij}(\kappa_1(x)) \\
    \omega_{(i+l)j} (\kappa_2 (y)) &\ =\ 
    \psi_{ij}(\kappa_2(\cdot)) \odot (
    \rfrac{\varphi_{l1}(\kappa_2(y))}{\sigma_0}
    \ovee r(\kappa_2(y))) \\
    r(z) & \ = \ 
    \begin{cases}
        (\rfrac{\lambda_0}{\lambda_0})^\perp & z = \kappa_1(x_1) \\
        (\rfrac{\sigma_0}{\sigma_0})^\perp & z = \kappa_2(y_1) \\
        0 & \text{otherwise},
    \end{cases}
\end{align*}
    where on the first two lines~$1 \leq i \leq l$
    and on the second two~$1 \leq i \leq k$.
Before we continue, we check whether the~$\omega_{ij}$
    are distributions, as claimed.
For~$1 \leq i \leq l$
    this amounts to $\bigovee_x \omega_{ij}(\kappa_1(x))
= \varphi_{ij}(\kappa_1(\cdot))$.
Indeed
\begin{align*}
\bigovee_x
    \omega_{ij}(\kappa_1(x))
    & \  =\  \varphi_{ij}(\kappa_1(\cdot)) \odot r(\kappa_1(x_1))
            \,\ovee\, \bigovee_x 
        \varphi_{ij}(\kappa_1(\cdot)) \odot
        \rfrac{\psi_{11}(\kappa_1(x))}{\lambda_0} \\
        & \  =\  \varphi_{ij}(\kappa_1(\cdot)) \odot (\rfrac{\lambda_0}{\lambda_0})^\perp
            \,\ovee \,
        \varphi_{ij}(\kappa_1(\cdot)) \odot
        \rfrac{\bigovee_x \psi_{11}(\kappa_1(x))}{\lambda_0} \\
        & \  =\  \varphi_{ij}(\kappa_1(\cdot)) \odot (\rfrac{\lambda_0}{\lambda_0})^\perp
            \,\ovee \,
        \varphi_{ij}(\kappa_1(\cdot)) \odot
        \rfrac{\lambda_0}{\lambda_0} \\
        & \  =\  \varphi_{ij}(\kappa_1(\cdot)).
\end{align*}
With an analogous argument, one checks~$\omega_{(i+l)j}$
    is a distribution for~$1 \leq i \leq k$.

To show~$\Omega_i$ is
    a derivation (in the sense of \sref{elements-coprod-conv}),
    first pick any~$1 \leq i < l$.
We distinguish between the two allowable derivation steps.
If~$ \mu(\Phi_i) = \mu(\Phi_{i+1}) $,
    then~$\mu(\Omega_i) = \mu(\Omega_{i+1})$
    by a straightforward computation
    and so~$\Omega_i$ has a valid step.
In the other case, we have~$\zeta_{ij} = \zeta_{(i+1)j}$ and
    for each~$j$ we have three possibilities.
In the first case, if~$\varphi_{ij} = \varphi_{(i+1)j}$,
    then clearly~$\omega_{ij} = \omega_{(i+1)j}$ as well.
    For the second case, assume~$\varphi_{ij} = (\mathcal{D}_M \kappa_2) (\chi)$
    and~$\varphi_{(i+1)j} = (\mathcal{D}_M \kappa_2) (\chi')$
    for some~$\chi,\chi' \in \mathcal{D}_M Y$
    with~$h_Y(\chi) = h_Y(\chi')$.
    Clearly~$\varphi_{ij}(\kappa_1(\cdot)) = 0$
    and so~$\omega_{ij} = (\mathcal{D}_M \kappa_2)(\chi)$.
    Similarly~$\omega_{(i+1)j} = (\mathcal{D}_M \kappa_2)(\chi')$.
    The third case is trivial.
    So~$\Omega_i$ also makes a valid step of the second kind.

With the same kind of argument, we cover
    $\Omega_{i+l}$ for~$1 \leq i < k$.
The only step left to check is the one
    from~$\Omega_l$ to~$\Omega_{l+1}$.
Note~$\zeta_{l1}=1$,~$\varphi_{l1}(\kappa_1(\cdot)) = \lambda_0$
and~$\lambda_0 \odot  (\rfrac{\lambda_0}{\lambda_0})^\perp = 0$,
so with some easy manipulation, we find
\begin{equation*}
    \Omega_l \ = \  \ket{
        \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
\, \ovee\,  \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)} }.
\end{equation*}
and in a similar fashion
\begin{align*}
    \Omega_{l+1} & \ = \  \ket{
        \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
    \, \ovee\,  \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)} } \\
    \Omega_{1} & \ = \  \ket{
        \bigovee^{n}_{i=1} \lambda_i \ket{\kappa_2(y_i)}
\,\ovee\, \bigovee^m_{i=1} \sigma_i \ket{\kappa_1(x_i)} } \\
    \Omega_{l+k} & \ = \  \ket{
        \bigovee^{n'}_{i=1} \lambda'_i \ket{\kappa_2(y'_i)}
    \,\ovee\, \bigovee^{m'}_{i=1} \sigma'_i \ket{\kappa_1(x'_i)} }.
\end{align*}
So~$\Omega_i$ is a valid derivation of \eqref{convexpulgoal}.
\end{point}
\begin{point}{50}%
We are in the home stretch now.
Define~$\gamma(z)$ as in \eqref{aconvmexpuldefgamma}.
It is easy to see~$\gamma$
    is the unique map with~$(\id+!) \after \gamma = \beta$
    and~$(!+\id)\after \gamma = \alpha$.
It remains to be shown~$\gamma$ is affine.
Write
\begin{equation*}
q_1\colon \mathcal{D}_M(X+Y) \to X+Y \quad
q_2\colon \mathcal{D}_M(1+Y) \to 1+Y \quad
q_3\colon \mathcal{D}_M(X+1) \to X+1
\end{equation*}
for the quotient maps used in the construction of the coproducts.
We worked hard to show
that
for all~$z \in Z$, $\varphi \in \mathcal{D}_M Y$,
$\psi \in \mathcal{D}_M X$, 
and~$\chi \in \mathcal{D}_M (X+Y)$
with~$\chi(\kappa_1 (y)) = \varphi(\kappa_1(y))$
and~$\chi(\kappa_2 (x)) = \psi(\kappa_2(x))$,
we have
\begin{equation*}
    \left.\begin{array}{ll}
    \alpha(z)\ =\ q_1(\varphi) \\
    \beta(z)\ =\ q_2(\psi)
    \end{array}\right] \quad \implies \quad
    \gamma(z) = q_3(\chi).
\end{equation*}
Assume~$z = h_Z(\bigovee_i \lambda_i \ket{z_i})$.
We want to show~$\gamma(z) = h_3(\bigovee_i \lambda_i \ket{\gamma(z_i)})$.
To this end, pick~$\varphi_i$, $\psi_i$, $\chi_i$
with~$\alpha(z_i) = q_1(\varphi_i)$,
$\beta(z_i) = q_2(\psi_i)$,
$\chi_i(\kappa_1(y)) = \varphi_i(\kappa_1(y))$
and $\chi_i(\kappa_2(x)) = \psi_i(\kappa_2(x))$.
So $\gamma(z_i) = q_3(\chi_i)$.
Define~$\varphi,\psi,\chi$ as follows.
\begin{align*}
\varphi &\ \equiv\  \mu\bigl(\bigovee_i \lambda_i \ket{\varphi_i}\bigr)&
\psi &\ \equiv\  \mu\bigl(\bigovee_i \lambda_i \ket{\psi_i}\bigr) &
\chi &\ \equiv\  \mu\bigl(\bigovee_i \lambda_i \ket{\chi_i}\bigr)
\end{align*}
Note
$q_1(\varphi)
    = h_1(\bigovee_i \lambda_i \ket{q_1(\varphi_i)})
    = h_1(\bigovee_i \lambda_i \ket{\alpha(z_i)})
    = \alpha(\bigovee_i \lambda_i \ket{z_i})
    = \alpha(z)$.
Similarly~$q_2(\psi) = \beta(z)$.
For any~$y \in Y$,
    we have
    $
    \chi(\kappa_1(y))
    = \bigovee_i \lambda_i \odot \chi_i(\kappa_1(y))
    = \bigovee_i \lambda_i \odot \varphi_i(\kappa_1(y))
    = \varphi(\kappa_1(y))
    $.
Similarly~$\chi(\kappa_2(x)) = \psi(\kappa_2(x))$ for any~$x \in X$.
So~$\gamma(z) = q_3(\chi)$ and consequently
\begin{equation*}
    \gamma(z) \ = \ q_3(\chi)
    \ = \ h_3\bigl(\bigovee_i \lambda_i\ket{q_3(\chi_i)} \bigr)
    \ = \ h_3\bigl(\bigovee_i \lambda_i\ket{\gamma(z_i)} \bigr),
\end{equation*}
as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}

\section{Effectuses with quotients}
\begin{parsec}{1970}%
\begin{point}{10}%
    We return to the main program
        of this chapter: the attempted axiomatisation
        of the effectus~$\op\vN$.
\end{point}
\begin{point}{20}[dfn-quotient]{Definition}%
Let~$C$ be an effectus.
We say~$C$ is an \Define{effectus with quotients}
    \index{effectus!with quotients}
    \index{*bra@$X/_p$}
    if for each predicate~$p \colon X \to 1$,
    there exists a map~$\xi_p \colon X \to X/_p$
    with~$1 \after \xi_p \leq p^\perp$
    satisfying the following universal property.
\begin{quote}
    For any map~$f\colon X \to Y$
        with~$1 \after f \leq p^\perp$,
        there is a unique map~$f' \colon X/_p \to Y$
        such that~$f' \after \xi_p = f$.
\end{quote}
Any  map with this universal property
    is called a \Define{quotient} for~$p$.
    \index{quotient}
\begin{point}{21}{Remarks}%
The universal property of quotients
    is essentially the same as
    the universal property of (contractive) \emph{compressions},
    which we proposed in~\cite{westerbaan2016universal}.
Effectuses with quotients also appear in~\cite{effintro}.
\end{point}
\begin{point}{30}[quot-not]{Notation}%
    Unless otherwise specified~\Define{$\xi_p$}\index{*xi@$\xi_p$}
    will denote some quotient for~$p$.
\end{point}
\end{point}
\begin{point}{40}{Examples}%
In~$\op{\vN}$ quotients are exactly the same thing
    as contractive filters,
    see~\sref{dils-def-filter}, \sref{filter}
    and~\sref{canonical-filter}.
An example of a quotient map for~$1-a \in \scrA$ is given
    by~$\xi\colon \ceil{a}\scrA \ceil{a} \to \scrA$
    with~$\xi(b) = \sqrt{a} b \sqrt{a}$.
\begin{point}{41}%
The effectus~$\op\EJA$ has quotients,
    which are in essence very similar to those of~$\op\vN$,
    when ignoring the technical complications Jordan algebras
    impose. \cite[prop.~25]{eja}
\end{point}
\begin{point}{42}[opous-quotients]%
The effectus~$\op\OUS$ has quotients,
    which are rather different from the previous two examples.
An example of a  quotient for a predicate~$v$ on an order unit space~$V$
    is given by the inclusion of the order ideal generated by~$1-v$
\begin{equation*}
    \langle 1-v\rangle \ \equiv \ \{
        a; \ a\in V; \ \exists n.\, -n (1-v) \leq a \leq n (1-v) \}
    \ \subseteq\  V,
\end{equation*}
where the order ideal is considered as an order unit space
    with order-unit~$1-v$.
    The effectus~$\op\OUG$ has very similar quotients. See~\cite{effintro}.
\end{point}
\end{point}
\begin{point}{50}[quotient-basics]{Exercise}%
Verify the following basic properties of quotients.
    (See~\cite{effintro}.)
\begin{enumerate}
    \item If~$\xi\colon X \to Y$ is a quotient for~$p$
                and~$\vartheta\colon Y \to Z$ is an isomorphism,
                then~$\vartheta \after \xi$ is a quotient for~$p$
                as well.
    \item Conversely, if~$\xi_1$ and~$\xi_2$
            are both quotients for~$p$,
            then there is a unique isomorphism~$\vartheta$
            with~$\xi_1 = \vartheta \after \xi_2$.
    \item Isomorphisms are quotients (for 0).
    \item Maps into~$0$ are quotients (for 1).
    \item If~$\xi$ is a quotient for~$p$, then~$1\after \xi = p^\perp$
                (Hint: apply the universal property to $p^\perp$).
    \item Quotients are epic.
\end{enumerate}
\spacingfix{}
\begin{point}{60}%
The following proposition is easy to prove,
    but shows an important property of quotients:
    any map~$f$ factors as a total map after a quotient
    for~$(1\after f)^\perp$.
\end{point}
\end{point}
\begin{point}{70}[quotient-total]{Proposition}%
Assume~$\xi_{p^\perp} \colon X \to X/_{p^\perp}$ is a quotient for~$p^\perp$.
For any~$f\colon X \to Z$
    with~$1 \after f = p$,
    there is a unique \emph{total} $g\colon X/_{p^\perp} \to Z$
    with~$f = g \after \xi_{p^\perp}$.
\begin{point}{80}{Proof}%
(This is a simplified version of our previous
    proof in~\cite{effintro}.)
By definition of quotient, there is a unique~$g\colon X/_{p^\perp} \to Z$
    with~$g \after \xi_{p^\perp} = f$.
Note~$1 \after g \after \xi_{p^\perp} = 1 \after f = p = 1 \after \xi_{p^\perp}$.
Thus, as~$\xi_{p^\perp}$ is epi (\sref{quotient-basics}),
    we conclude~$1 \after g = 1$.
That is: $g$ is total. \qed
\end{point}
\end{point}
\begin{point}{90}[quotients-composition]{Proposition}%
In an effectus with quotients,
    quotients are closed under composition.
\begin{point}{100}{Proof}%
(This is essentially the same proof as we gave in~\cite{effintro}.)
Assume~$\xi_1\colon X \to Y$ is a quotient for~$p^\perp$
    and~$\xi_2\colon Y \to Z$ is a quotient for~$q^\perp$.
We will prove~$\xi_2 \after \xi_1$
    is a quotient for~$(q \after \xi_1)^\perp$.
As our effectus has quotients,
    we can pick a quotient~$\xi \colon X \to X/_{(q \after \xi_1)^\perp}$
        of~$(q \after \xi_1)^\perp$.
First, some preparation.
Note~$1 \after \xi = q \after \xi_1 \leq 1 \after \xi_1 = p$.
Thus by the universal property of~$\xi_1$,
there is a unique map~$h_1\colon Y \to X/_{(q \after \xi_1)^\perp}$
        with~$h_1 \after \xi_1 = \xi$.
As~$1 \after h_1 \after \xi_1 = 1 \after \xi = q \after \xi_1$
    and~$\xi_1$ is epi, we see~$1 \after h_1 = q$.
Thus by \sref{quotient-total},
there is a unique total map~$h_2 \colon Z \to X/_{(q \after \xi_1)^\perp}$
    with~$h_2 \after \xi_2 = h_1$.
Let~$g\colon X/_{(q \after \xi_1)^\perp} \to Z$
    be the unique map such that~$g \after \xi = \xi_2 \after \xi_1$.
We are in the following situation.
\begin{equation*}
    \xymatrix@C+2pc{
        X  \ar[r]^{\xi_1} \ar@/_/[rrd]_{\xi}
        & Y \ar[r]^{\xi_2} \ar@{.>}[rd]_{h_1}
        & Z \ar@{.>}@/^/[d]^{h_2} \\
        && X/_{(q \after \xi_1)^\perp} \ar@{.>}@/^/[u]^{g}
    }
\end{equation*}
We claim~$g$ and~$h_2$ are each other's inverse.
Indeed: from $g \after h_2 \after \xi_2 \after \xi_1= g \after \xi = \xi_2 \after \xi_1$
    we get~$g \after h_2 = \id$
    and from~$h_2 \after g \after \xi = h_2 \after \xi_2 \after \xi_1 = \xi$
    we find~$h_2 \after g = \id$.
Thus~$\xi_2 \after \xi_1 = g \after \xi$ for an isomorphism~$g$,
which shows~$\xi_2 \after \xi_1$ is a quotient, see \sref{quotient-basics}. \qed
\end{point}
\end{point}
\begin{point}{110}[quot-fact-system]{Exercise}
By \sref{quotient-total} we know that each
    map~$f$ in an effectus with quotients factors as~$t \after \xi$
    for some total map~$t$ and quotient~$\xi$.
Show that this forms an orthogonal factorization system (cf.~\cite{korostenski1993factorization}) ---
    that is: prove that if~$t' \after \xi' = t \after \xi$
    for some quotient~$\xi'$ and total map~$t'$,
    then there is a unique isomorphism~$\vartheta$
    with~$\xi' = \vartheta \after \xi$
    and~$t = t' \after \vartheta$.
\end{point}
\end{parsec}

\begin{parsec}{1980}%
\begin{point}{10}%
In \sref{quot-fact-system} we saw
    that every  map~$f$
    factors uniquely via a quotient for~$(1 \after f)^\perp$.
In this sense quotients are the universal way to restrict to the
    support on the domain --- so why do we call them quotients
    instead of, say, initial-support-maps?
We answer this question in~\sref{bartequivquotrem},
    but need some preparation first.
\end{point}
\begin{point}{20}[dfn-eff-grothendieck]{Definition}%
For an effectus~$C$,
    write~$\Define{\int \Pred_\square}$
    \index{$\int \Pred_\square$}
    for the category with
\begin{enumerate}
\item as objects pairs~$(X,p)$,
        where~$X$ is an object of~$C$
        and~$p \in \Pred X$ and
\item
    an morphism between~$(X,p)$ and~$(Y,q)$
    corresponds to a partial map~$f\colon X \to Y$ in~$C$
       for which we have~$p \leq (q^\perp \after f)^\perp$.
\end{enumerate}
Write~$U\colon \int \Pred_\square \to C$
for the forgetful functor --- that is:~$U(X,p) = X$
and~$Uf = f$ for arrows~$f$.
The functor~$U$ has left- and right-adjoint
    $0 \dashv U \dashv 1$
    with
    $0,1 \colon C \to \int \Pred_\square$
    given by~$0X = (X,0)$, $1X = (X,1)$
    and~$0f=1f=f$.
\end{point}
\begin{point}{30}[exc-quot-adjoint]{Exercise*}%
Show that for an effectus~$C$, the following are equivalent.
\begin{enumerate}
\item $C$ has quotients.
\item The functor~$0\colon C \to \int \Pred_\square$,
        has a left-adjoint~$Q \colon \int\Pred_\square \to C$.
\end{enumerate}
\spacingfix{}
\end{point}
\begin{point}{40}[bartequivquotrem]%
If the existence of a left adjoint~$Q$ to~$0$
    gives quotients,
    what does the existence of a right adjoint~$K$ to~$1$ amount to?
    It will turn out (\sref{compr-grothendieck})
    this is equivalent to the existence of
        so-called \emph{comprehensions},
        the topic of the next section.
With both quotients and comprehension, we have a chain of four adjunctions:
\begin{equation*}
   \vcenter{\xymatrix{
\int \Pred_\square \ar[d]_{\dashv\;}^{\;\dashv}
   \ar@/_6ex/[d]^{\;\dashv}_{Q} 
   \ar@/^6ex/[d]_{\dashv\;}^{K} \\
   C\ar@/^3ex/[u]^(0.4){0\!}\ar@/_3ex/[u]_(0.4){\!1}
}} 
\end{equation*}
There are numerous other examples
    of categories which also
    have such a chain of four adjunctions
    between it and a natural category of object-with-predicates.
    See \cite{cho2015quotient} for several examples.
    In most of these examples, the predicates correspond to subspaces
        and the left-most functor to quotienting by this subspace.
    This is the reason for the name `effectus with quotients'.
\begin{point}{50}%
Originally, we considered the universal properties of
    quotients and comprehensions separately and under different names.
It was Jacobs who recognized that both universal properties
    appear together in a chain of adjunctions.
\end{point}
\end{point}
\end{parsec}

\section{Effectuses with comprehension and images}
\begin{parsec}{1990}%
\begin{point}{10}%
We continue with the formal introduction
        of our second axiom:
        the existence of~\emph{comprehension}.
\end{point}
\begin{point}{20}[dfn-comprehension]{Definition}%
Let~$C$ be an effectus.
We say~$C$ \Define{has comprehension}
    \index{effectus!with comprehension}%
    \index{*acc@$\cmpr{X}{p}$}%
    if for each predicate~$p \colon X \to 1$,
    there exists a map~$\pi_p \colon \cmpr{X}{p} \to X$
    with~$p \after \pi_p = 1 \after \pi_p$
    satisfying the following universal property.
\begin{quote}
    For any map~$g\colon Z \to X$
        with~$p \after g = 1 \after g$,
        there is a unique map~$g' \colon Z \to \cmpr{X}{p}$
        such that~$\pi_p \after g' = g$.
\end{quote}
Any  map with this universal property
    is called a \Define{comprehension} for~$p$.
    \index{comprehension}
\begin{point}{30}{Beware}%
    We do not assume comprehensions are total
    (in contrast to~\cite{effintro}.)
    In~\sref{compr-total} we will see that
    in an effectus with quotients, comprehensions must be total.
\end{point}
\begin{point}{31}{Remarks}%
The universal property of comprehensions is essentially the same
    as the universal property of (contractive) \emph{corners},
    which we proposed in~\cite{westerbaan2016universal}.
Effectuses with compression also appear in~\cite{effintro}.
In partial form, comprehensions are
    essentially the same
    as categorical kernels, see~\sref{compr-is-kernel} later on.
\end{point}
\begin{point}{40}[compr-not]{Notation}%
    Unless otherwise specified~\Define{$\pi_p$}\index{*pi@$\pi_p$}
        will denote some comprehension of~$p$.
\end{point}
\end{point}
\begin{point}{50}{Examples}%
In~$\op{\vN}$ comprehensions are exactly the same thing
    as corners, see \sref{dils-corner} or \sref{corner}.
An example of a comprehension for~$a \in \scrA$
    is given by~$\pi\colon \scrA \to \floor{a}\scrA\floor{a}$
    with~$\pi(b) = \floor{a}b\floor{a}$
    as proven in \sref{prop-corner}.
\begin{point}{51}%
The effectus~$\op\EJA$ also has comprehension,
    which is very similar to those of~$\op\vN$.~\cite[prop.~24]{eja}

The comprehension maps of~$\op\OUS$ are again quite different
    from those of~$\op\vN$ and~$\op\EJA$.
Confusingly, a comprehension for a predicate~$v$
    of an order unit space~$V$
    is given by the vector-space-quotient
    map~$q\colon V \to V/_{\langle1-v\rangle}$,
    where~$\langle 1-v \rangle$ is the order ideal generated
    by~$1-v$ defined in~\sref{opous-quotients}.
The effectus~$\op\OUG$ has similar comprehension.
    See~\cite{effintro}.

Any extensive category with final object has comprehension,
    which includes~$\SET$, $\bCH$ and~$\CRng$,
    see~\cite{effintro}.
\end{point}
\end{point}
\begin{point}{60}[compr-grothendieck]{Exercise*}%
    Show that an effectus~$C$ has comprehension if and only
        if the functor~$1 \colon C \to \int \Pred_\square$
        from \sref{dfn-eff-grothendieck}
        has a right adjoint~$K$.
\end{point}
\begin{point}{70}[compr-basics]{Exercise}%
Show the following basic properties of comprehensions.
    (See~\cite{effintro}.)
\begin{enumerate}
    \item If~$\pi\colon X \to Y$ is a comprehension for~$p$
                and~$\vartheta\colon Z \to X$ is an isomorphism,
                then~$\pi \after \vartheta$ is a comprehension for~$p$
                as well.
    \item Conversely, if~$\pi_1$ and~$\pi_2$
            are both comprehensions for~$p$,
            then there is a unique isomorphism~$\vartheta$
            with~$\pi_1 = \pi_2 \after \vartheta$.
    \item Isomorphisms are comprehensions (for 1).
    \item Zero maps are comprehensions (for 0).
    \item Comprehensions are monic.
    \item $p^\perp \after \pi = 0$ if~$\pi$ is a comprehension for~$p$.
\end{enumerate}
\end{point}
\end{parsec}
\spacingfix{}
\begin{parsec}{2000}%
\begin{point}{10}%
Comprehensions and categorical kernels are very similar.
\end{point}
\begin{point}{20}{Definition}%
Let~$C$ be a category with a zero object.
    A \Define{(categorical) kernel}~of an arrow~$f$
    \index{kernel!category theoretic}
    (in symbols: $\Define{\ker f}$)
    \index{kerf@$\ker f$}
    is an equalizer of~$f$ with the parallel zero map.
(That is: $f \after (\ker f) = 0$
    and for every~$g$ with~$f \after g = 0$,
    there exists a unique~$g'$ with~$(\ker f) \after g' = g$.)
We will use \Define{$\cok f$}
    \index{$\cok f$}
    to denote a cokernel of~$f$
    --- that is: a kernel of~$f$ in~$\op{C}$.
\end{point}
\begin{point}{30}[effectus-kernels]{Proposition}%
An effectus with comprehension has all kernels.
    The kernel of a map~$f$ is given by
        a comprehension~$\pi_{(1 \after f)^\perp}$
        for~$(1 \after f)^\perp$.
\begin{point}{40}{Proof}%
Clearly~$1 \after f \after \pi_{(1 \after f)^\perp} = 0$
    and so~$f \after \pi_{(1 \after f)^\perp} = 0$.
Assume~$g$ is any map with~$f \after g = 0$.
Then~$1 \after f \after g = 0$
    and so~$(1 \after f)^\perp \after g = 1 \after g$.
Thus there exists a unique~$g'$
    with~$\pi_{(1 \after f)^\perp} \after g' = g$. \qed
\end{point}
\end{point}
\begin{point}{50}[compr-is-kernel]{Exercise}%
Show that in an effectus,
    a map~$f$ is a comprehension for~$p$
    if and only if it is a kernel of~$p^\perp$.
\end{point}
\end{parsec}

\begin{parsec}{2010}%
\begin{point}{10}%
We are ready to define purity in effectuses.
\end{point}
\begin{point}{20}{Definition}%
In an effectus a map~$f$ is called \Define{pure}
    \index{pure!in an effectus}
    if~$f = \pi \after \xi$
    for some comprehension~$\pi$
    and quotient~$\xi$.
\end{point}
\begin{point}{30}{Example}%
Due to \sref{pure-fundamental}
    pure maps in~$\op\vN$
    are precisely the pure maps
    as defined in~\sref{dils-def-pure}
    and~\sref{pure}.

The pure maps~$\scrB(\scrH) \to \scrB(\scrK)$
    are exactly the maps of the form~$\ad_T$
    where~$T$ is a contractive map~$\scrK \to \scrH$.
\end{point}
\begin{point}{40}{Remark}%
In the previous chapter
    we discussed (in \sref{dils-pure-discussion})
    why some more familiar notions of purity for states,
    like extremality,
    do not generalize properly to arbitrary maps.
Recently, three other definitions of purity
        have been proposed in different contexts.
        \cite{cunningham2017purity,chiribella2014distinguishability,selby2017leaks}
All three are inspired by the essential uniqueness
    of purification (see \sref{ess-uniq-pur})
    and require a monoidal structure to state.
The identity map might not be pure
    in the sense of~\cite{chiribella2014distinguishability},
    which is too restrictive for our taste.
Hazarding a guess,
    it seems likely
    that~\cite{cunningham2017purity} considers maps pure which we don't
     and that \cite{selby2017leaks} does not contain all our pure maps.
The exact relation between
 our definition of pure
    and~\cite{cunningham2017purity,selby2017leaks}
    is left open.
\end{point}
\begin{point}{50}%
We do not have a good handle on the structure of pure maps in
    an arbitrary effectus.  We will need a few additional assumptions.
\end{point}
\end{parsec}

\begin{parsec}{2020}%
\begin{point}{10}{Definition}%
Let~$C$ be an effectus.
\begin{enumerate}
\item
    We say~$C$ has \Define{images}\index{effectus!with images}
    if for each map~$f\colon X \to Y$,
    there is a least predicate~$\Define{\IM f}$ on~$Y$
        \index{im@$\IM$, $\IMperp$}
        with the property~$(\IM f) \after f = 1 \after f$ ---
        that is, 
    for every predicate~$p$ on~$Y$
    with~$p \after f = 1 \after f$,
    we must have~$\IM f \leq p$.
For brevity, write~$\Define{\IMperp f} \equiv (\IM f)^\perp$. 
Note~$\IMperp f$ is the greatest predicate
with the property~$(\IMperp f) \after f = 0$.
\item
We say a map~$f\colon X \to Y$ is \Define{faithful}
    \index{faithful}
    if~$\IM f = 1$.
That is: $f$ is faithful if and only if
    $p \after f = 0$ implies~$p = 0$
    for every predicate~$p$.
\end{enumerate}
\spacingfix{}
\begin{point}{20}{Notation}%
The expression~$\IM f \after g$
    is read as~$\IM (f \after g)$.
\end{point}
\begin{point}{30}{Remarks}%
The predicate~$\IM f$ will play for comprehension the same role
    as~$1 \after f$ plays for quotients.
Similarly faithful is the analogue of total.
Images in effectuses are also studied in \cite{effintro}.
\end{point}
\end{point}
\begin{point}{40}{Examples}%
In $\op{\vN}$ the image of a map~$f\colon \scrA \to \scrB$
    is given by the least projection~$e \in \scrA$
    with the property~$f(1-e) = 0$.
The map~$f$ is faithful if and only
    if~$f(a^*a)=0$ implies~$a^*a = 0$
    for all~$a\in \scrA$.
\begin{point}{41}%
The effectus~$\op\EJA$ also has all images,
    which are defined similarly, see~\cite[prop.~29]{eja}.
In contrast, the effectuses~$\op\OUG$ and~$\op\OUS$
    do not have all images, see~\cite{effintro}.
\end{point}
\end{point}
\begin{point}{50}[im-ineq]{Exercise}%
Show~$\IM f \after g \leq \IM f$.
Conclude~$\IM f \after \alpha = \IM f$
    for any iso~$\alpha$.
\end{point}
\begin{point}{60}[exc-quot-faithful]{Exercise}%
Show that in an effectus, any quotient is faithful.
\end{point}
\begin{point}{70}%
In contrast to quotients,
    it is not clear at all whether (without additional assumptions)
    comprehensions are total;
    they are part of a factorization system
    or are closed under composition.
\end{point}
\begin{point}{80}[compr-total]{Lemma}%
In an effectus with quotients, comprehensions are total.
\begin{point}{90}{Proof}%
Assume~$\pi$ is some comprehension for~$p$.
Let~$\xi$ be a quotient for~$(1 \after \pi)^\perp$.
There is a total~$\pi_t$ with~$\pi = \pi_t \after \xi$.
As~$ 1 \after \pi_t \after \xi
        = 1 \after \pi
        = p \after \pi
        = p \after \pi_t \after \xi$
        and~$\xi$ is epi,
        we see~$1 \after \pi_t = p \after \pi_t$.
Thus, as~$\pi$ is a comprehension for~$p$,
    there exists an~$f$ with~$\pi_t = \pi \after f$.
Now~$\pi = \pi_t \after \xi = \pi \after f \after \xi$
    and so~$\id = f \after \xi$, since~$\pi$ is mono.
Hence~$1 = 1 \after \id =1 \after f \after \xi \leq 1 \after \xi = 1 \after \pi$
    and so~$\pi$ is total. \qed
\end{point}
\end{point}
\end{parsec}
\subsection{Sharp predicates}
\begin{parsec}{2030}%
\begin{point}{10}{Definition}%
Let~$C$ be an effectus with comprehension and images.
\begin{enumerate}
\item
    We say a predicate~$p$ is (image) \Define{sharp} \index{sharp}
        if~$p = \IM f$ for some map~$f$.
        Write~$\Define{\SPred X}$ for the set of all sharp predicates on~$X$.
        \index{SPred@$\SPred X$}
\item
    We define~$\Define{\floor{p}} = \IM \pi_p$, \index{*floor@$\floor{\ }$, floor}
    where~$\pi_p$ is some comprehension for~$p$.
(Comprehensions for the same predicate have the same image
    by \sref{im-ineq}.)
Also write~$\Define{\ceil{p}} = \floor{p^\perp}^\perp$.
    \index{*floorc@$\ceil{\ }$, ceiling}
\end{enumerate}
\spacingfix{}
\begin{point}{20}{Beware}%
In \cite{effintro} $p$ is called sharp whenever~$p \wedge p^\perp=0$.
In general this is weaker than image-sharpness, which we use in this text.
In~\sref{floor-basics}
    we will see~$\floor{p}$ is sharp.
It is unclear whether~$\ceil{p}$ is sharp (without additional
    assumptions).
\end{point}
\end{point}
\begin{point}{30}{Example}%
In $\op{\vN}$ the sharp predicates are the projections.
For a predicate~$a \in \scrA$,
    the sharp predicate~$\ceil{a}$
    is the least projection above~$a$.
\end{point}
\begin{point}{40}[floor-basics]{Lemma}%
In an effectus with comprehension and images, we have
\begin{multicols}{2}
\begin{enumerate}
\item
    $\floor{p} \leq p$
\item
    $\pi_p = \pi_{\floor{p}} \after \alpha$
        for some iso~$\alpha$;
\item
    $\floor{\floor{p}} = \floor{p}$;
\item
    $p \leq q$ $\implies$ $\floor{p} \leq \floor{q}$;
\item
    $\ceil{p} \after f \leq \ceil{p \after f}$ \emph{and}
\item
    $\ceil{p} \after f =0$ iff~$p \after f = 0$,
\end{enumerate}
\end{multicols}
\noindent for any map~$f\colon X \to Y$,
    predicates~$p,q$ on~$X$ and
$\pi_p$ and~$\pi_{\floor{p}}$
    comprehensions for~$p$ and~$\floor{p}$ respectively.
\begin{point}{50}{Proof}%
We will prove the statements in listed order.
\begin{point}{60}{Ad 1}%
    Let~$\pi$ be a comprehension for~$p$.
    By definition~$p \after \pi = 1 \after \pi$.
    Thus~$\floor{p} = \IM \pi \leq p$, as desired.
\end{point}
\begin{point}{70}{Ad 2}%
It is sufficient to show~$\pi_p$ is a comprehension for~$\floor{p}$.
First, note~$\floor{p}\after \pi_p = (\IM \pi_p) \after \pi_p = 1 \after \pi_p$.
To show the universal property,
    assume~$g\colon Z \to X$
    is some map with~$\floor{p} \after g = 1 \after g$.
Then~$1 \after g = \floor{p} \after g \leq p \after g \leq 1 \after g$
    and so~$1 \after g = p \after g$.
As~$\pi_p$ is a comprehension for~$p$,
    there is a unique~$g'$ with~$\pi_p \after  g' = g$
    and so~$\pi_p$ is indeed a comprehension for~$\floor{p}$ as well.
\end{point}
\begin{point}{80}{Ad 3}%
Follows from the previous point and \sref{im-ineq}.
\end{point}
\begin{point}{90}{Ad 4}%
Pick a comprehension~$\pi_p$ for~$p$ and~$\pi_q$ for~$q$.
Note~$1 \after \pi_p = p \after \pi_p
                \leq q \after \pi_p \leq 1 \after \pi_p $
so~$q \after \pi_p = 1 \after \pi_p$
and thus~$\pi_p = \pi_q \after f$ for some~$f$.
By~\sref{im-ineq}
    we see~$\floor{p} = \IM \pi_p = \IM \pi_q \after f \leq \IM \pi_q = \floor{q}$.
\end{point}
\begin{point}{100}{Ad 5}%
Clearly~$p \after f \after \pi_{(p \after f)^\perp} = 0$.
(Recall our convention \sref{compr-not} for $\pi$'s.)
Thus there is some~$h$
with~$f \after \pi_{(p \after f)^\perp} = \pi_{p^\perp}\after h$.
By point 2 there is some (isomorphism)~$\alpha$
    with~$\pi_{p^\perp} =\pi_{\floor{p^\perp}} \after \alpha$.
    We compute
\begin{equation*}
    \ceil{p} \after f \after \pi_{(p \after f)^\perp}
        = \ceil{p} \after \pi_{p^\perp}\after h
        = \ceil{p} \after \pi_{\floor{p^\perp}}\after \alpha\after h
    = \ceil{p} \after \pi_{\ceil{p}^\perp}\after \alpha\after h
    = 0.
\end{equation*}
Thus~$\ceil{p} \after f \leq \IMperp \pi_{(p \after f)^\perp}
= \lfloor(p \after f)^\perp\rfloor^\perp = \ceil{p \after f}$, as promised.
\end{point}
\begin{point}{110}{Ad 6}%
Assume~$\ceil{p}\after f = 0$.
From~$p \leq \ceil{p}$
it follows~$p \after f \leq \ceil{p} \after f = 0$.
Thus~$p \after f = 0$.
For the converse, assume~$p \after f = 0$.
Then~$\ceil{p \after f} = \ceil{0} = (\IM \id)^\perp = 0$
    as~$\id$ is a comprehension for~$1$.
    Thus~$\ceil{p} \after f \leq \ceil{p \after f} = 0$. \qed
\end{point}
\end{point}
\end{point}
\begin{point}{120}[img-of-compr]{Exercise}%
Let~$C$ be an effectus with comprehension and images.
Show that~$p$ is sharp if and only if~$\floor{p}= p$.
Conclude~$\IM \pi_s = s$ for sharp~$s$.
\end{point}
\begin{point}{130}[ceiling-within-ceiling]{Exercise}%
Show that in an effectus with comprehension and images
    we have the equality
    $\ceil{\ceil{p}\after f} = \ceil{p \after f}$
    for any map~$f\colon X \to Y$ and predicate~$p$ on~$X$.
\end{point}
\begin{point}{140}[img-tupling]{Exercise}%
Show that in an effectus with
images~$\IM \left<f,g \right> = [\IM f, \IM g]$.
Conclude that a predicate~$[p,q]$ is sharp
    if and only if~$p$ and~$q$ are sharp.
\end{point}
\end{parsec}

\begin{parsec}{2040}%
\begin{point}{10}[compr-is-full]{Lemma}%
In an effectus with comprehension and images
    we have
\begin{equation*}
    s \leq t
    \quad \iff \quad
    \pi_s = \pi_t \after h
    \quad \text{for some $h$},
\end{equation*}
for all sharp predicates~$s,t$ on the same object.
\begin{point}{20}{Proof}%
(This simpler proof than ours in~\cite{effintro}.)
Assume~$\pi_s = \pi_t \after h$.
Then
\begin{equation*}
    s \ \overset{\sref{img-of-compr}}{=}\  \floor{s} \ =\  \IM \pi_s \  = \ \IM \pi_t \after h
    \ \overset{\sref{im-ineq}}{\leq} \ \IM \pi_t = \floor{t} 
            \ \overset{\sref{img-of-compr}}{=} \ t.
\end{equation*}
as desired.
Conversely assume~$s \leq t$.
Then~$t^\perp \after \pi_s \leq s^\perp \after \pi_s = 0$
    and so~$\pi_s = \pi_t \after h$
    for some~$h$ by the universal property of~$\pi_t$. \qed
\end{point}
\end{point}
\begin{point}{30}{Lemma}%
In an effectus with images,
    we have~$\IM [f,g] = (\IM f) \vee (\IM g)$.
\begin{point}{40}{Proof}%
We get~$\IM[f,g] \geq \IM f$ and~$\IM[f,g] \geq \IM  g$
    from
\begin{align*}
    [1 \after f, 1 \after g] 
        &\ =\  1 \after [f,g]  \\ 
        &\ =\ (\IM [f,g]) \after [f,g] \\
        & \ = \  [(\IM [f,g]) \after f, (\IM [f,g]) \after g].
\end{align*}
To show~$\IM [f,g]$ is the least upper-bound,
assume~$p \geq \IM f$ and~$p \geq \IM g$.
Then
\begin{equation*}
    1 \after [f,g] \ \geq\ p \after [f,g] \ =\  [p \after f, p \after g]
                    \ \geq\  [(\IM f) \after f, (\IM g)\after g]
                    \ = \ 1 \after [f,g],
\end{equation*}
    hence~$1 \after [f,g] = p \after [f,g]$
    and so~$p \geq \IM [f,g]$, as desired. \qed
\end{point}
\begin{point}{50}[lattice-compr]{Corollary}%
In an effectus with comprehension and images,
we have for any sharp~$s,t$
    a supremum (among all predicates)
    given by~$s \vee t = \IM[\pi_s, \pi_t]$.
    In particular:~$s \vee t$ is sharp.
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{2050}%
\begin{point}{10}%
In \sref{compr-is-kernel} we saw that comprehensions
    are precisely kernels of predicates.
What about cokernels and quotients?
\end{point}
\begin{point}{20}[effectus-cokernels]{Proposition}%
An effectus with quotients and images has all cokernels.
A cokernel of a map~$f$
    is given by a quotient~$\xi_{\IM f}$ of~$\IM f$.
\begin{point}{30}{Proof}%
As~$0 = (\IMperp f) \after f = 1 \after \xi_{\IM f} \after f$,
        we have~$\xi_{\IM f} \after f = 0$.
    Assume~$g$ is a map with~$g \after f = 0$.
Then~$1 \after g \leq \IMperp f$
    and so~$g = g' \after \xi_{\IM f}$
    for a unique~$g'$.
Thus indeed, $\xi_{\IM f}$ is a cokernel of~$f$. \qed
\end{point}
\end{point}
\begin{point}{40}[exc-cokernels]{Exercise}%
Show that in an effectus with comprehension and images,
    a map~$f$ is a quotient of sharp~$s$
    if and only if~$f$ is a cokernel
    of a comprehension~$\pi_s$ of~$s$.
\end{point}
\end{parsec}

\section{\texorpdfstring{$\diamond$-effectuses}{%
                    diamond-effectuses}}
\begin{parsec}{2060}%
\begin{point}{10}%
In quantum physics it is not uncommon to restrict one's attention
    to sharp predicates (i.e.~projections).
Does this restriction hurt the expressivity?
It does not: every (normal) state on a von Neumann algebra
        is determined by its values on projections.
In fact, on~$\scrB(\scrH)$ with~$\dim \scrH \geq 3$,
    Gleason's famous theorem states that every
    measure on the projections extends uniquely to a state.
We take the idea of restricting oneself to projections
    one step further: we also want to restrict to projections
    for our outcomes.
It is rare for quantum processes to send projections to projections
    (see \sref{exa-sharp-vn}),
    so instead we consider the least projection above the outcome.
The simple idea of taking the restriction to sharp predicates
    seriously leads to a host of interesting new notions.
We will give these right off the bat and study their relevance later on.
\end{point}
\begin{point}{20}[diamond-basics]{Definition}%
    A~\Define{$\diamond$-effectus} (``diamond effectus'')
    \index{effectus!$\diamond$-}
    \index{*dia@$\diamond$, diamond!-effectus}
    is an effectus with quotients, comprehension and images
    such that~$s^\perp$ is sharp for every sharp predicate~$s$.
In a~$\diamond$-effectus,
    define for~$f\colon X \to Y$
    the following restrictions to sharp predicates.
    \begin{equation*}
        \xymatrix{
            \SPred X  \ar@/^/[r]^{f_\diamond}
            & \SPred Y \ar@/^/[l]^{f^\diamond}}
            \quad \text{by} \quad
            \Define{f^\diamond(s)} = \ceil{s \after f}
            \index{*par1@$(\ )_\diamond$, $(\ )^\diamond$}
            \quad
            \text{and}
            \quad
            \Define{f_\diamond(s)} = \IM f \after \pi_s
    \end{equation*}
    \begin{enumerate}
        \item
    We say maps~$f \colon X \leftrightarrows Y\colon g$
        are~\Define{$\diamond$-adjoint}
        if~$f^\diamond = g_\diamond$.
    \index{*dia@$\diamond$, diamond!-adjoint}
    \item
    An endomap~$f\colon X \to X$ is \Define{$\diamond$-self-adjoint}
        if~$f$ is $\diamond$-adjoint to itself.
    \index{*dia@$\diamond$, diamond!-self-adjoint}
    \item
    Two maps~$f,g\colon X \to Y$
        are~\Define{$\diamond$-equivalent}
        if~$f^\diamond = g^\diamond$
        (or equivalently whenever~$f_\diamond = g_\diamond$,
                see~\sref{diamond-equiv-equiv}.)
            \index{*dia@$\diamond$, diamond!-equivalent}
    \item
        A pure endomap~$f$ is~\Define{$\diamond$-positive}
            if $f = g\after g$ for some~$\diamond$-self-adjoint~$g$.
            \index{*dia@$\diamond$, diamond!-positive}
    \end{enumerate}
For brevity, write $\Define{f^\BOX(s)} = f^\diamond(s^\perp)^\perp$
    and~$\Define{f_\BOX(s)} = f_\diamond(s^\perp)^\perp$
    \index{*par2@$(\ )_\BOX$, $(\ )^\BOX$}
\end{point}
\begin{point}{30}{Examples}%
The categories~$\op\vN$, $\op\CvN$, $\op\EJA$
        and $\SET$ are all~$\diamond$-effectuses.
\end{point}
\end{parsec}
\begin{parsec}{2070}%
\begin{point}{10}%
Let's investigate the basic properties of~$(\ )^\diamond$, $(\ )_\diamond$
    and $(\ )^\BOX$.
\end{point}
\begin{point}{20}[exc-diam-order-pres]{Exercise}%
Show that in a~$\diamond$-effectus
    both~$f^\diamond$ and~$f^\BOX$ are order preserving maps.
\end{point}
\begin{point}{30}[diamond-adjunction]{Proposition}%
For~$f\colon X \to Y$ in a~$\diamond$-effectus we have
\begin{equation}
    f^\diamond(s) \ \leq\  t^\perp
    \quad \iff
    \quad f_\diamond(t) \ \leq\  s^\perp \label{diamond-main-lemma}
\end{equation}
for all sharp~$s,t$.
In other words: $f_\diamond$ is the left order-adjoint of~$f^\BOX$.
\begin{point}{40}{Proof}%
To start, let's prove the order-adjunction reformulation
\begin{equation*}
    f_\diamond(s) \leq t
    \ \overset{\eqref{diamond-main-lemma}}{\iff} \ 
    f^\diamond(t^\perp) \equiv f^\BOX(t)^\perp \leq s^\perp
            \ \iff \
    s \leq f^\BOX(t).
\end{equation*}
To prove \eqref{diamond-main-lemma},
first assume~$f^\diamond(s) \leq t^\perp$.
Then~$s \after f \leq \ceil{s \after f} = f^\diamond(s) \leq t^\perp
= \IMperp \pi_t$, where the last equality is
due to \sref{img-of-compr}.
Thus~$s \after f \after \pi_t = 0$
    which is to say~$s \leq \IMperp f \after \pi_t$,
    so~$f_\diamond(t) = \IM f \after \pi_t \leq s^\perp$.

For the converse, assume
    $f_\diamond(t) \leq s^\perp$.
Then as before (but in the other direction)
    we find~$s \after f \after \pi_t = 0$
    and so~$s \after f \leq t^\perp$.
    Hence~$f^\diamond(s) =  \ceil{s \after f} \leq \lceil t^\perp\rceil
                = \floor{t}^\perp = t^\perp$, as desired. \qed
\end{point}
\end{point}
\begin{point}{50}[order-adj-basics]{Exercise}%
Use the fact that there is an
order adjunction between~$f_\diamond$ and $f^\BOX$
to show that in a~$\diamond$-effectus
\begin{multicols}{2}
\begin{enumerate}
    \item $f_\diamond$ is order preserving;
    \item $f_\diamond$ preserves suprema;
    \item $f^\BOX$ preserves infima;
    \item $f^\diamond$ preserves suprema;
    \item $f_\diamond \after f^\BOX \after f_\diamond = f_\diamond$ \emph{and}
    \item $f^\BOX \after f_\diamond \after f^\BOX = f^\BOX$.
\end{enumerate}
\end{multicols}
\end{point}
\spacingfix{}
\begin{point}{60}[diamond-functor]{Lemma}%
    In a~$\diamond$-effectus
        $(\ )^\diamond$,
        $(\ )^\BOX$ and
        $(\ )_\diamond$
        are functorial --- that is
\begin{multicols}{3}
\begin{enumerate}
\item
$(\id)^\diamond = \id$,
\item
$(f\after g)^\diamond
            =   g^\diamond \after f^\diamond$,
\item
$(\id)^\BOX = \id$,
\item
$(f\after g)^\BOX
            =   g^\BOX \after f^\BOX$,
\item
$(\id)_\diamond= \id$ and
\item
            $(f \after g)_\diamond = f_\diamond \after g_\diamond$.
\end{enumerate}
\end{multicols}
\spacingfix{}
\begin{point}{70}{Proof}%
We get~$(\id)^\diamond = \id$
directly from~\sref{img-of-compr}.
For 2 we only need a single line:
\begin{equation*}
(f\after g)^\diamond(s)
    \ =\  \ceil{s \after f \after g}
    \ \overset{\sref{ceiling-within-ceiling}}{=}\ 
    \ceil{\ceil{s \after f} \after g}
    \ =\  g^\diamond(f^\diamond(s)).
\end{equation*}
Note that we used that ceilings are sharp.
Point 3 and 4 follow easily from~1 and 2 respectively.
The identity~$(\id)_\diamond = \id$ is again~\sref{img-of-compr}.
We claim~$f_\diamond \after g_\diamond$
    is left order-adjoint to~$(f\after g)^\BOX$,
     indeed
\begin{equation*}
    f_\diamond (g_\diamond(s)) \leq t
        \ \iff\  g_\diamond(s) \leq f^\BOX (t)
        \ \iff\  s \leq g^\BOX (f^\BOX (t)) = (f \after g)^\BOX(t).
\end{equation*}
Thus by uniqueness of order adjoints, we find
$(f\after g)_\diamond = f_\diamond \after g_\diamond$. \qed
\end{point}
\end{point}
\begin{point}{71}[diamond-equiv-equiv]{Exercise}%
Derive from~\sref{diamond-adjunction}
    that~$f^\diamond = g^\diamond$
    if and only if~$f_\diamond = g_\diamond$.
\end{point}
\end{parsec}
\begin{parsec}{2080}%
\begin{point}{10}[image-sharp-is-order-sharp]{Lemma}%
In a $\diamond$-effectus,
sharp predicates are \Define{order sharp} ---
    \index{sharp!order-}
    that is:
    for any predicate~$p$
    and sharp predicate~$s$
    with~$p \leq s$ and~$p \leq s^\perp$,
    we must have~$p = 0$.
\begin{point}{20}{Proof}%
Note~$\ceil{p} \leq \ceil{s} = s$
    and~$\ceil{p} \leq \lceil s^\perp\rceil = s^\perp$.
So by~\sref{compr-is-full},
there is an~$h$ with~$\pi_{\ceil{p}} = \pi_s \after h$.
We compute
\begin{equation*}
    1 \after \pi_{\ceil{p}} \ =\  \ceil{p} \after \pi_{\ceil{p}}  \ = \
    \ceil{p} \after \pi_s \after h \ \leq \ 
        s^\perp \after \pi_s \after h \ = \ 0.
\end{equation*}
Thus~$\pi_{\ceil{p}} = 0$
and so~$p \leq \ceil{p} = \IM\pi_{\ceil{p}} = 0$, as desired.\qed
\end{point}
\end{point}
\begin{point}{30}[diamond-oml]{Proposition (Cho)}%
In a~$\diamond$-effectus,
the poset~$\SPred X$ of sharp predicates on any object~$X$,
is a sub-effect algebra of~$\Pred X$
and an orthomodular lattice.
\begin{point}{40}{Proof}%
Let~$C$ be a~$\diamond$-effectus with some object~$X$.
We will show~$\SPred X$ is a sub-effect algebra of~$\Pred X$,
    which is additionally an ortholattice.
    By \sref{orth-ea-is-orthomodular} this is sufficient to show
    $\SPred X$ is orthomodular.
\begin{point}{50}{Ortholattice}%
In \sref{lattice-compr}
    we already saw that sharp~$s,t$ have a sharp supremum
    $s\vee t = \IM [\pi_s,\pi_t]$ 
    in~$\Pred X$.
So~$s\vee t$ is also the supremum of~$s$ and~$t$ in~$\SPred X$.
As~$(\ )^\perp$ is an order anti-automorphism of both~$\Pred X$ and~$\SPred X$,
    we know~$(s^\perp \vee t^\perp)^\perp$
    is the infimum of~$s$ and~$t$ in~$\Pred X$ and~$\SPred X$.
As any sharp predicate~$s$ is order sharp by \sref{image-sharp-is-order-sharp},
    we find~$s \wedge s^\perp = 0$ (and consequently~$s^\perp \vee s = 1$).
    We have shown~$\SPred X$ is an ortholattice.
\end{point}
\begin{point}{60}{Sub-EA}%
Clearly~$0,1$ are sharp and~$s^\perp$ is sharp for sharp~$s$
        by definition of~$\diamond$-effectus.
To prove~$\SPred X$ is a sub-effect algebra of~$\Pred X$,
    it only remains to be shown~$s \ovee t$ is sharp
        for sharp and summable~$s,t$.
So, assume~$s,t$ are sharp and~$s \perp t$.
Note~$s \wedge t \leq s \wedge s^\perp =0$ as~$\SPred X$ is an ortholattice
    and so by \sref{ea-modularity-prop}
    we find~$s \ovee t = s \vee t$, which is indeed sharp. \qed
\end{point}
\end{point}
\begin{point}{70}{Corollary}%
In an $\diamond$-effectus~$C$
the assignment~$X\mapsto \SPred X$, ~$f \mapsto (f_\diamond,f^\BOX)$
    yields a functor from~$C$
    to~$\mathsf{OMLatGal}$,
    the category of orthomodular lattices
    with Galois connection between them,
    as defined in~\cite{jacobs2009orthomodular}.
\end{point}
\begin{point}{80}%
    There is a rather different
    formula for the infima of sharp predicates,
    which will be useful later on.
\end{point}
\end{point}
\begin{point}{90}[spred-infimum]{Lemma}%
In a~$\diamond$-effectus, we have
$s \wedge t = (\pi_s)_\diamond (\pi_s^\BOX (t))$
    for sharp predicates~$s,t$.
\begin{point}{100}{Proof}%
It is easy to see
$(\pi_s)_\diamond (\pi_s^\BOX (t))$ is a lower bound:
indeed
$(\pi_s)_\diamond (\pi_s^\BOX (t)) \leq t$
and~$(\pi_s)_\diamond (\pi_s^\BOX (t)) \leq (\pi_s)_\diamond(1)
    = \IM \pi_s = s$.
We have to show $(\pi_s)_\diamond (\pi_s^\BOX (t))$ is the greatest lower bound.
Let~$r$ be any sharp predicate with~$r \leq s$ and~$r \leq t$.
By~\sref{compr-is-full}
    we have~$\pi_r = \pi_s \after h$ for some~$h$.
Thus
\begin{equation*}
    (\pi_r)_\diamond
        \ = \  (\pi_s)_\diamond \after h_\diamond
        \ =\  (\pi_s)_\diamond \after \pi_s^\BOX  
            \after (\pi_s)_\diamond \after h_\diamond
        \ =\  (\pi_s)_\diamond \after \pi_s^\BOX \after (\pi_r)_\diamond.
\end{equation*}
Hence~$r = (\pi_r)_\diamond(1)  
=((\pi_s)_\diamond \after \pi_s^\BOX \after (\pi_r)_\diamond )(1)
=  (\pi_s)_\diamond ( \pi_s^\BOX (r))
\leq  (\pi_s)_\diamond ( \pi_s^\BOX (t))$. \qed
\end{point}
\begin{point}{110}{Remark}%
In \cite{effintro} there appears a similar result due to Jacobs,
    which is based on subtly different assumptions.
\end{point}
\end{point}
\begin{point}{120}[spred-sup]{Exercise}%
Show that in a~$\diamond$-effectus,
we have
        $(\xi^\BOX \after \xi_\diamond )(t) = s \vee t$
    for sharp~$s,t$ and  quotient~$\xi$ of~$s$.
    (Hint: mimic \sref{spred-infimum}.)
\end{point}
\end{parsec}

\begin{parsec}{2090}%
\begin{point}{10}%
We turn to~$\diamond$-adjointness.
\end{point}
\begin{point}{20}[exc-diamond-adj]{Exercise}%
Show the following basic properties of~$\diamond$-adjointness
\begin{enumerate}
    \item
$f^\diamond = g_\diamond$
    ($f$ is $\diamond$-adjoint to~$g$)
    if and only if~$f_\diamond = g^\diamond$.
    \item
If~$f$ and~$g$ are~$\diamond$-adjoint,
    then~$\IM f = \ceil{1 \after g}$.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{30}[diamond-squares]{Exercise}%
Show in order:
\begin{enumerate}
\item
If~$f$ is~$\diamond$-self-adjoint,
    then~$f \after f$ is~$\diamond$-self-adjoint.
\item
If~$f$ is~$\diamond$-positive,
    then~$f$ is~$\diamond$-self-adjoint.
\item
If~$f$ is~$\diamond$-positive and~$f\after f$ is pure,
    then~$f \after f$ is~$\diamond$-positive.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{40}[iso-diamond-adjoint]{Lemma}%
Let~$\alpha$ be an isomorphism in a~$\diamond$-effectus.
Then
\begin{enumerate}
\item
    $s\after\alpha$ is sharp for sharp predicates~$s$ \emph{and}
\item
    $\alpha^\diamond(s) = s \after \alpha$
    and~$\alpha_\diamond(s) = s\after \alpha^{-1}$
    (so~$\alpha$ and~$\alpha^{-1}$ are~$\diamond$-adjoint).
\end{enumerate}
\spacingfix{}
\begin{point}{50}{Proof}%
Let~$s$ be a sharp predicate. Then~$s = \IM \pi_s$.
Note~$\IM \alpha^{-1}\after \pi_s = s \after \alpha$
    --- indeed, $s \after \alpha \after \alpha^{-1} \after \pi_s=1$
    and when~$p \after \alpha^{-1} \after \pi_s=1$,
    we must have~$p \after \alpha^{-1} \geq s$,
    which gives~$p \geq s \after \alpha$ as desired.
    So~$s \after \alpha$ is indeed sharp.

So~$\alpha^\diamond(s) = \ceil{s \after \alpha} = s\after \alpha$
    and~$\alpha_\diamond(s) = \IM \alpha \after \pi_s = s \after \alpha^{-1}$
    as promised. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{2100}%
\begin{point}{10}[sharp-map]{Definition}%
A map~$f$ in a~$\diamond$-effectus is a~\Define{sharp map}
    \index{sharp!map}
    provided~$s \after f$ is sharp for all sharp predicates~$s$.
\end{point}
\begin{point}{20}[sharp-ceil]{Exercise}%
Show that the following are equivalent.
\begin{enumerate}
    \item $f$ is a sharp map.
    \item $\ceil{p \after f} = \ceil{p}\after f$
            for every predicate~$p$.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{30}[exa-sharp-vn]{Example}%
In~$\op{\vN}$ the sharp maps are exactly the~mni-maps
(i.e.~the normal $*$-homomorphisms).
See \sref{sharp-multiplicative}.
\end{point}
    
\end{parsec}

\section{$\&$-effectuses}
\begin{parsec}{2110}%
\begin{point}{10}%
In a~$\diamond$-effectus
    quotient and comprehension are not tied together by its axioms.
    With two additional axioms, we will see quotient and comprehension
    become tightly interwoven.
\end{point}
\begin{point}{20}{Definition}%
An~\Define{$\&$-effectus} (``andthen effectus'')
    \index{effectus!$\&$-}
is a $\diamond$-effectus
such that
\begin{enumerate}
\item
    for each object~$X$
    and each predicate~$p$ on~$X$,
        there is a unique $\diamond$-positive
        map $\Define{\asrt_p}\colon X \to X$
        \index{asrt@$\asrt_p$, assert}
        (``assert p'')
        with~$1 \after \asrt_p = p$ (see \sref{diamond-basics})
        \emph{and}
\item
    for every quotient~$\xi \colon Y \to Z$
    and comprehension~$\pi \colon X \to Y$
    the composite~$\xi \after \pi$ is pure.
\end{enumerate}
In an $\&$-effectus,
we define~$\Define{\andthen{p}{q}} \equiv q \after \asrt_p$,
    \index{$\&$, andthen}
    pronounced ``$p$ andthen~$q$''.
For brevity, we will write~$\Define{p^2} \equiv \andthen{p}{p}$.
\begin{point}{30}[asrt-remarks]{Remarks}%
The $\asrt_p$ maps are named after the \texttt{assert} statement
    found in many programming languages.
The \texttt{assert} statement checks whether
    the provided Boolean expression (i.e.~predicate)
    is true (at the time of execution) --- and if it is, it will continue the program
    without further action; if it isn't, it will halt execution
    immediately.
Our~$\asrt_p$ maps can be thought of in the same way.
Alternatively, $\asrt_p$ can be viewed as a filter
    that blocks states for which~$p^\perp$ holds.
With this intuition,
    the predicate~$\andthen{p}{q}$
    corresponds to whether~$p$ and~$q$ are true,
    by first checking~$p$ and then checking~$q$.

The~$\asrt_p$ maps can be used to construct more complicated measurements.
For instance, let~$p, q, r$ be three predicates (measurement outcomes)
    on an object~$X$
    with~$p \ovee q \ovee r = 1$.
Then~$\left<\asrt_p,\asrt_q,\asrt_r\right>\colon X \to X + X + X $
    models measuring whether~$p,q,r$ hold
    without discarding the state of the (possibly affected) system
    after measurement
    (in contrast to~$\left<p,q,r\right>\colon X \to 1+1+1$).
If we discard the measurement outcome,
    we find the map~$\asrt_p \ovee \asrt_q \ovee \asrt_r \colon X \to X$,
    which is the side-effect of measuring $p,q,r$.
\begin{point}{31}
The second axiom is closely related to polar decomposition:
    in the case of~$\op\vN$ (flipping direction of arrows now),
    the unique isomorphism~$\varphi$
    such that~$h \after c = c' \after \varphi \after h'$
    for the suitable standard filter~$c'$ and corner~$h'$
    is given by~$\ad_u$
    where~$u$ is the isomtry from the
    polar decomposition~$u \sqrt{\ceil{h}c(1)\ceil{h}}
        \equiv \sqrt{c(1)} \ceil{h}$
    restricted to a unitary.
\end{point}
\end{point}
\end{point}
\begin{point}{40}[vn-is-andthen-eff]{Examples}%
The category~$\op{\vN}$ is an~$\&$-effectuses
    with~$\asrt_a\colon b \mapsto \sqrt{a}b\sqrt{a}$.
The first axiom is proven in \sref{positive-map-uniqueness}
    and the second in \sref{pure-fundamental}.
The full subcategory~$\op\CvN$ of commutative von Neumann algebras
    is a~$\&$-effectus as well.

The only other known example of an~$\&$-effectus
    is the category~$\op\EJA$ of Euclidean Jordan algebras
    with positive unital maps in the opposite direction,
    see~\cite{eja}.
\end{point}
\begin{point}{50}[sharp-prop]{Proposition}%
For a predicate~$p$ in an $\&$-effectus the following are equivalent.
\begin{enumerate}
\item $p$ is sharp,
\item $\andthen{p}{p}=p$ and
\item $\asrt_p \after \asrt_p = \asrt_p$.
\end{enumerate}
\spacingfix{}
\begin{point}{60}{Proof}%
First we prove that~$p$ is sharp if and only if~$\andthen{p}{p}=p.$
So, assume~$p$ is sharp.
As $\diamond$-positive maps are~$\diamond$-self-adjoint
    we have~$\IM \asrt_p = \ceil{1 \after \asrt_p} = \ceil{p} = p$.
Thus~$\andthen{p}{p} = p \after \asrt_p = 1 \after \asrt_p = p$.
For the converse, assume~$\andthen{p}{p}=p$.
From~$\IM \asrt_p = \ceil{1 \after \asrt_p} = \ceil{p}$,
we get~$\ceil{p} \after \asrt_p = \andthen{p}{\ceil{p}} = 1 \after \asrt_p = p$.
By assumption~$\andthen{p}{p}=p$.
So~$\andthen{p}{(\ceil{p} \ominus p)} = 0$.
Hence~$\ceil{p}\ominus p \leq \IMperp \asrt_p = \ceil{p}^\perp$.
However $\ceil{p}\ominus p \leq \ceil{p}$.
Thus by~\sref{image-sharp-is-order-sharp}
    get~$\ceil{p} \ominus p = 0$. So~$p$ is indeed sharp.

Clearly, if~$\asrt_p \after \asrt_p = \asrt_p$,
then~$p = 1 \after \asrt_p = 1\after\asrt_p\after\asrt_p = \andthen{p}{p}$.
It only remains to be shown~$\asrt_p \after \asrt_p = \asrt_p$
    whenever~$p$ is sharp.
So assume~$p$ is sharp.
By definition~$\asrt_p$ is pure: $\asrt_p = \pi \after \xi$
    for some quotient~$\xi$ and comprehension~$\pi$.
By assumption~$\xi \after \pi$ is pure as well,
    so there is a quotient~$\xi'$ and comprehension~$\pi'$
    with~$\xi \after \pi = \pi' \after \xi'$.
Note~$1 \after \xi = 1 \after \asrt_p = p$
and~$1 \after \asrt_p \after \asrt_p = \andthen{p}{p} = p = 1 \after \xi$,
hence
\begin{equation*}
 1\after \xi  
    \ =\  1 \after \asrt_p \after \asrt_p 
    \ =\  1 \after \pi \after \xi \after \pi \after \xi 
    \ =\  1 \after \pi \after \pi' \after \xi' \after \xi 
    \ =\  1 \after \xi' \after \xi,
\end{equation*}
so~$1 \after \xi' = 1$. Thus~$\xi'$ is an iso.
Also~$
    (\IM \pi') \after \xi \after \pi
    = (\IM \pi') \after \pi' \after \xi'
    = 1 \after \xi' = 1 $
    from which it follows~$p = \IM \pi \leq  (\IM \pi') \after \xi 
            \leq 1 \after \xi = p$.
Thus~$(\IM \pi') \after \xi = p = 1\after \xi$.
Hence~$\IM \pi' = 1$ and so~$\pi'$ is an isomorphism.
Now we know~$\pi \after \pi'$
    is a comprehension and~$\xi' \after \xi$ is a quotient,
    we see~$\asrt_p\after\asrt_p$ is pure.
As~$\asrt_p$ is $\diamond$-self-adjoint,
    we see~$\asrt_p\after\asrt_p$ is $\diamond$-positive.
By uniqueness of positive maps~$\asrt_p \after \asrt_p = \asrt_p$,
    as desired. \qed
\end{point}    
\end{point}
\begin{point}{70}[prop-corr-zeta-pi]{Proposition}%
Let~$C$ be an~$\&$-effectus and~$s$
     be any sharp predicate.
There exist comprehension~$\pi_s$ of~$s$
        and quotient~$\zeta_s$ of~$s^\perp$ such that
\begin{equation*}
    \zeta_s \after \pi_s \ = \ \id \quad \text{and} \quad
        \pi_s \after \zeta_s \ = \ \asrt_s.
\end{equation*}
In fact, for every comprehension~$\pi$ of~$s$,
    there is a quotient~$\xi$ of~$s^\perp$
    with~$\xi \after \pi = \id$ and~$\pi \after \xi = \asrt_s$
    \emph{and} conversely for every quotient~$\xi$ of~$s^\perp$
    there exists a comprehension~$\pi$ of~$s$
    with~$\xi \after \pi = \id$ and~$\pi \after \xi = \asrt_s$.
\begin{point}{80}{Proof}%
Let~$s$ be any sharp predicate.
By definition~$\diamond$-positive maps are pure and so
    there is a quotient~$\xi$ and comprehension~$\pi$
    with~$\pi \after \xi = \asrt_s$.
    So
\begin{equation*}
   \pi \after \xi \ =\  \asrt_s 
    \ \stackrel{\mathclap{\sref{sharp-prop}}}{=}\  \asrt_s\after\asrt_s \ =\  \pi \after \xi \after \pi \after \xi.
\end{equation*}
Thus~$\xi \after \pi = \id$.
We compute~$s = 1 \after \asrt_s = 1 \after \xi$
and so
\begin{alignat*}{2}
    \IM \pi &\ = \ 
    \IM \pi \after \xi \after \pi &\qquad& \text{as $\xi \after \pi=\id$}\\
                  &\ = \ \IM \asrt_s \after \pi &&\text{by dfn.~$\xi$ and~$\pi$}\\
                  &\ = \ (\asrt_s)_{\diamond}(\IM \pi)&& \text{by dfn.~$(\ )_\diamond$} \\
                  & \ = \ (\asrt_s)^{\diamond}(\IM \pi)&&
        \text{by $\diamond$-s.a.~$\asrt_s$}\\
        &\ = \ \ceil{(\IM \pi) \after \pi \after \xi} && \text{by dfn.~$(\ )^\diamond$} \\
&\ = \ \ceil{1 \after \xi} \\
    & \ = \ s.
\end{alignat*}
Thus~$\pi$ is a comprehension of~$s$
and~$\xi$ is a quotient of~$s^\perp$.
We have proven the first part.

For the second part,
let~$\pi'$ be any comprehension of~$s$.
Then~$\pi' = \pi \after \alpha$ for some iso~$\alpha$.
Define~$\xi' = \alpha^{-1} \after \xi$.
It is easy to see~$\pi' \after \xi' = \asrt_s$
and~$\xi' \after \pi' = \id$.
The other statement is proven in a similar way. \qed
\end{point}
\begin{point}{90}[zeta-s-convention]{Notation}%
In an~$\&$-effectus
    together with chosen comprehension~$\pi_s$ for~$s$,
    we will write~$\zeta_s$
    for the unique quotient for~$s^\perp$
    satisfying~$\zeta_s \after \pi_s = \id$
    and~$\pi_s \after \zeta_s = \asrt_s$.
We call this~$\zeta_s$
    \index{quotient!corresponding}
    \index{comprehension!corresponding}
    the \Define{corresponding quotient} of~$\pi_s$
    and vice versa~$\pi_s$ the \Define{corresponding comprehension}
    of~$\zeta_s$. \index{*zeta@$\zeta_s$}\index{*pi@$\pi_p$}
\end{point}
\begin{point}{100}{Warning}%
    $\xi_{s^\perp} = \zeta_s$!
\end{point}
\end{point}
\begin{point}{110}[upm-closed]{Proposition}%
In an $\&$-effectus
    both comprehensions and pure maps are closed under composition.
\begin{point}{120}{Proof}%
We will first prove that comprehensions are closed under composition.
Assume~$\pi_1 \colon X \to Y$
    and~$\pi_2 \colon Y \to Z$
    are comprehensions with~$s = \IM \pi_1$
    and~$t = \IM \pi_2$.
We will show~$\pi_2 \after \pi_1$
    is a comprehension for~$\IM \pi_2 \after \pi_1$.
To this end, let~$f\colon V\to Z$ be any map
with~$(\IM \pi_2 \after \pi_1)^\perp \after f = 0$.
As~$\IM \pi_2 \after \pi_1 \leq \IM \pi_2 = t$
    we get~$t^\perp \after f = 0$,
    so~$f = \pi_2 \after g_2$ for a unique~$g_2\colon V \to Y$.
Let~$\zeta_2$ be a quotient for~$t^\perp$
such that~$\zeta_2 \after \pi_2 = \id$,
which exists by \sref{prop-corr-zeta-pi}.
Then~$s \after \zeta_2 \after \pi_2 \after \pi_1
            = s \after \pi_1 = 1$
            so~$s \after \zeta_2 \geq \IM \pi_2 \after \pi_1$.
Consequently
\begin{equation*}
    s \after g_2 \ =\  s \after \zeta_2 \after \pi_2 \after g_2
        \ =\  s \after \zeta_2 \after f
        \ \geq\   (\IM \pi_2 \after \pi_1) \after f \ =\  1 \after f
                \ =\  1 \after g_2.
\end{equation*}
Hence there exists a unique~$g_1\colon V \to X$
    with~$\pi_1 \after g_1 = g_2$
    and so~$\pi_2 \after \pi_1 \after g_1 = f$.
By monicity of~$\pi_2 \after \pi_1$,
    this~$g_1$ is unique and so~$\pi_2 \after \pi_1$
    is indeed a comprehension.
\begin{point}{130}%
Now we will prove that pure maps are closed under composition.
Assume~$g\colon X \to Y$ and~$f\colon Y \to Z$ are pure maps.
Say~$f = \pi_1 \after \xi_1$
    and~$g = \pi_2 \after \xi_2$
    for some comprehensions~$\pi_1$, $\pi_2$
        and quotients~$\xi_1$, $\xi_2$.
By definition of $\&$-effectus
    there is a comprehension~$\pi'$ and quotient~$\xi'$
    such that~$\xi_1 \after \pi_2 = \pi' \after \xi'$.
By the previous point~$\pi_1 \after \pi'$
    is a comprehension
    and~$\xi' \after \xi_2$ is a quotient by \sref{quotients-composition}.
Thus
$f \after g 
=\pi_1 \after \pi' \after \xi' \after \xi_2$
is pure. \qed
\end{point}
\end{point}
\end{point}
\begin{point}{140}[andthen-square-rule]{Exercise}%
Show that in an~$\&$-effectus,
    we have~$\asrt_p \after \asrt_p = \asrt_{\andthen{p}{p}}$.
\end{point}
\begin{point}{150}[asrt-absorp-rule]{Exercise}%
    Show that in an~$\&$-effectus,
    we have
    \begin{align*}
        \IM f \leq s \quad&\iff\quad  \asrt_s \after f = f \\
        1 \after f \leq t \quad&\iff\quad  f \after \asrt_t = f
    \end{align*}
for any sharp predicates~$s$ and~$t$.
\end{point}
\begin{point}{160}{Definition}%
Let~$C$ be an~$\&$-effectus.
In \sref{upm-closed} we saw pure maps are closed under composition.
Write~$\Define{\Pure C}$ for the subcategory
    \index{PureC@$\Pure C$} of pure maps.
\end{point}
\end{parsec}

\begin{parsec}{2120}%
\begin{point}{10}[zeta-asrt-quot]{Lemma}%
    In an~$\&$-effectus,
    $\zeta_{\ceil{p}} \after \asrt_p$
    is a quotient for~$p^\perp$.
\begin{point}{20}{Proof}%
Recall~$\IM \asrt_p = \ceil{1 \after \asrt_p} = \ceil{p}$ and so
\begin{equation*}
\IM \zeta_{\ceil{p}} \after \asrt_p
\ =\  (\zeta_{\ceil{p}})_\diamond( \ceil{p})
\ =\  \IM \zeta_{\ceil{p}} \after \pi_{\ceil{p}}
\ =\  \IM \id \ =\  1,
\end{equation*}
where~$\pi_{\ceil{p}}$ is the comprehension corresponding to~$\zeta_{\ceil{p}}$.
By~\sref{upm-closed}~$\zeta_{\ceil{p}} \after \asrt_p = \pi \after \xi$
    for some comprehension~$\pi$ and quotient~$\xi$.
Putting it together:
$1 = \IM \zeta_{\ceil{p}} \after \asrt_p = \IM \pi \after \xi \leq \IM \pi$,
so~$\IM \pi = 1$ and thus~$\pi$ is an isomorphism,
hence~$\zeta_{\ceil{p}}\after \asrt_p$
is a quotient for the orthocomplement of~$\ceil{p} \after \asrt_p = p$. \qed
\end{point}
\end{point}
\begin{point}{30}[standard-form-map]{Proposition}%
Every map~$f$
in an~$\&$-effectus
factors as
\begin{equation}\label{eq-standard-form-map}
        f \ =\ \pi_{\IM f} \after g \after \zeta_{\ceil{1 \after f}} \after \asrt_{1 \after f} 
    \end{equation}
    for a unique total and faithful map~$g$.
Furthermore the following holds.
\begin{enumerate}
\item
If~$f$ is pure, then~$g$ is an isomorphism.
\item
If~$f$ is pure and~$\IM f = 1$, then~$f$ is a quotient.
\item
If~$f$ is pure and~$1 \after f = 1$, then~$f$ is a comprehension.
\end{enumerate}
\spacingfix{}
\begin{point}{40}{Proof}%
By the universal property of~$\pi_{\IM f}$,
    there is a unique~$g'$ with~$f = \pi_{\IM f} \after g'$.
To show~$g'$ is faithful, assume~$p\after g' = 0$
    for some predicate~$p$.
Then~$0 = p \after g' = p \after \zeta_{\IM f} \after \pi_{\IM f} \after g'
                = p \after \zeta_{\IM f} \after f$
    and so~$p \after \zeta_{\IM f} \leq \IMperp f$,
    hence~$p = p \after \zeta_{\IM f} \after \pi_{\IM f}
                \leq (\IMperp f )\after \pi_{\IM f} = 0$, which
                shows~$g'$ is indeed faithful.

Note~$1 \after g' = 1 \after \pi_{\IM f} \after g' = 1 \after f$.
By~\sref{quotient-total} and~\sref{zeta-asrt-quot}
    there is a unique total~$g$ with~$g' = g \after \zeta_{\ceil{1 \after f}} \after \asrt_{1 \after f}$.
Clearly~\eqref{eq-standard-form-map} holds
and~$g$ is the unique map
    for which \eqref{eq-standard-form-map} holds
    as  comprehensions are mono and quotients are epi.
    As~$1 = \IM g' = \IM g \after \zeta_{\ceil{1 \after f}}
            \after \asrt_{1 \after f} \leq \IM g$,
            we see~$\IM g = 1$ and so~$g$ is faithful.

To prove point 1, assume~$f$ is pure.
That is: $f = \pi \after \xi$ for some comprehension~$\pi$
        and quotient~$\xi$.
As~$1 \after \pi=1$ and~$\IM \xi = 1$,
    we see~$\IM \pi = \IM f$ and~$1 \after \xi = 1\after f$.
Thus~$\pi = \pi_{\IM f} \after \alpha$
    and~$\xi = \beta \after \zeta_{\ceil{1 \after f}}
                \after \asrt_{1 \after f}$
        for some isomorphisms~$\alpha$ and~$\beta$.
Thus~$f = \pi_{\IM f} \after \alpha \after \beta
                \after \zeta_{\ceil{1 \after f}}
                \after \asrt_{1 \after f}$
        and so by uniqueness of~$g$,
        we see~$g = \alpha \after \beta$ is an isomorphism.

To prove point 2, additionally assume~$\IM f= 1$.
Then~$\pi_{\IM f}$ is an iso and so
using the previous, we see~$f$ is indeed a quotient.
Point 3 is just as easy. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{2130}%
\begin{point}{10}[andthen-effect-divisoid]{Proposition}%
If~$C$ is an~$\&$-effectus,
    then~$(\Scal C)^{\mathsf{op}}$ is an effect divisoid,
    see~\sref{dfn-effect-divisoid}.
\begin{point}{20}{Proof}%
Let~$\lambda,\mu$ be scalars with~$\lambda \leq \mu$.
Recall that the scalar~$1=\id$
    and so~$\mu = 1 \after \asrt_\mu = \asrt_\mu$.
By~\sref{zeta-asrt-quot},
    there is a unique~$\lambda'$
    with~$\lambda' \after \zeta_{\ceil{\mu}} \after \mu = \lambda$.
Define~$\rfrac{\lambda}{\mu} = \lambda'  \after \zeta_{\ceil{\mu}}$.

For the moment, assume~$\lambda = \mu$.
Then~$\lambda' \after \zeta_{\ceil{\mu}} \after \mu
            = \mu = 1 \after \zeta_{\ceil{\mu}} \after \mu$
            as~$\IM \mu = \IM \asrt_{\mu} = \ceil{\mu}$.
        By epicity of~$\zeta_{\ceil{\mu}} \after \mu$,
            we see~$\lambda' = 1$, hence~$\rfrac{\mu}{\mu}=\ceil{\mu}$.
As we have~$\mu \leq \ceil{\mu}$ and~$\ceil{\ceil{\mu}} = \ceil{\mu}$,
    we see axioms 2 and 3 hold.

We return to the general case to prove axiom 1.
Clearly~$\rfrac{\lambda}{\mu} = \lambda' \after \zeta_{\ceil{\mu}}
            \leq 1 \after \zeta_{\ceil{\mu}} = \ceil{\mu} 
            = \rfrac{\mu}{\mu}$
    and~$\mu \odot_{\mathsf{op}} \rfrac{\lambda}{\mu}
= \lambda'  \after \zeta_{\ceil{\mu}} \after \mu = \lambda$
as required.
Assume~$\sigma$ is an arbitrary
    scalar with~$\mu \odot_{\mathsf{op}} \sigma = \lambda$
    and~$\sigma \leq \rfrac{\mu}{\mu} \equiv \ceil{\mu}$.
Then~$\sigma = \sigma' \after \zeta_{\ceil{\mu}}$
    for a unique~$\sigma'$.
As~$
\lambda'  \after \zeta_{\ceil{\mu}} \after \mu = \lambda
= \sigma' \after \zeta_{\ceil{\mu}} \after \mu$
we must have~$\lambda' = \sigma'$, whence~$\rfrac{\lambda}{\mu}=\sigma$. \qed
\end{point}
\end{point}
\begin{point}{30}[perp-sharp-is-orth]{Lemma}%
In an~$\&$-effectus, if~$s \perp t$
    for sharp~$s,t$, then~$\andthen{s}{t} = 0 = \andthen{t}{s}$.
\begin{point}{40}{Proof}%
Write~$r \equiv (s \ovee t)^\perp$.
    As~$1 = s \ovee t \ovee r$ and~$\andthen{s}{s}=s$, we have
\begin{equation*}
    s \ = \ 
    \andthen{s}{1} \ = \ 
    \andthen{s}{s} \ovee \andthen{s}{t} \ovee \andthen{s}{r} \ = \ 
    s \ovee \andthen{s}{t} \ovee \andthen{s}{r}
\end{equation*}
and so~$\andthen{s}{t} \leq \andthen{s}{t} \ovee \andthen{s}{r} = 0$. \qed
\end{point}
\end{point}
\begin{point}{50}[simple-andthen-absorption]{Exercise}%
Show that in an~$\&$-effectus, we have
\begin{equation*}
p \ \leq\  s \quad \iff \quad \andthen{s}{p} \ =\  p
\end{equation*}
for sharp~$s$ and any predicate~$p$.
\end{point}
\begin{point}{60}[exc-prod-sharp-maps]{Exercise}%
Show that in a~$\&$-effectus,
    a map~$\left<f,g\right>$
    is sharp if and only if both~$f$ and~$g$ are sharp.
    (Hint: use \sref{diamond-oml} and \sref{img-tupling}.)
\end{point}
\end{parsec}

\section{\texorpdfstring{$\dagger$-effectuses}{%
                    dagger-effectuses}}
\begin{parsec}{2140}%
\begin{point}{10}[dagger-effectus]{Definition}%
A \Define{$\dagger$-category} (``dagger category'')
    \index{*dagg@$\dagger$, dagger!-category}
is a category~$C$ together with an involutive identity-on-objects
    functor~$(\ )^\dagger \colon C \to \op{C}$
    ---
    that is, for all objects~$X$ and maps~$f,g$ in~$C$, we have
\begin{multicols}{2}
\begin{enumerate}
    \item $(f \after g)^\dagger = g^\dagger \after f^\dagger$
    \item $\id^\dagger = \id$
    \item $f^{\dagger\dagger} = f$ \emph{and}
    \item $X^\dagger = X$.
\end{enumerate}
\end{multicols}
\noindent
Cf.~\cite{burgin1970categories,selinger,heunenphd,karvonen}.
In any~$\dagger$-category we may define the following.
\begin{enumerate}
\item
    An endomap~$f$ is called \Define{$\dagger$-self-adjoint}
    \index{*dagg@$\dagger$, dagger!-self-adjoint}
    if~$f^\dagger = f$.
\item
    An endomap~$f$ is \Define{$\dagger$-positive}
    \index{*dagg@$\dagger$, dagger!-positive}
    if~$f = g^\dagger \after g$ for some other map~$g$.
\item
    An isomorphism~$\alpha$ is called~\Define{$\dagger$-unitary}
        \index{*dagg@$\dagger$, dagger!-unitary}
        whenever~$\alpha^{-1} = \alpha^\dagger$.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{20}{Example}%
The category~$\mathsf{Hilb}$
    of Hilbert spaces with bounded linear maps
    is a~$\dagger$-category
    with the familiar adjoint as~$\dagger$.
\end{point}
\end{parsec}
\begin{parsec}{2150}%
\begin{point}{10}{Definition}%
We call an~$\&$-effectus~$C$
    a~\Define{$\dagger$-effectus} (``dagger effectus'') provided
    \index{effectus!$\dagger$-}
    \index{*dagg@$\dagger$, dagger!-effectus}
\begin{enumerate}
\item
    $\Pure C$ is a  $\dagger$-category
     satisfying~$\asrt_p^\dagger = \asrt_p$
        and~$f$ is $\diamond$-adjoint to~$f^\dagger$;
\item
    for every~$\dagger$-positive~$f$,
        there is a unique~$\dagger$-positive~$g$
        with~$g \after g = f$ \emph{and}
\item
    $\diamond$-positive maps are $\dagger$-positive.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{20}{Examples}%
In \sref{vn-is-dagger-category}
we will see that the category~$\op\vN$ is a~$\dagger$-effectus.
Recently we have shown with van de Wetering
    that the category~$\op\EJA$
    of Euclidean Jordan algebras
    with positive unital maps in the opposite direction,
    is a~$\dagger$-effectus as well. \cite{eja}
\end{point}
\begin{point}{30}[dagger-theorem]{Theorem}%
    An $\&$-effectus
        is a~$\dagger$-effectus if and only if
\begin{enumerate}
\item
for every predicate~$p$, there is a unique predicate~$q$
    with~$\andthen{q}{q} = p$;
\item
    $\asrt^2_{\andthen{p}{q}}
        = \asrt_p \after \asrt^2_q \after \asrt_p$
     for all predicates~$p,q$ \emph{and}
\item
    a quotient for a sharp predicate (e.g.~$\zeta_s$)
    is a sharp map, see \sref{sharp-map}.
\end{enumerate}
\spacingfix{}
\begin{point}{40}{Proof}%
Necessity will be proven in
    \sref{dagger-thm-necessity}
        and sufficiency in \sref{dagger-thm-sufficiency}. \qed
\end{point}
\begin{point}{50}%
Especially the sufficiency requires quite some preparation.
For convenience, call~$C$ a \Define{$\dagger'$-effectus}
    \index{effectus!$\dagger'$-}
    if~$C$ is an~$\&$-effectus
    satisfying axioms 1, 2 and 3 from the Theorem above.
\end{point}
\begin{point}{60}[vn-is-dagger-category]{Corollary}%
The category~$\op\vN$ of von Neumann algebras with
    ncpu-maps in the opposite direction,
    which is an~$\&$-effectus by~\sref{vn-is-andthen-eff},
    is also a~$\dagger$-effectus.
\end{point}
\begin{point}{61}{Remarks}%
    The dagger on the pure maps of~$\vN$ (that exists by the previous
    corollary) is fixed by the following two rules.
\begin{enumerate}
\item
    For any (nmiu-)isomorphism~$\vartheta$
        we have~$\vartheta^\dagger = \vartheta^{-1}$
        as~$\vartheta$ is~$\diamond$-adjoint to~$\vartheta^{-1}$
         and pure maps are rigid, see~\sref{pure-is-rigid}.
\item
    The standard filter~$c\colon \scrA \to \ceil{b} \scrA \ceil{b}$
        for~$b \in \scrA$
        (ie.~$c(a) = \sqrt{b}a\sqrt{b}$, see~\sref{dils-def-filter})
        has as dagger~$c^\dagger\colon \ceil{b} \scrA  \ceil{b} \to \scrA$
        given by~$c^\dagger(a) = \sqrt{b} a \sqrt{b}$.
        (This follows from~$\asrt_p^\dagger = \asrt_p$
            and~\sref{dagger-of-zeta}.)
\end{enumerate}
More concretely,
    for any pure ncp-map~$\varphi\colon \scrA \to \scrB$
    we can find
    a unique isomorphism~$\vartheta \colon \ceil{\varphi} \scrA \ceil{\varphi}
    \to \ceil{\varphi(1)} \scrB \ceil{\varphi(1)}$
    such that
\begin{equation*}
    \varphi(a) \ =\  \sqrt{\varphi(1)} \,\vartheta
    \bigl(\ceil{\varphi} a \ceil{\varphi}\bigr) \,\sqrt{\varphi(1)} \qquad \text{(for all $a\in \scrA$)}
\end{equation*}
    (this follows from~\sref{pure-fundamental} and~\sref{square-f})
    and so by the previous two rules we get
\begin{equation*}
    \varphi^\dagger(b) \ = \  \ceil{\varphi} \,\vartheta^{-1} 
    \Bigl( \sqrt{\varphi(1)} \, b \, \sqrt{\varphi(1)} \Bigr) \, \ceil{\varphi}
        \qquad \text{(for all $b \in \scrB$)}.
\end{equation*}
\spacingfix{}
\begin{point}{72}%
In special cases, we can give a simpler definition of the dagger.
For instance, if the
    pure map is of the form~$\varphi\colon \scrB(\scrH) \to \scrB(\scrK)$,
    then~$\varphi = \ad_T$ for some operator~$T \colon \scrK \to \scrH$
    and in that case~$\varphi^\dagger = \ad_{T^*}$.

Another example is a pure map~$\varphi\colon \scrA \to \scrB$
    between finite-dimensional von Neumann algebras.
The Hilbert--Schmidt inner product~$[a, b] \equiv \TR a^*b$
    turns a finite-dimensional von Neumann algebra into a Hilbert space.
The adjoint of~$\varphi$ with respect to this inner product
    equals~$\varphi^\dagger$.
This can be seen by considering the special cases
    of nmiu-isomorphisms and standard filters
    (noting nmiu-isomorphisms are trace-preserving).
\end{point}
\end{point}
\begin{point}{70}{Remarks}%
    In an~$\&$-effectus
    with separating predicates
    (see \sref{dfn-mandso}),
    the second axiom of a~$\dagger'$-effectus is equivalent
    to
\begin{equation*}
    \andthen{(\andthen{p}{q})^2}{r}
    \ =\  \andthen{p}{(\andthen{q^2}{(\andthen{p}{r})})}
\end{equation*}
    for all predicates~$p,q,r$.
This is essentially the \emph{fundamental formula
    of quadratic Jordan algebras} \cite[\S4.2]{mccrimmon2006taste}
    (with~$U_x y \equiv \andthen{x^2}{y}$).

The second axiom of a~$\dagger$-effectus
    has been considered before in~$\dagger$-categories
    by Selinger \cite{selinger2008idempotents}
    who calls it the \emph{unique square root axiom}.
\end{point}
\end{point}
\end{parsec}


\begin{parsec}{2160}%
\begin{point}{10}[diamond-is-dagger-positive]{Lemma}%
In a~$\dagger$-effectus,
    a map is~$\dagger$-positive if and only if it is~$\diamond$-positive.
\begin{point}{20}{Proof}%
Assume~$f$ is~$\dagger$-positive.
By assumption 2, there is a (unique) $\dagger$-positive
    $g$ with~$f = g \after g$.
By~$\dagger$-positivity of~$g$,
    there is an~$h$ with~$g = h^\dagger \after h$.
Using the fact~$h$ is~$\diamond$-adjoint
    to~$h^\dagger$, we see~$g$ is~$\diamond$-self-adjoint:
\begin{equation*}
    g^\diamond
    \ =\  (h^\dagger \after h)^\diamond
    \ =\  h^\diamond \after (h^\dagger)^\diamond 
    \ =\  (h^\dagger)_\diamond \after h_\diamond 
    \ =\  (h^\dagger\after h)_\diamond
    \ =\  g_\diamond.
\end{equation*}
Thus~$f$ is the square of the~$\diamond$-self-adjoint map $g$,
    hence~$f$ is~$\diamond$-positive. \qed
\end{point}
\end{point}

\begin{point}{30}[dagger-eff-square-root]{Lemma}%
Predicates in a~$\dagger$-effectus have a unique square root:
    for every predicate~$p$,
    there is a unique predicate~$q$
    with~$\andthen{q}{q}=p$.
\begin{point}{40}{Proof}%
Let~$p\colon X \to 1$ be any predicate.
By assumption 3,
    the~$\diamond$-positive map~$\asrt_p$
        is also~$\dagger$-positive.
So by assumption 2,
    there is (a unique)~$\dagger$-positive map~$f$
    with~$f \after f = \asrt_p$.
Define~$q = 1 \after f$.
By \sref{diamond-is-dagger-positive}
    $f$ is~$\diamond$-positive
    and so by uniqueness of~$\diamond$-positive maps,
    we get~$f = \asrt_{1\after f} \equiv \asrt_q$.
We compute
\begin{equation*}
    \andthen{q}{q}
        \ =\    
        q \after \asrt_q \ \equiv \ 
        1 \after f \after \asrt_{1 \after f} \ = \ 
        1 \after f \after f \ = \ 1 \after \asrt_p \ = \ p,
\end{equation*}
which shows~$p$ has as square root~$q$.

To show uniqueness, assume~$p = \andthen{r}{r}$ for some
    predicate~$r$.
Note
\begin{equation*}
    \asrt_p
        \ = \ \asrt_{\andthen{r}{r}}
        \ \overset{\smash{\sref{andthen-square-rule}}}{=} \ \asrt_r \after \asrt_r.
\end{equation*}
As~$\asrt_r$ is~$\diamond$-positive,
    it is also~$\dagger$-positive by the third axiom.
    So by the second axiom~$\asrt_r = \asrt_q$.
Thus~$r = q$, which shows uniqueness of the square root.
\qed
\end{point}
\end{point}
\begin{point}{50}[asrt-iso]{Proposition}%
In an~$\&$-effectus with square roots
    (e.g.~$\dagger$- or~$\dagger'$-effectus) we have
\begin{equation*}
    \asrt_p \after \alpha
        \ =\  \alpha \after \asrt_{p\after \alpha}
\end{equation*}
for every isomorphism~$\alpha$ and predicate~$p$.
\begin{point}{60}{Proof}%
There is some~$q$ with~$\andthen{q}{q}=p$.
The map~$\alpha^{-1} \after \asrt_q \after \alpha$
    is~$\diamond$-self-adjoint:
\begin{alignat*}{2}
    (\alpha^{-1} \after \asrt_q \after \alpha)_\diamond
    &\ = \ \alpha^{-1}_\diamond \after (\asrt_q)_\diamond \after \alpha_\diamond \\
    &\ \overset{\mathclap{\sref{iso-diamond-adjoint}}}{=} \ \alpha^\diamond \after (\asrt_q)^\diamond \after (\alpha^{-1})^\diamond\\
    &\ = \ (\alpha^{-1} \after \asrt_q \after \alpha)^\diamond.
\end{alignat*}
Thus~$
\alpha^{-1} \after \asrt_q \after \alpha \after
\alpha^{-1} \after \asrt_q \after \alpha
= \alpha^{-1} \after \asrt_p \after \alpha
$ is~$\diamond$-positive.  By uniqueness of~$\diamond$-positive maps,
we get~$\alpha^{-1} \after \asrt_p \after \alpha
    = \asrt_{1 \after \alpha^{-1}\after\asrt_p \after \alpha}
    = \asrt_{p \after \alpha} $.
Postcomposing~$\alpha$, we find~$\asrt_p\after\alpha = 
        \alpha \after \asrt_{p \after \alpha}$, as desired. \qed
\end{point}
\end{point}
\begin{point}{70}[dagger-of-zeta]{Proposition}%
In a $\dagger$-effectus:~$\zeta_s^\dagger = \pi_s$
(recall convention \sref{zeta-s-convention} for~$\pi_s$ and~$\zeta_s$).
\begin{point}{80}{Proof}%
As~$\pi_s$ is~$\diamond$-adjoint to~$\pi_s^\dagger$,
we have
\begin{equation*}
\IM \pi_s^\dagger
 \ = \  (\pi^\dagger_s)_\diamond(1) \ =\ 
 (\pi_s)^\diamond(1) \ = \  \ceil{1 \after \pi_s}
 \ =\  1
\end{equation*}
and similarly~$\ceil{1 \after \pi_s^\dagger} = \IM \pi_s = s$.
As~$1 \after \pi_s^\dagger \leq \ceil{1 \after \pi_s^\dagger} = s$,
    there is some pure~$h$ with~$\pi_s^\dagger = h \after \zeta_s$.
By \sref{standard-form-map},
    there is also some pure and faithful~$g$
    with~$\zeta_s^\dagger = \pi_s \after g$.
Using~$\zeta_s \after \pi_s = \id$ twice we find
\begin{equation}\label{eq-dagger-zeta-pi-conn}
    \id \ =\  \id^\dagger
    \ = \ \pi_s^\dagger \after \zeta_s^\dagger
    \ = \ h \after \zeta_s \after \pi_s \after g 
    \ = \ h \after g.
\end{equation}
Now~$1= 1 \after h \after g \leq 1 \after g$ and so~$g$ is total.
Clearly~$\zeta_s^\dagger\after\zeta_s$ is~$\dagger$-positive,
    hence~$\diamond$-positive and so by uniqueness of~$\diamond$-positive maps:
\begin{equation*}
\zeta_s^\dagger \after \zeta_s
    \ = \ \asrt_{1 \after \zeta_s^\dagger \after \zeta_s}
    \ =\  \asrt_{1 \after \pi_s \after g\after \zeta_s}
    \ =\  \asrt_s
    \ =\  \pi_s \after \zeta_s.
\end{equation*}
So by epicity of~$\zeta_s$, we find~$\zeta_s^\dagger = \pi_s$, as desired.\qed
\end{point}
\end{point}
\begin{point}{90}[dagger-of-iso]{Corollary}%
    In a~$\dagger$-effectus,
        $\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$.
    Also~$\alpha^\dagger = \alpha^{-1}$
        for any iso~$\alpha$.
\end{point}
\begin{point}{100}[zeta-through-asrt]{Exercise}%
Show that in an~$\&$-effectus
        where every predicate has a square root
        and where~$\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$
        (e.g.~a~$\dagger$-effectus)
        we have
    $\asrt_p \after \zeta_s \ = \ \zeta_s \after \asrt_{p \after \zeta_s}$.
    (Hint: mimic the proof of \sref{asrt-iso}.)
\end{point}
\begin{point}{110}[dagger-thm-necessity]{Theorem}%
    A~$\dagger$-effectus is a~$\dagger'$-effectus.
\begin{point}{120}{Proof}%
Assume~$C$ is a~$\dagger$-effectus.
Axiom 1 is already proven in \sref{dagger-eff-square-root}.
\begin{point}{130}[pqqp-from-dagger]{Ax.~2}%
Let~$p,q$ be predicates.
To start, note~$1 \after \asrt_q\after  \asrt_p = \andthen{p}{q}$ and
\begin{equation*}
    \IM \asrt_q \after \asrt_p \ =\ 
        (\asrt_q)_\diamond(p) \ = \ 
        (\asrt_q)^\diamond(p) \ = \ 
        \ceil{\andthen{q}{p}}.
\end{equation*}
So using \sref{standard-form-map}
    we know
\begin{equation*}
    \asrt_q \after \asrt_p \ =\ 
    \pi_{\ceil{\andthen{q}{p}}}
    \after \alpha \after \zeta_{\ceil{\andthen{p}{q}}} \after \asrt_{\andthen{p}{q}}
\end{equation*}
for some iso~$\alpha$.
Applying the dagger to both sides
we get, using \sref{dagger-of-zeta} and \sref{dagger-of-iso}:
\begin{align*}
    \asrt_p \after \asrt_q &\ =\ 
    (\asrt_q \after \asrt_p)^\dagger \\
    & \ =\  \asrt_{\andthen{p}{q}}
    \after \zeta^\dagger_{\ceil{\andthen{p}{q}}}
    \after \alpha^\dagger \after
    \pi^\dagger_{\ceil{\andthen{q}{p}}} \\
    & \ = \ 
    \asrt_{\andthen{p}{q}}
    \after \pi_{\ceil{\andthen{p}{q}}}
    \after \alpha^{-1} \after
    \zeta_{\ceil{\andthen{q}{p}}}.
\end{align*}
Combining both:
\begin{align*}
    & \asrt_p \after \asrt_q^2 \after \asrt_p \\
    &\qquad = \ \asrt_{\andthen{p}{q}}
    \after \pi_{\ceil{\andthen{p}{q}}}
    \after \alpha^{-1} \after
    \zeta_{\ceil{\andthen{q}{p}}}
    \after \pi_{\ceil{\andthen{q}{p}}}
    \after \alpha \after \zeta_{\ceil{\andthen{p}{q}}} \after \asrt_{\andthen{p}{q}} \\
    &\qquad = \ \asrt_{\andthen{p}{q}}
    \after \pi_{\ceil{\andthen{p}{q}}}
    \after \zeta_{\ceil{\andthen{p}{q}}} \after \asrt_{\andthen{p}{q}} \\
    &\qquad = \ \asrt_{\andthen{p}{q}}
    \after \asrt_{\ceil{\andthen{p}{q}}}
    \after \asrt_{\andthen{p}{q}} \\
    &\qquad \overset{\smash{\mathclap{\sref{asrt-absorp-rule}}}}{=} \ 
    \asrt_{\andthen{p}{q}}^2,
\end{align*}
as desired.
\end{point}
\begin{point}{140}{Ax.~3}%
Pick any sharp predicates~$s,t$.
We want to show~$t \after \zeta_s$ is sharp.
To this end, we will show~$t \after \zeta_s$
    is the image of~$\pi_s \after \pi_t$.
Clearly~$t \after \zeta_s \after \pi_s \after \pi_t = 1$.
Let~$p$ be any sharp predicate with~$p \after \pi_s \after \pi_t = 1$.
Then~$p \after \pi_s \geq \IM \pi_t = t$.
So~$  p^\perp \after \pi_s \leq t^\perp$
and hence~$\ceil{p^\perp \after \pi_s} \leq t^\perp$.
As~$\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$ by \sref{dagger-of-iso},
we get~$t \after \zeta_s \leq \ceil{t \after \zeta_s} \leq p$,
    which shows~$t \after \zeta_s$
    is the image of~$\pi_s \after \pi_t$
    and consequently sharp. \qed
\end{point}
\end{point}
\end{point}

    
\end{parsec}

\begin{parsec}{2170}%
\begin{point}{10}%
Let~$f$ be a pure map in a~$\dagger'$-effectus.
We will work towards the definition of~$f^\dagger$.
By \sref{standard-form-map} we
know there is an iso~$\alpha$ with
\begin{equation*}
f  \ =\   \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1\after f}}
            \after \asrt_{1 \after f}.
\end{equation*}
In a~$\dagger$-effectus
    we have~$\asrt_p^\dagger = \asrt_p$,
    $\zeta_s^\dagger = \pi_s$,
    $\alpha^\dagger = \alpha^{-1}$
    and~$\pi_s^\dagger = \zeta_s$ 
    (for corresponding~$\zeta_s$ and~$\pi_s$)
    ---
    so we are forced to define~
\begin{equation}\label{dagger-definition}
    f^\dagger
        \ =\  \asrt_{1 \after f} \after
    \pi_{\ceil{1\after f}} \after
    \alpha^{-1} \after
    \zeta_{\IM f},
\end{equation}
    where~$\zeta_{\IM f}$
    is the unique corresponding
        quotient of~$\pi_{\IM f}$
        and~$\pi_{\ceil{1 \after f}}$
        the unique corresponding comprehension of
        and~$\zeta_{\ceil{1 \after f}}$,
        see \sref{zeta-s-convention}.
Before we declare~\eqref{dagger-definition} a definition,
 we have to check whether it is independent
    of choice of~$\pi$ (and corresponding $\zeta$).
    So suppose~$ f  =  \pi' \after \alpha' \after \zeta'
        \after \asrt_{1 \after f}$
        for some iso~$\alpha'$, comprehension~$\pi'$ of~$\IM f$
        and quotient~$\zeta'$ of~$\smash{\ceil{1 \after f}^\perp}$.
There are isos~$\beta$ and~$\gamma$
    such that~$\pi' = \pi_{\IM f} \after \beta$
    and~$\zeta' = \gamma \after \zeta_{\ceil{1 \after f}}$.
We will take a moment to relate~$\alpha$ and~$\alpha'$:
as~$\pi_{\IM f}$ is mono
    and~$\zeta_{1 \after f}\after\asrt_{1 \after f}$
    is epic,
    we have~$\beta\after\alpha'\after\gamma = \alpha$
    and so~$(\alpha')^{-1}= \gamma \after\alpha^{-1}\after\beta$.
To continue,
it is easy to see~$\beta^{-1} \after \zeta_{\IM f}$
    is the unique corresponding quotient to~$\pi'$
    and~$\pi_{\ceil{1 \after f}}\after \gamma^{-1}$
    is the unique corresponding comprehension to~$\zeta'$.
So with this choice of quotient and comprehension,
    we are forced to define
\begin{align*}
    f^\dagger 
    &\ = \ \asrt_{1 \after f}\after \pi_{\ceil{1 \after f}}
    \after \gamma^{-1} \after {\alpha'}^{-1}
                \after \beta^{-1}\after \zeta_{\IM f} \\
    &\ = \ \asrt_{1 \after f}\after \pi_{\ceil{1 \after f}}
                \after \gamma^{-1} \after \gamma \after \alpha^{-1} \after \beta 
                \after \beta^{-1}\after \zeta_{\IM f} \\
    &\ = \ \asrt_{1 \after f}\after \pi_{\ceil{1 \after f}}
                \after \alpha^{-1} \after \zeta_{\IM f},
\end{align*}
which is indeed consistent with~\eqref{dagger-definition}.
So we are justified to declare:
\end{point}
\begin{point}{20}[dagger-definition2]{Definition}%
In a~$\dagger'$-effectus, for a pure map~$f$, define
    \index{*dagg@$\dagger$, dagger!in a $\dagger'$-effectus}
\begin{equation*}
    \Define{f^\dagger}
        \ =\  \asrt_{1 \after f} \after
    \pi_{\ceil{1\after f}} \after
    \alpha^{-1} \after
    \zeta_{\IM f},
\end{equation*}
where~$\alpha$ is the unique iso such that
$f  =  \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1\after f}}
            \after \asrt_{1 \after f}$.
\end{point}
\begin{point}{30}[dagger-prime-basics]{Exercise}%
Show that in a~$\dagger'$-effectus,
    we have
\begin{align*}
    \asrt_p^\dagger &= \asrt_p &
    \pi_s^\dagger &= \zeta_s &
    \zeta_s^\dagger &= \pi_s &
    \alpha^\dagger &= \alpha^{-1}
\end{align*}
for a quotient~$\zeta_s$ corresponding to~$\pi_s$
and iso~$\alpha$.
\end{point}
\end{parsec}

\begin{parsec}{2180}%
\begin{point}{10}%
To compute~$f^{\dagger\dagger}$,
    we need to put~$f^\dagger$
    in the standard form of~\sref{standard-form-map}.
To do this, we need to pull~$\asrt_p$ from one side to the other.
In this section we will work towards a general result for this.
\end{point}
\begin{point}{20}[quotcompr-diamond-adjoint]{Lemma}%
In a~$\dagger'$-effectus,
$\pi_s$ is~$\diamond$-adjoint to~$\zeta_s$.
\begin{point}{30}{Proof}%
    Pick any sharp~$t,u$.
We have to
    show~$t \after \zeta_s \leq u^\perp$
    if and only if~$u \after \pi_s \leq t^\perp$.
So assume~$t \after \zeta_s \leq u^\perp$.
Then~$t =  t\after \zeta_s \after \pi_s  \leq  u^\perp \after \pi_s
                 =  (u \after \pi_s)^\perp$
    so~$u \after \pi_s \leq t^\perp$.
For the converse, assume~$u \after \pi_s \leq t^\perp$.
Then~$u \after \asrt_s = u \after \pi_s \after \zeta_s \leq t^\perp \after \zeta_s$.
From this,
    the
    $\diamond$-self-adjointness of~$\asrt_s$
    and the fact that~$t^\perp \after \zeta_s$ is sharp,
    we find~$(t^\perp \after \zeta_s)^\perp \after \pi_s \after \zeta_s \leq
        u^\perp$
    and so
\begin{alignat*}{2}
    t \after \zeta_s
    &\ =\  (t^\perp \after \id)^\perp \after \zeta_s \\
    &\ =\  (t^\perp \after \zeta_s \after \pi_s)^\perp \after \zeta_s \\
    &\ =\  (t^\perp \after \zeta_s)^\perp \after \pi_s \after \zeta_s \\
    &\ \leq \ u^\perp,
\end{alignat*}
as desired. \qed
\end{point}
\end{point}
\begin{point}{40}[dfn-pristine]{Definition}%
    In an~$\&$-effectus, a map~$f$ is \Define{pristine}\index{pristine}
        if it is pure and~$1\after f$ is sharp.
\begin{point}{50}{Remarks}%
    In general, pristine maps are not closed under composition:
    in~$\op\vN$, the maps~$\asrt_{\ketbra{0}{0}}$
            and~$\asrt_{\ketbra{+}{+}}$ on~$M_2$
            are both pristine,
            but their composite is not.
However, with a non-standard composition
    of pristine maps
    (namely~$f \cdot g \equiv \asrt_{\floor{1 \after f \after g}}
    \after f \after g$),
    the pristine maps are closed under composition and even
    form a~$\dagger$-category \cite{effintro}.
Essentially the same construction
    has been found independently by~\cite{hines2010structure}
    for partial isometries between Hilbert spaces.
\end{point}
\end{point}
\begin{point}{60}[standard-form-pristine]{Exercise}%
Show that in an~$\&$-effectus, every pristine map~$h$ is of the form
        \begin{equation*}
            h \ =\ \pi_{\IM h} \after \alpha \after \zeta_{1 \after h}
        \end{equation*}
        for some iso~$\alpha$.
\end{point}
\begin{point}{70}[pristine-asrt]{Proposition}%
In a~$\dagger'$-effectus,
    with pristine map~$h$, we have
\begin{equation*}
    \asrt_p \after h
        \ =\  h \after \asrt_{p \after h}
\end{equation*}
for any predicate~$p$ with~$p \leq \IM h$.
\begin{point}{80}{Proof}%
For brevity,
write~$t = 1 \after h$
    and~$s = \IM h$.
By~\sref{standard-form-pristine}
    there is some iso~$\alpha$
    such that~$h = \pi_s \after \alpha \after \zeta_t$.
    Note~$\IM \asrt_p = \ceil{p } \leq \ceil{s} = s$
    and so~$\asrt_p = \asrt_{s} \after \asrt_p$
    by the first rule of \sref{asrt-absorp-rule}.
By the second rule of \sref{asrt-absorp-rule}
    and~$1 \after p = p \leq s$,
    we see~$p = p \after \asrt_{s}$.
Thus
\begin{alignat*}{2}
    \asrt_p \after \pi_{s}
    &\ =\  \asrt_{s} \after \asrt_{p \after \asrt_{s}} \after \pi_{s} \\
    &\ =\  \pi_{s} \after \zeta_{s} \after
    \asrt_{p \after \pi_{s} \after \zeta_{s}} \after \pi_{s} \\
    &\ =\  \pi_{s}  \after
    \asrt_{p \after \pi_{s}} \after \zeta_{s} \after \pi_{s} 
    &\qquad& \text{by \sref{zeta-through-asrt}
                    and \sref{quotcompr-diamond-adjoint} }\\
    &\ =\  \pi_{s}  \after
    \asrt_{p \after \pi_{s}}.
\end{alignat*}
Putting everything together
\begin{alignat*}{2}
   \asrt_p \after h
   & \ =\  \asrt_p \after \pi_s \after \alpha \after \zeta_t \\
   & \ =\  \pi_s \after \asrt_{p\after\pi_s} \after \alpha \after \zeta_t  \\
   & \ =\  \pi_s \after \alpha \after \asrt_{p\after\pi_s \after \alpha} \after \zeta_t 
   &\qquad&\text{by \sref{asrt-iso}}\\
   & \ =\  \pi_s \after \alpha \after \zeta_t \after \asrt_{p\after\pi_s \after \alpha \after \zeta_t} 
    &\qquad& \text{by \sref{zeta-through-asrt}
                    and \sref{quotcompr-diamond-adjoint} }\\
   & \ = \ h \after \asrt_{p \after h},
\end{alignat*}
as desired.\qed
\end{point}
\end{point}
\begin{point}{90}[asrt-pristine-reverse]{Exercise}%
Working in a~$\dagger'$-effectus, show in order
\begin{enumerate}
    \item if~$h \equiv \pi_{\IM h} \after \alpha \after \zeta_{1 \after h}$
            is some pristine map,
            then~$h^\dagger = \pi_{1 \after h} \after \alpha^{-1} \after \zeta_{\IM h}$;
    \item $h^{\dagger\dagger} = h$ for any pristine~$h$;
    \item $h^\dagger \after h = \asrt_{1 \after h}$ for any pristine map~$h$;
    \item $p \after h^\dagger \leq \IM h$ for any predicate~$p$
        and pristine map~$h$ \emph{and}
    \item
        if~$p \leq 1 \after h$,
        then~$\asrt_{p\after h^\dagger} \after h = h \after \asrt_p$
        for any pristine map~$h$.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{100}[prist-asrt-decomp]{Proposition}%
In a~$\dagger'$-effectus,
        for every pure map~$f$,
    there exists a unique pristine map~$h$
    with~$1 \after h = \ceil{1 \after f}$
    and~$f = h \after \asrt_{1 \after f}$.
    Furthermore~$f^\dagger = \asrt_{1 \after f}\after h^\dagger$.
\begin{point}{110}{Proof}%
By~\sref{standard-form-map}
 we know~$f = \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1 \after f}}
        \after \asrt_{1 \after f}$
        for some iso~$\alpha$.
Define~$h = \pi_{\IM f} \after \alpha \after \zeta_{\ceil{1 \after f}}$.
Clearly~$1 \after h = \ceil{1 \after f}$
    and $f = h \after \asrt_{1 \after f}$.
    Also
    \begin{alignat*}{2}
        f^\dagger &\ \equiv\ 
        \asrt_{1 \after f}
            \after \pi_{\ceil{1 \after f}}
            \after \alpha^{-1}
            \after \zeta_{\IM f} \\
        &\ = \ 
        \asrt_{1 \after f}
        \after \asrt_{\ceil{1 \after f}}
            \after \pi_{\ceil{1 \after f}}
            \after \alpha^{-1} 
            \after \zeta_{\IM f} 
            &\qquad&\text{by \sref{asrt-absorp-rule}}
            \\
        &\ \equiv \ 
        \asrt_{1 \after f}
        \after h^\dagger.
\end{alignat*}
Only uniqueness remains.
Assume~$f = h' \after \asrt_{1 \after f}$
    for some pristine
    map~$h'$ with~$\ceil{1 \after h'} = \ceil{1 \after f}$.
By \sref{standard-form-map} and \sref{asrt-absorp-rule},
    there is an iso~$\alpha'$
    with~$h' = \pi_{\IM h} \after \alpha' \after \zeta_{\ceil{1 \after f}}$.
As~$\zeta_{\ceil{1 \after f}} \after \asrt_{1 \after f}$
    is a quotient (by \sref{zeta-asrt-quot}),
    quotients are faithful and~$f = h' \after \asrt_{1 \after f}$,
    we see~$\IM h' = \IM f$
    and so~$\alpha = \alpha'$ by \sref{standard-form-map}.\qed
\end{point}
\end{point}
\begin{point}{120}[dagger-idempotent]{Proposition}%
    In a~$\dagger'$-effectus, we have~$f^{\dagger\dagger}=f$
        for any pure map~$f$.
\begin{point}{130}{Proof}%
By~\sref{prist-asrt-decomp}
    we have~$f = h \after \asrt_{1\after f}$
    and~$f^\dagger = \asrt_{1 \after f} \after h^\dagger$
    for some pristine~$h$
    with~$1 \after h = \ceil{1 \after f}$.
Clearly~$1 \after f \leq \ceil{1 \after f} = 1 \after h = \IM h^\dagger$,
    so by \sref{pristine-asrt}
    we get~$f^\dagger = \asrt_{1 \after f} \after h^\dagger
              = h^\dagger \after \asrt_{1 \after f \after h^\dagger}$.
Consequently
\begin{equation*}
    f^{\dagger\dagger}
    \ =\  \asrt_{1 \after f\after h^\dagger} \after h^{\dagger\dagger}
    \ \overset{\sref{asrt-pristine-reverse}}{=}\  \asrt_{1 \after f\after h^\dagger} \after h
    \ \overset{\sref{asrt-pristine-reverse}}{=}\  h\after \asrt_{1 \after f}
    \ = \ f,
\end{equation*}
as desired. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{2190}%
\begin{point}{10}%
Now we tackle the most tedious part
    of \sref{dagger-theorem}:
    we will show~$(f \after g)^\dagger = g^\dagger \after f^\dagger$
    in a~$\dagger'$-effectus.
To avoid too much repetition, let us fix the setting.
\end{point}%
\begin{point}{20}[dagger-setting]{Setting}%
Let~$f,g$ be two composable pure maps in a~$\dagger'$-effectus.
For brevity, write~$p = 1 \after f$, $q = 1 \after g$,
    $s = \IM f$ and $t = \IM g$.
Let~$\varphi$ and~$\psi$
be the unique isomorphisms (see \sref{standard-form-map}) such that
\begin{equation*}
    f \ =\  \pi_s \after \varphi \after \zeta_{\ceil{p}} \after \asrt_p 
    \qquad \text{and} \qquad
    g \ =\  \pi_t \after \psi \after \zeta_{\ceil{q}} \after \asrt_q.
\end{equation*}
Define~$
    h = \pi_s \after \varphi \after \zeta_{\ceil{p}}$
    and~$k = \pi_t \after \psi \after \zeta_{\ceil{q}}$.
To compute~$(f\after g)^\dagger$,
    we have to put~$f\after g$
    in the standard form
    of~\sref{standard-form-map}.
We will do this step-by-step,
    first we put~$\zeta_{\ceil{p}} \after \asrt_p \after \pi_t$
        in standard form.
\begin{align*}
1 \after \zeta_{\ceil{p}} \after \asrt_p \after \pi_t
&\ =\  \ceil{p} \after \asrt_p \after \pi_t
    \ \overset{\sref{asrt-absorp-rule}}{=}\  p \after \pi_t\\
    \IM \zeta_{\ceil{p}}  \after \asrt_p \after \pi_t &\ = \ 
(\zeta_{\ceil{p}}  \after \asrt_p)_\diamond(t)
\ \overset{\sref{quotcompr-diamond-adjoint}}{=} \ \ceil{t \after \asrt_p \after \pi_{\ceil{p}}}.
\end{align*}
Thus there is a unique isomorphism~$\chi$ with
\begin{equation}\label{dagger-iso-chi}
    \zeta_{\ceil{p}} \after \asrt_p \after \pi_t
    \ = \ \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after \chi \after \zeta_{\ceil{p \after \pi_t}} \after \asrt_{p \after \pi_t}.
\end{equation}
Next, we consider~$\asrt_{p \after k}
                        \after \asrt_q$, clearly
\begin{equation*}
    1 \after \asrt_{p \after k}
\after \asrt_q 
\ =\ p \after k
\after \asrt_q \ = \ p \after g.
\end{equation*}
Concerning the image, first
    note~$p \after k = p \after \pi_t \after \psi \after \zeta_{\ceil{q}}
    \leq 1 \after \zeta_{\ceil{q}} = \ceil{q}$
        and so we must have~$\IM \asrt_{p \after k} \leq \ceil{q}$, which implies
\begin{equation*}
\IM \asrt_{p \after k}
\after \asrt_q
\ = \ (\asrt_{p \after k})_\diamond(q)
\ =\  \ceil{\ceil{q} \after \asrt_{p \after k}}
\ =\  \ceil{p \after k}.
\end{equation*}
So there is a unique isomorphism~$\omega$ such that
\begin{equation}\label{dagger-iso-omega}
\asrt_{p \after k} \after \asrt_q
    \ =\   \pi_{\lceil p \after k \rceil}
    \after \omega \after \zeta_{\ceil{p \after g}} \after \asrt_{p \after g}.
\end{equation}
Next, we consider~$
\zeta_{\ceil{p \after \pi_t}} \after \psi \after
                \zeta_{\ceil{q}}$.
Note~$\psi \after \zeta_{\ceil{q}}$
    is a quotient for a sharp predicate,
    hence sharp and so~$\ceil{p \after \pi_t} \after \psi \after \zeta_{\ceil{q}}
                =\lceil p \after \pi_t \after \psi
                \after \zeta_{\ceil{q}}\rceil = \lceil p \after k \rceil$
                by \sref{sharp-ceil}.
As quotients are closed under composition
(\sref{quotients-composition}),
    there is an iso~$\beta$
    with
    \begin{equation}\label{dagger-iso-beta}
    \zeta_{\ceil{p \after \pi_t}} \after \psi \after \zeta_{\ceil{q}}
    \ = \ \beta \after \zeta_{\ceil{p \after k}}.
\end{equation}
Finally, we deal with~$
\pi_s \after \varphi \after 
\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil}
$.
By \sref{upm-closed} this is again a comprehension.
We compute
\begin{align*}
    \IM
\pi_s \after \varphi \after 
\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil}
& \ = \ 
(\pi_s \after \varphi \after 
\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil})_\diamond(1)
\\
& \ \overset{\smash{\mathclap{\sref{quotcompr-diamond-adjoint}}}}{=}\ 
\zeta_s^\diamond ( \varphi_\diamond (
\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil)) \\
& \ =\ 
\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil
\after \varphi^{-1} \after \zeta_s \\
& \ \overset{\smash{\mathclap{\sref{sharp-ceil}}}}{=}\ 
\lceil t \after \asrt_p \after \pi_{\ceil{p}}
\after \varphi^{-1} \after \zeta_s \rceil \\
& \ =\ 
\lceil t \after f^\dagger\rceil
\end{align*}
and so there must be a unique iso~$\alpha$ with
\begin{equation}\label{dagger-iso-alpha}
    \pi_s \after \varphi \after \pi_{\lceil t \after \asrt_p \after
    \pi_{\ceil{p}} \rceil} = \pi_{\ceil{t \after f^\dagger}} \after \alpha.
\end{equation}
\end{point}
\spacingfix{}
\begin{point}{30}{Lemma}%
In setting \sref{dagger-setting}, we have
    $f \after g  =  \pi_{\ceil{t \after f^\dagger}}
        \after \alpha \after \chi \after \beta \after \omega
        \after \zeta_{\ceil{p \after g}} \after
        \asrt_{p \after g}$.
\begin{point}{40}{Proof}%
It's a long, but easy verification,
    either with a diagram
\begin{equation*}
    \xymatrix@C+3pc {
        \bullet \ar[rr]^g
        \ar[rd]|{\asrt_q}
        \ar[ddd]_{\rotatebox{90}{$\scriptstyle\omega\after\zeta_{\ceil{p \after g}} \after \asrt_{p \after g}$}}
        && \bullet \ar[rr]^f
            \ar[rd]|{\zeta_{\ceil{p}}\after \asrt_p}
        && \bullet
            \\ \ar@{}[rd]|{\text{\eqref{dagger-iso-omega}}}
            & \bullet
                \ar[r]^{\psi \after \zeta_{\ceil{q}}}
                \ar[d]|{\asrt_{p \after k}}
                \ar@{}[rd]|{\text{\sref{pristine-asrt}}}
 & \bullet
            \ar[u]^{\pi_t}
            \ar[d]|{\asrt_{p \after \pi_t}}
            & \bullet \ar[ru]_{\pi_s\after\varphi}
            \ar@{}[rd]|{\text{\eqref{dagger-iso-alpha}}}
            \\& \bullet \ar[r]^{\psi \after \zeta_{\ceil{q}}}
                        \ar[d]|{\zeta_{\ceil{p \after k}}}
                \ar@{}[rd]|{\text{\eqref{dagger-iso-beta}}}
            &\bullet \ar[d]|{\zeta_{\ceil{p \after \pi_t}}}
                        \ar@{}[ru]|{\text{\eqref{dagger-iso-chi}}}
                        &&
            \\ \bullet \ar@{=}[r]
            \ar[ru]^{\pi_{\ceil{p \after k}}}
            &\bullet \ar[r]_\beta
            &\bullet \ar[rr]_\chi
            &&\bullet \ar[uuu]_{\rotatebox{90}{$\scriptstyle\pi_{\ceil{t \after f^\dagger}} \after \alpha$}}
                        \ar[luu]|{\pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}}
        }
\end{equation*}
or with equational reasoning
\begin{align*}
   f \after g
    & \ = \ \pi_s \after \varphi \after \zeta_{\ceil{p}}
        \after \asrt_p \after \pi_t \after \psi \after \zeta_{\ceil{q}}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-chi}}}}{=} \ 
        \pi_s \after \varphi \after
        \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \chi \after \zeta_{\ceil{p \after \pi_t}}
        \after \asrt_{p \after \pi_t}
    \after \psi \after 
        \zeta_{\ceil{q}}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\sref{pristine-asrt}}}}{=} \ 
        \pi_s \after \varphi \after
        \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \chi \after \zeta_{\ceil{p \after \pi_t}}
        \after \psi \after \zeta_{\ceil{q}}
        \after \asrt_{p \after k}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-beta}}}}{=} \ 
        \pi_s \after \varphi \after
        \pi_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \chi
        \after \beta \after \zeta_{\ceil{p \after k}}
        \after \asrt_{p \after k}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-alpha}}}}{=} \ 
        \pi_{\ceil{t \after f^\dagger}}\after\alpha
        \after \chi
        \after \beta \after \zeta_{\ceil{p \after k}}
        \after \asrt_{p \after k}
        \after \asrt_q \\
    & \ \overset{\smash{\mathclap{\eqref{dagger-iso-omega}}}}{=} \ 
        \pi_{\ceil{t \after f^\dagger}}\after\alpha
        \after \chi
        \after \beta \after \zeta_{\ceil{p \after k}}
        \after \pi_{\ceil{p \after k}} \after \omega
            \after \zeta_{\ceil{p \after g}}
            \after \asrt_{p \after g} \\
    & \ = \ 
        \pi_{\ceil{t \after f^\dagger}}\after\alpha
        \after \chi
        \after \beta \after
        \omega
            \after \zeta_{\ceil{p \after g}}
            \after \asrt_{p \after g},
\end{align*}
whichever the Reader might prefer. \qed
\end{point}
\end{point}
\begin{point}{50}[dagger-of-fg]{Corollary}%
    $(f \after g)^\dagger = \asrt_{p \after g}
                \after \pi_{\ceil{p \after g}}
                \after \omega^{-1}
                \after \beta^{-1}
                \after \chi^{-1}
                \after \alpha^{-1}
                \after \zeta_{\ceil{t \after f^\dagger}} $ .
\begin{point}{60}%
To show~$(f \after g)^\dagger = g^\dagger \after f^\dagger$,
    it is sufficient to proof that
    the `daggered' version
    of each of the subdiagrams
        \eqref{dagger-iso-alpha},
        \eqref{dagger-iso-beta},
        \eqref{dagger-iso-chi},
        \eqref{dagger-iso-omega} and
        \sref{pristine-asrt} of the above diagram holds.
We start with the simple ones.
\end{point}
\end{point}
\begin{point}{70}[dagger-iso-beta2]{Lemma}%
In setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-beta} holds --- that is:
    \begin{equation*}
        \pi_{\ceil{p \after k}} \after \beta^{-1}
            \ =\  \pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}.
    \end{equation*}
\spacingfix{}
\begin{point}{80}{Proof}%
The map~$
\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}} \after \beta$
is a comprehension for~$\ceil{p \after k}$ --- indeed
\begin{align*}
    (\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}\after\beta)_\diamond(1)
    &\ = \ 
    (\zeta^\diamond_{\ceil{q}} \after \psi^\diamond) (\ceil{p \after \pi_t})\\
    &\ = \ \ceil{p \after \pi_t} \after \zeta_{\ceil{q}} \after \psi \\
    &\ = \ \ceil{p \after \pi_t \after \zeta_{\ceil{q}} \after \psi} \\
    &\ = \ \ceil{p \after k}.
\end{align*}
Furthermore
\begin{align*}
    &\zeta_{\ceil{p \after k}} \after
    \pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
    \after \beta \\
    & \qquad \ \overset{\mathclap{\eqref{dagger-iso-beta}}}{=}\  
    \beta^{-1}\after \zeta_{\ceil{p \after \pi_t}}
    \after \psi \after \zeta_{\ceil{q}}
    \after \pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
    \after \beta \\
    & \qquad \ = \ \id.
\end{align*}
So~$
\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
\after \beta
$ is the unique comprehension corresponding to~$\zeta_{\ceil{p \after k}}$ --- that is:~$
\pi_{\ceil{q}} \after \psi^{-1} \after \pi_{\ceil{p \after \pi_t}}
\after \beta \ = \ \pi_{\ceil{p \after k}} $,
as desired. \qed
\end{point}
\end{point}
\begin{point}{90}[dagger-iso-alpha2]{Exercise}%
Show that in the setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-alpha} holds --- i.e.
    \begin{equation*}
        \alpha^{-1} \after \zeta_{\ceil{t \after f^\dagger}}
        \ =\   \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}
        \after \varphi^{-1} \after \zeta_s.
    \end{equation*}
(Hint: mimic the proof of~\sref{dagger-iso-beta2}.)
\end{point}
\begin{point}{100}[dagger-iso-zeta2]{Exercise}%
Show that in the setting \sref{dagger-setting},
we have
\begin{equation*}
    \pi_{\ceil{q}} \after \psi^{-1} \after \asrt_{p \after \pi_t}
    \ = \ \asrt_{p \after k} \after \pi_{\ceil{q}} \after \psi^{-1}.
\end{equation*}
(This is the daggered version of the subdiagram
marked~\sref{pristine-asrt}.)
\end{point}
\begin{point}{110}[dagger-iso-mu]{Proposition}%
If in a~$\dagger'$-effectus,
$\nu$ is the unique iso (cf.~\sref{pqqp-from-dagger}) such that
\begin{equation*}
    \asrt_a \after \asrt_b\  =\  \pi_{\ceil{\andthen{a}{b}}} 
    \after \nu \after \zeta_{\ceil{\andthen{b}{a}}} \after \asrt_{\andthen{b}{a}},
\end{equation*}
then~$\asrt_b \after \asrt_a\  =\  \asrt_{\andthen{b}{a}}
        \after \pi_{\ceil{\andthen{b}{a}}} 
        \after \nu^{-1} \after \zeta_{\ceil{\andthen{a}{b}}}$.
\begin{point}{120}{Proof}%
Let~$\mu$ be the unique iso with~$
\asrt_b \after \asrt_a\  =\  
        \pi_{\ceil{\andthen{b}{a}}} 
        \after \mu \after \zeta_{\ceil{\andthen{a}{b}}}
                \after \asrt_{{\andthen{a}{b}}}$.
We will see~$\mu = \nu^{-1}$.
For brevity, write
\begin{align*}
    \overline{\andthen{a}{b}} &\ = \ (\andthen{a}{b}) \after \pi_{\ceil{\andthen{a}{b}}} &
\overline{\andthen{b}{a}} &\ = \ (\andthen{b}{a}) \after \pi_{\ceil{\andthen{b}{a}}}
\end{align*}
By \sref{asrt-pristine-reverse} and~\sref{asrt-absorp-rule}, we have
\begin{equation*}
    \pi_{\ceil{\andthen{a}{b}}} \after
\asrt_{\overline{\andthen{a}{b}}} \after
 \zeta_{\ceil{\andthen{a}{b}}}
    \ = \ 
    \pi_{\ceil{\andthen{a}{b}}} \after
 \zeta_{\ceil{\andthen{a}{b}}} \after
\asrt_{\andthen{a}{b}}
    \ = \ 
\asrt_{\andthen{a}{b}}.
\end{equation*}
Now the second axiom of a~$\dagger'$-effectus comes into play
\begin{align*}
    &\pi_{\ceil{\andthen{a}{b}}} \after
    \asrt^2_{\overline{\andthen{a}{b}}} \after \zeta_{\ceil{\andthen{a}{b}}} \\
    &\qquad \ = \ 
    \pi_{\ceil{\andthen{a}{b}}} \after
\asrt_{\overline{\andthen{a}{b}}} \after
 \zeta_{\ceil{\andthen{a}{b}}} \after
\pi_{\ceil{\andthen{a}{b}}} \after
\asrt_{\overline{\andthen{a}{b}}}
\after \zeta_{\ceil{\andthen{a}{b}}} \\
    &\qquad \ = \ 
\asrt_{\andthen{a}{b}}^2
\\
    &\qquad \ = \ 
\asrt_{a} \after
\asrt^2_{b}\after
\asrt_{a}
\\
    &\qquad \ = \ 
\pi_{\ceil{\andthen{a}{b}}} \after
    \nu \after
    \asrt_{\overline{\andthen{b}{a}}} \after
    \zeta_{\ceil{\andthen{b}{a}}} \after
\pi_{\ceil{\andthen{b}{a}}} \after
    \mu \after
    \asrt_{\overline{\andthen{a}{b}}} \after
    \zeta_{\ceil{\andthen{a}{b}}} 
\\
    &\qquad \ = \ 
\pi_{\ceil{\andthen{a}{b}}} \after
    \nu \after
    \asrt_{\overline{\andthen{b}{a}}} \after
    \mu \after
    \asrt_{\overline{\andthen{a}{b}}} \after
    \zeta_{\ceil{\andthen{a}{b}}}.
\end{align*}
Thus as quotients are epis and comprehensions are monos:
\begin{equation} \label{dagger-second-axiom-intermediate}
\asrt^2_{\overline{\andthen{a}{b}}}
         \ = \ \nu \after \asrt_{\overline{\andthen{b}{a}}}
            \after \mu \after \asrt_{\overline{\andthen{a}{b}}}.
\end{equation}
We want to show~$\asrt_{\overline{\andthen{a}{b}}}$ is an epi.
First note
\begin{equation*}
    \ceil{\overline{\andthen{a}{b}}}\after\zeta_{\ceil{\andthen{a}{b}}}
    \ \overset{\sref{sharp-ceil}}{=} \ 
    \ceil{\overline{\andthen{a}{b}}\after\zeta_{\ceil{\andthen{a}{b}}}}
    \ \overset{\sref{asrt-absorp-rule}}{=} \ 
    \ceil{\andthen{a}{b}} \ = \ 1 \after \zeta_{\ceil{\andthen{a}{b}}}
\end{equation*}
and so~$\IM \asrt_{\overline{\andthen{a}{b}}}
= \ceil{\overline{\andthen{a}{b}}} = 1 $,
    which tells us~$\asrt_{\overline{\andthen{a}{b}}}$
    is a quotient and therefore an epi.
    So, from \eqref{dagger-second-axiom-intermediate} we get
    $ \asrt_{\overline{\andthen{a}{b}}}
     =  \nu \after \asrt_{\overline{\andthen{b}{a}}} \after \mu$ and so
\begin{equation}\label{dagger-seqprod-inversion}
    \overline{\andthen{a}{b}}
    \ = \ 1 \after \asrt_{\overline{\andthen{a}{b}}}
    \ = \ 1 \after \nu \after \asrt_{\overline{\andthen{b}{a}}} \after \mu
    \ = \ \overline{\andthen{b}{a}} \after \mu.
\end{equation}
Using this equation again in the previous, we find
\begin{equation*}
    \nu \after \mu \after \asrt_{\overline{\andthen{a}{b}}}
            \ = \ 
    \nu \after \mu \after \asrt_{\overline{\andthen{b}{a}}\after \mu}
            \ = \ 
    \nu \after \asrt_{\overline{\andthen{b}{a}}} \after \mu
            \ = \ \asrt_{\overline{\andthen{a}{b}}}.
\end{equation*}
Thus~$\nu \after \mu = \id$ and so~$\mu = \nu^{-1}$.
Write~$l = \pi_{\ceil{\andthen{b}{a}}} \after \nu^{-1}
                        \after \zeta_{\ceil{\andthen{a}{b}}}$. Then
\begin{alignat*}{2}
    (\andthen{a}{b}) \after l^\dagger & \ = \ 
    (\andthen{a}{b})
        \after \pi_{\ceil{\andthen{a}{b}}} 
        \after \nu
        \after \zeta_{\ceil{\andthen{b}{a}}}  
        &\qquad& \text{by \sref{asrt-pristine-reverse}}\\
        & \ = \ 
        \overline{\andthen{a}{b}}
        \after \nu
        \after \zeta_{\ceil{\andthen{b}{a}}}  \\
        & \ = \ 
        \overline{\andthen{b}{a}}
        \after \zeta_{\ceil{\andthen{b}{a}}}  
        &&\text{by \eqref{dagger-seqprod-inversion} and~$\mu = \nu^{-1}$}\\
        & \ = \ 
        \andthen{b}{a}.
\end{alignat*}
And so, keeping in mind~$\andthen{a}{b} \leq \ceil{\andthen{a}{b}}
    =  1 \after l$,
we have
\begin{alignat*}{2}
    \asrt_b \after \asrt_a &\ = \ 
        l \after \asrt_{\andthen{a}{b}} \\
        & \ = \ 
        \asrt_{(\andthen{a}{b}) \after l^\dagger} \after l 
    &\qquad&\text{by \sref{asrt-pristine-reverse}} \\
        &\ = \ 
        \asrt_{\andthen{b}{a}} \after l \\
        &\ = \ 
        \asrt_{\andthen{b}{a}}
        \after \pi_{\ceil{\andthen{b}{a}}} 
        \after \nu^{-1} \after \zeta_{\ceil{\andthen{a}{b}}},
\end{alignat*}
as promised. \qed
\end{point}
\end{point}
\begin{point}{130}[dagger-iso-omega2]{Corollary}
In setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-omega} holds --- that is:
    \begin{equation*}
\asrt_q \after
\asrt_{p \after k}
    \ =\ 
    \asrt_{p \after g} \after
    \pi_{\ceil{p \after g}} \after
    \omega^{-1} \after
    \zeta_{\lceil p \after k \rceil}.
    \end{equation*}
\end{point}
\spacingfix{}
\begin{point}{140}[dagger-iso-chi2]{Lemma}%
In setting \sref{dagger-setting},
    the daggered version of
        \eqref{dagger-iso-chi} holds --- that is:
    \begin{equation*}
    \zeta_t \after
    \asrt_p \after
    \pi_{\ceil{p}}
    \ = \ 
    \asrt_{p \after \pi_t} \after
    \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil}.
    \end{equation*}
\spacingfix{}
\begin{point}{150}{Proof}%
The heavy lifting has been done in \sref{dagger-iso-mu} already. To start, note
    \begin{align*}
\asrt_p \after \asrt_t
& \ \overset{\mathclap{\smash{\sref{asrt-absorp-rule}}}}{=}
    \ \asrt_{\ceil{p}} \after \asrt_p  \after \asrt_t \\
    & \ = \ \pi_{\ceil{p}} \after \zeta_{\ceil{p}} \after \asrt_p \after
                    \pi_t \after \zeta_t \\
                    & \ \overset{\mathclap{\smash{\eqref{dagger-iso-chi}}}}{=} \ 
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \chi \after \zeta_{\ceil{p \after \pi_t}} \after
        \asrt_{p \after \pi_t} \after
        \zeta_t \\
                    & \ \overset{\mathclap{\smash{\sref{pristine-asrt}}}}{=} \ 
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \chi \after \zeta_{\ceil{p \after \pi_t}} \after
        \zeta_t \after
        \asrt_{p \after \pi_t\after \zeta_t} \\
                    & \  = \ 
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \chi \after
        \zeta_{\ceil{p \after \pi_t}} \after
        \zeta_t \after
        \asrt_{\andthen{t}{p}} \\
                    & \  = \ 
        \pi_{\ceil{\andthen{p}{t}}} \after \alpha_2 \after
        \chi \after \beta_2 \after
        \zeta_{\ceil{\andthen{t}{p}}} \after
        \asrt_{\andthen{t}{p}},
    \end{align*}
where~$\alpha_2$ and~$\beta_2$ are the unique isomorphisms such that
\begin{align*}
        \pi_{\ceil{p}} \after 
        \pi_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} &\ = \ 
            \pi_{\ceil{\andthen{p}{t}}} \after \alpha_2 &
        \zeta_{\ceil{p \after \pi_t}} \after
        \zeta_t
        &\ = \ 
        \beta_2 \after \zeta_{\ceil{\andthen{t}{p}}}.
\end{align*}
With the same reasoning as in \sref{dagger-iso-alpha2}
        and~\sref{dagger-iso-beta2}, we see
\begin{align*}
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \zeta_{\ceil{p}}
        &\ = \ 
        \alpha_2^{-1} \after
            \zeta_{\ceil{\andthen{p}{t}}}
            &
        \pi_t \after
        \pi_{\ceil{p \after \pi_t}}
        &\ = \ 
        \pi_{\ceil{\andthen{t}{p}}}
        \after \beta_2^{-1}.
\end{align*}
Now we can apply \sref{dagger-iso-mu}:
\begin{align*}
    \zeta_t \after \asrt_p \after \pi_{\ceil{p}} 
    &\ \overset{\smash{\mathclap{\sref{asrt-absorp-rule}}}}{=} \ 
    \zeta_t \after \asrt_t \after
    \asrt_p \after
    \pi_{\ceil{p}}
    \\
    &\ \overset{\smash{\mathclap{\sref{dagger-iso-mu}}}}{=} \ 
    \zeta_t \after \asrt_{\andthen{t}{p}} \after
    \pi_{\ceil{\andthen{t}{p}}} \after
    \beta_2^{-1} \after
    \chi^{-1} \after
    \alpha_2^{-1} \after
    \zeta_{\ceil{\andthen{p}{t}}} \after
    \pi_{\ceil{p}}
    \\
    &\ = \ 
    \zeta_t \after \asrt_{\andthen{t}{p}} \after
        \pi_t \after
        \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil} \after
        \zeta_{\ceil{p}} \after
    \pi_{\ceil{p}}
    \\
    &\ = \ 
    \zeta_t \after \asrt_{p \after \pi_t \after \zeta_t} \after
        \pi_t \after
        \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil}
    \\
    &\ = \ 
    \asrt_{p \after \pi_t} \after 
        \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
        \zeta_{\lceil t \after
        \asrt_p \after \pi_{\ceil{p}}\rceil},
\end{align*}
as desired. \qed
\end{point}
\end{point}
\begin{point}{160}[dagger-is-functor]{Proposition}%
In a~$\dagger'$-effectus~$(f \after g)^\dagger = g^\dagger \after f^\dagger$
    holds.
\begin{point}{170}{Proof}%
We work in setting~\sref{dagger-setting}.
The equality~$(f\after g)^\dagger = g^\dagger \after f^\dagger$
follows from~\sref{dagger-of-fg} and the commutativity
of the following diagram
\begin{equation*}
    \xymatrix@C+3pc {
        \bullet \ar@{<-}[rr]^{g^\dagger}
        \ar@{<-}[rd]|{\asrt_q}
        \ar@{<-}[ddd]_{\rotatebox{90}{$\scriptstyle
            \asrt_{p \after g}
            \pi_{\ceil{p \after g}} \after
            \omega^{-1}
        $}}
        && \bullet \ar@{<-}[rr]^{f^\dagger}
            \ar@{<-}[rd]|{ \asrt_p \after \zeta_{\ceil{p}} }
        && \bullet
            \\ \ar@{}[rd]|{\text{\sref{dagger-iso-omega2}}}
            & \bullet
            \ar@{<-}[r]^{ \pi_{\ceil{q}} \after \psi^{-1} }
            \ar@{<-}[d]|{\asrt_{p \after k}}
                \ar@{}[rd]|{\text{\sref{dagger-iso-zeta2}}}
 & \bullet
                \ar@{<-}[u]^{\zeta_t}
                \ar@{<-}[d]|{\asrt_{p \after \pi_t}}
                & \bullet \ar@{<-}[ru]_{\varphi^{-1} \after \zeta_s}
            \ar@{}[rd]|{\text{\sref{dagger-iso-alpha2}}}
            \\& \bullet \ar@{<-}[r]^{\pi_{\ceil{q}} \after \psi^{-1}}
            \ar@{<-}[d]|{\pi_{\ceil{p \after k}}}
                \ar@{}[rd]|{\text{\sref{dagger-iso-beta2}}}
                &\bullet \ar@{<-}[d]|{\pi_{\ceil{p \after \pi_t}}}
                        \ar@{}[ru]|{\text{\sref{dagger-iso-chi2}}}
                        &&
            \\ \bullet \ar@{=}[r]
            \ar@{<-}[ru]^{\zeta_{\ceil{p \after k}}}
            &\bullet \ar@{<-}[r]_{\beta^{-1}}
            &\bullet \ar@{<-}[rr]_{\chi^{-1}}
            &&\bullet \ar@{<-}[uuu]_{\rotatebox{90}{$\scriptstyle
    \alpha^{-1}\after \zeta_{\ceil{t \after f^\dagger}}$}}
    \ar@{<-}[luu]|{ \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}} \rceil}} }
\end{equation*}
or alternatively by
\begin{align*}
    g^\dagger \after f^\dagger
        & \ = \ 
            \asrt_q \after
            \pi_{\ceil{q}} \after
            \psi^{-1} \after
            \zeta_t \after
            \asrt_p \after
            \pi_{\ceil{p}} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-chi2}}}}{=} \ 
            \asrt_q \after
            \pi_{\ceil{q}} \after
            \psi^{-1} \after
    \asrt_{p \after \pi_t} \after
    \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-zeta2}}}}{=} \ 
            \asrt_q \after
    \asrt_{p \after k} \after
    \pi_{\ceil{q}} \after
    \psi^{-1} \after
    \pi_{\ceil{p \after \pi_t}} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-beta2}}}}{=} \ 
            \asrt_q \after
    \asrt_{p \after k} \after
        \pi_{\ceil{p \after k}} \after 
        \beta^{-1} \after
    \chi^{-1} \after
    \zeta_{\lceil t \after \asrt_p \after \pi_{\ceil{p}}\rceil} \after
            \varphi^{-1} \after
            \zeta_s
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-alpha2}}}}{=} \ 
            \asrt_q \after
    \asrt_{p \after k} \after
        \pi_{\ceil{p \after k}} \after 
        \beta^{-1} \after
    \chi^{-1} \after
        \alpha^{-1} \after
        \zeta_{\ceil{t \after f^\dagger}}
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-iso-omega2}}}}{=} \ 
    \asrt_{p \after g} \after
    \pi_{\ceil{p \after g}} \after
    \omega^{-1} \after
    \zeta_{\lceil p \after k \rceil} \after
        \pi_{\ceil{p \after k}} \after 
        \beta^{-1} \after
    \chi^{-1} \after
        \alpha^{-1} \after
        \zeta_{\ceil{t \after f^\dagger}}
        \\
        & \ = \ 
    \asrt_{p \after g} \after
    \pi_{\ceil{p \after g}} \after
    \omega^{-1} \after
        \beta^{-1} \after
    \chi^{-1} \after
        \alpha^{-1} \after
        \zeta_{\ceil{t \after f^\dagger}}
        \\
        & \ \overset{\smash{\mathclap{\sref{dagger-of-fg}}}}{=} \ 
        (f \after g)^\dagger,
\end{align*}
whichever the Reader might prefer. \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{2200}%
\begin{point}{10}%
We are ready to finish the proof of \sref{dagger-theorem}.
\end{point}
\begin{point}{20}[dagger-thm-sufficiency]{Theorem}%
    A~$\dagger'$-effectus is a~$\dagger$-effectus
        with~$\dagger$
            as defined in \sref{dagger-definition2}.
\begin{point}{30}{Proof}%
Let~$C$ be a~$\dagger'$-effectus.
\begin{point}{40}{Ax.~1}%
By~\sref{dagger-is-functor}, \sref{dagger-idempotent}
    and~\sref{dagger-prime-basics}
    the~$\dagger$ defined in~\sref{dagger-definition2}
    turns~$\Pure C$ into a~$\dagger$-category.
Also by~\sref{dagger-prime-basics},
    we have~$\asrt_p^\dagger = \asrt_p$
    for any predicate~$p$.
Pick any pure~$f$.
We have to show~$f$ is~$\diamond$-adjoint to~$f^\dagger$.
By~\sref{standard-form-map}
    we have~$f =
    \pi_{\IM f} \after \varphi \after \zeta_{\ceil{1 \after f}}
        \after \asrt_{1 \after f}$
        for some iso~$\alpha$.
We compute
\begin{align*}
   f_\diamond 
   & \ = \ 
   (\pi_{\IM f})_\diamond \after \varphi_\diamond \after (\zeta_{\ceil{1 \after f}})_\diamond
   \after (\asrt_{1 \after f})^\diamond \\
   & \ \overset{\mathclap{\smash{\sref{quotcompr-diamond-adjoint}}}}{=} \ 
   (\zeta_{\IM f})^\diamond \after \varphi_\diamond \after (\pi_{\ceil{1 \after f}})^\diamond
   \after (\asrt_{1 \after f})^\diamond \\
   & \ \overset{\mathclap{\smash{\sref{iso-diamond-adjoint}}}}{=} \ 
   (\zeta_{\IM f})^\diamond \after (\varphi^{-1})^\diamond \after (\pi_{\ceil{1 \after f}})^\diamond
   \after (\asrt_{1 \after f})^\diamond \\
   & \ = \ 
   (\asrt_{1 \after f} \after
   \pi_{\ceil{1 \after f}} \after
   {\varphi^{-1}} \after
   \zeta_{\IM f})^\diamond
   \\
   & \ = \ 
   (f^\dagger)^\diamond,
\end{align*}
so~$f$ is indeed~$\diamond$-adjoint to~$f^\dagger$.
\end{point}
\begin{point}{50}{Ax.~2}%
Let~$f$ be a~$\dagger$-positive map.
That is: $f = h^\dagger \after h$ for some pure map~$h$.
By~\sref{standard-form-map}
    we have~$h =
    \pi_{\IM h} \after \alpha \after \zeta_{\ceil{1 \after h}}
                    \after \asrt_{1 \after h}
                    $
                    for some iso~$\alpha$.
            We compute
\begin{align*}
    f &\ = \ h^\dagger \after h \\
    &\ = \ 
    \asrt_{1 \after h} \after \pi_{\ceil{1 \after  h}} \after \alpha^{-1} \after \zeta_{\IM h} \after
    \pi_{\IM h} \after \alpha \after \zeta_{\ceil{1 \after h}}
                    \after \asrt_{1 \after h}
                    \\
    &\ = \ 
    \asrt_{1 \after h} \after \asrt_{\ceil{1 \after  h}}
                    \after \asrt_{1 \after h}
                    \\
                    &\ \overset{\smash{\mathclap{\sref{asrt-absorp-rule}}}}{=} \ 
    \asrt_{1 \after h} \after \asrt_{1 \after h}.
\end{align*}
Form this it follows that $\dagger$-positive maps are~$\diamond$-positive.
Let~$q$ be the predicate such that~$\andthen{q}{q} = 1 \after h$.
Then
\begin{equation*}
\asrt_{q}^\dagger \after \asrt_{q}  
    \ =\  \asrt_q\after \asrt_q
    \ \overset{\sref{andthen-square-rule}}{=}\  
    \asrt_{\andthen{q}{q}}
    \  =\  \asrt_{1 \after h}.
\end{equation*}
Thus~$\asrt_{1 \after h}$ is a~$\dagger$-positive
    with~$\asrt_{1 \after h} \after \asrt_{1 \after h} = f$.
We have to show~$\asrt_{1 \after h}$
    is the unique map with this property.
Let~$g$ be any~$\dagger$-positive map with~$g \after g = f$.
Recall both~$g$ and~$f$ are~$\diamond$-positive, hence
\begin{equation*}
    \asrt_{1 \after f} \ =\  f\ =\ g \after g \ = \ \asrt_{1 \after g}
            \after \asrt_{1 \after g}
            \ \overset{\smash{\sref{andthen-square-rule}}}{=}\  
            \asrt_{\andthen{(1 \after g)}{(1 \after g)}}.
\end{equation*}
So~$\andthen{(1 \after g)}{(1\after g)} = 1\after f =
            \andthen{(1 \after h)}{(1 \after h)}$.
Hence~$1\after g = 1 \after h$ by uniqueness of the square root.
So~$g = \asrt_{1 \after g} = \asrt_{1 \after h} = h$, as desired.
\end{point}
\begin{point}{60}{Ax.~3}%
Let~$\asrt_p$ be any~$\diamond$-positive map.
Write~$q$ for the unique predicate with~$\andthen{q}{q}=p$.
Then
\begin{equation*}
    \asrt_p
     \ = \ \asrt_{\andthen{q}{q}}
            \ \overset{\smash{\sref{andthen-square-rule}}}{=}\ 
     \asrt_q \after \asrt_q  \ =\ 
     \asrt_q^\dagger \after \asrt_q ,
\end{equation*}
so~$\asrt_p$ is~$\dagger$-positive, as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}

\subsection{Dilations}
\begin{parsec}{2210}%
\begin{point}{10}%
Being the main topic of the first part of this thesis,
    we cannot finish our discussion of~$\dagger$-effectuses
    without mentioning dilations.
The presented abstract theory of dilations in a~$\dagger$-effectus
    is preliminary and as of yet rather unimpressive.
\end{point}
\begin{point}{20}[dfn-eff-dilations]{Definition}%
Let~$f\colon X \to Y$ be any map in an effectus.
    A \Define{dilation} of~$f$ \index{dilation!in an effectus}
    is a triple~$(P, \varrho, h)$
    of a sharp total map~$\varrho \colon P \to Y$
    and a pure map~$h \colon X \to P$
    such that~$\varrho \after h = f$
        and the following universal property holds.
\begin{quote}
    For every  triple~$(P', \varrho', h')$
    with~$\varrho'\colon P' \to Y$ total sharp,
    $h'\colon X \to P$ arbitrary and~$f = \varrho'\after h'$,
    there is a unique~$\sigma \colon P \to P'$
    with~$\sigma \after h = h'$
    and~$\varrho' \after \sigma = \varrho$.
\end{quote}
    We say an effectus \Define{has dilations} if \index{effectus!with dilations}
    there exists a dilation for every map.
\end{point}
\begin{point}{30}{Example}%
    The effectus $\op\vN$~(\sref{effectus-vn}) has dilations,
    as shown in \sref{existence-paschke},
    but the full subcategory~$\op\CvN$
    of commutative von Neumann algebras
    does not as shown in the next exercise.
\end{point}
\begin{point}{31}[exc-cvn-no-dilations]{Exercise}%
In this exercise you will show that~$\op\CvN$
    does not have dilations.
First, show that a corner between commutative von Neumann algebras
    is multiplicative.
Conclude that if~$\op\CvN$ were to have dilations,
    then any ncpu-map would be multiplicative, quod non.
\end{point}
\begin{point}{40}[dils-abstract-basics]{Proposition}%
Let~$C$ be an effectus with dilations.
\begin{enumerate}
\item
    If~$(P_1,\varrho_1,h_1)$
    and~$(P_2,\varrho_2,h_2)$
        are both dilations of~$f$,
    then there is a unique isomorphism~$\alpha\colon P_1 \to P_2$
        with~$\alpha \after h_1 = h_2$ and~$\varrho_2 \after \alpha = \varrho_1$.
\item
    Conversely,
    if~$(P,\varrho,h)$
        is a dilation of~$f$ and~$\alpha\colon P \to P'$ is some isomorphism,
        then~$(P', \varrho \after \alpha^{-1}, \alpha \after h)$
        is also a dilation of~$f$.

\item
    $(X, \varrho, \id)$ is the dilation
        of a sharp total map~$\varrho$.

\item
    If~$(P, \varrho, h)$ is some dilation,
        then~$(P, \id, h)$ is the dilation of~$h$.

\item
    For any quotient~$\xi \colon X \to Q$
            and map~$f\colon Q \to Y$
            with dilation~$(P, \varrho, h)$,
            the triple~$(P, \varrho, h \after \xi)$
            is a dilation of~$f \after \xi$.

\item
    Conversely, if~$(P, \varrho, h)$
            is a dilation of~$f \after \xi$
            for a map~$f\colon Q \to Y$
            and quotient~$\xi \colon X \to Q$,
        then~$(P, \varrho, h'')$ is a dilation of~$f$,
        where~$h''\colon Q \to P$ is the unique map with~$h'' \after \xi = h$.

\item
    If for~$i=1,2$ the triple~$(P_i, \varrho_i, h_i)$
            is a dilation of~$f_i \colon X_i \to Y$,
    then~$(P_1 + P_2, [\varrho_1,\varrho_2], h_1 + h_2)$
        is a dilation of~$[f_1, f_2] \colon X_1 + X_2 \to Y$.
\end{enumerate}
\spacingfix{}
\begin{point}{50}{Proof}%
Point 1 has been proven in \sref{paschke-unique-up-to-iso}.
Point 2 is easily verified.
To prove point 3, assume~$\varrho$ is a sharp total map.
Assume~$\varrho = \varrho' \after h'$ for some~$h'$ and sharp total~$\varrho'$.
Then~$h'$ is clearly the unique map
    satisfying~$h' = h' \after \id$ (and~$\varrho = \varrho' \after h'$),
    which demonstrates point 3.

For point 4, assume~$(P, \varrho, h)$ is some dilation.
Assume~$h = \varrho' \after h'$ for some~$h'$ and sharp total~$\varrho'$.
There is a unique~$\sigma$ with~$h' = \sigma \after h$
    and~$\varrho\after \varrho' \after \sigma = \varrho$.
Now~$\varrho' \after \sigma \after h = \varrho' \after h' = h$.
    So~$\varrho' \after \sigma$
        satisfies the properties of the unique mediating map~$\id\colon P \to P$,
        hence~$\varrho' \after \sigma = \id$.
Only uniqueness of~$\sigma$ remains,
    so assume~$\sigma'$ is a ncp-map with~$h'  = \sigma' \after h$
    and~$\varrho' \after \sigma' = \id$.
Then~$\varrho \after \varrho' \after \sigma' = \varrho$
    and so~$\sigma = \sigma'$.

To demonstrate point 5, assume~$\varrho' \after h' = f \after \xi$
    for some~$h'$ and total sharp~$\varrho'$.
    Then~$1 \after h' = 1 \after \varrho' \after h'
                    = 1 \after f \after \xi \leq 1 \after \xi$,
                    so there is a unique~$h''$
                    with~$h'' \after \xi = h'$.
By epicity of~$\xi$,
    we get~$\varrho'\after h'' = f$
    from~$\varrho' \after h'' \after \xi = \varrho' \after h' = f \after \xi$.
Thus there is a unique~$\sigma$
    with~$\sigma \after h = h''$ and~$\varrho' \after \sigma = \varrho$
    and so~$\sigma \after h \after \xi = h'' \after \xi = h'$.
Only uniqueness of~$\sigma$ remains,
    so suppose~$\sigma'$ is a map with~$\sigma'\after h \after \xi = h'$
            and~$\varrho' \after \sigma = \varrho$.
    Then~$\sigma' \after h = h''$ by epicity of~$\xi$,
    hence~$\sigma'=\sigma$ as desired.

For point 6, assume~$f  = \varrho' \after h'$
    for some~$h'$ and sharp total~$\varrho'$.
    Then~$f \after \xi = \varrho' \after h' \after \xi $
    and so there is a unique~$\sigma$
    with~$\varrho \after \sigma = \varrho'$
    and~$\sigma \after h' \after \xi = h \equiv h'' \after \xi$.
    Thus~$\sigma \after h' = h''$ by epicity of~$\xi$.
To show uniqueness,
    assume~$\sigma'$ is such that~$\sigma' \after h' = h''$
    and~$\varrho \after \sigma' = \varrho'$.
    Then~$\sigma' \after h' \after \xi = h'' \after xi = h$
    and indeed~$\sigma' = \sigma$.

To show point 7, assume~$[f_1,f_2] = \varrho'\after h'$
    for some~$h'$ and total sharp~$\varrho'$.
For any~$i=1,2$
    we have~$\varrho' \after h' \after \kappa_i = f_i$,
    so there is a unique~$\sigma_i$
    with~$\sigma_i \after h_i = h' \after \kappa_i$
    and~$\varrho_i = \varrho' \after \sigma_i$.
Define~$\sigma = [\sigma_1, \sigma_2]$.
Clearly~$\sigma \after (h_1 + h_2)
    = [\sigma_1 \after h_1,\sigma_2 \after h_2]
    = [ h' \after \kappa_1,  h'\after \kappa_2] = h'$
    and~$\varrho' \after \sigma
            = [\varrho' \after \sigma_1, \varrho' \after \sigma_2]
            = [\varrho_1, \varrho_2]$.
Assume~$\sigma'$ is any ncp-map with~$\sigma' \after (h_1 + h_2) = h'$
    and~$\varrho' \after \sigma' = [\varrho_1, \varrho_2]$.
For~$i=1,2$
    we have~$\varrho' \after \sigma' \after \kappa_i = \varrho_i$
    and~$h' \after \kappa_i = \sigma' \after (h_1 + h_2) \after \kappa_i
                =  \sigma' \after h_i$,
                so~$\sigma' \after \kappa_i = \sigma_i$.
    Hence~$\sigma' = [\sigma' \after \kappa_1, 
                \sigma' \after \kappa_2] = [\sigma_1,\sigma_2] = \sigma$.
                \qed
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{2220}%
\begin{point}{10}[absdilsdag]%
With some additional assumptions,
    the existence of dilations
    forces the existence of some
    familiar quantum gates.
Assume~$C$ is a~$\dagger$-effectus with dilation
    with a scalar~$\lambda$ such that~$\lambda^\perp = \lambda$.
    (For instance: $\lambda = \frac{1}{2}$ in~$\op\vN$.)
Let~$(P, \langle s,s^\perp \rangle, h)$ be a dilation
    of the map~$\left<\lambda,\lambda^\perp\right>\colon 1 \to 1+1$.
We think of~$P$ as an abstract qubit
    --- indeed in $\op\vN$ any
    dilation of~$\left<\frac{1}{2},\frac{1}{2}\right>$
    is of the form~$(M_2, \langle e,e^\perp \rangle, h)$
    where~$h$ is the vector state for some~$v \in \C^2$
    and~$e$ is a projector on~$w\C$,
    with~$\left<v,w\right> = \frac{1}{\sqrt{2}}$
    (for instance~$v = \ket{0}$ and~$w = \ket{+}$).
\begin{point}{20}%
By assumption~$\langle s,s^\perp \rangle \after h = \langle\lambda, \lambda\rangle$,
    so~$s \after h = s^\perp \after h = \lambda$.
and~$\langle s^\perp,s \rangle \after h = \langle\lambda, \lambda\rangle$.
Hence by the definition of dilation,
    there is a unique map~$X \colon P \to P$
    with~$X \after h = h$
    and~$\langle s^\perp, s\rangle\after X = \langle s, s^\perp\rangle $,
    whence~$s \after X = s^\perp \after X$
    and~$s^\perp \after X = s \after X$.
Clearly~$X \after X \after h = h$
    and~$\langle s, s^\perp \rangle  \after X \after X 
            = \langle s, s^\perp \rangle$,
    so by uniqueness of the mediating map~$\id \colon P \to P$,
    we must have~$X \after X = \id$.
Thus the isomorphism~$X$ behaves like the~$X$-gate
    --- indeed, in~$\op\vN$, we have~$X = \ad_X$
        if~$e = \ketbra{0}{0}$.
\end{point}
\begin{point}{30}%
For the next gate,
    assume~$s$ is pure and~$\IM s = 1$.
Note~$s^\dagger$ is total.
As~$\asrt_\lambda = \lambda$,
    we have~$h^\dagger \after s^\dagger = \lambda^\dagger = \lambda$
    and so~$(h^\dagger)^\perp \after s^\dagger = \lambda^\perp = \lambda$.
Combined:~$\langle h^\dagger, (h^\dagger)^\perp \rangle \after s^\dagger
            = \langle \lambda,\lambda \rangle$.
Thus using the universal property of the dilation,
    there is a unique map~$H\colon P \to P$
    with~$H \after h = s^\dagger$
    and~$\langle h^\dagger, (h^\dagger)^\perp \rangle \after H =
            \langle s, s^\perp \rangle$.
So~$h^\dagger \after H = s$.
In general, we do not know a lot more about~$H$.
Assume~$H$ is an comprehension (as it is in~$\op\vN$ in this situation).
    Then~$s^\dagger = H^\dagger \after h$ and
        $s = h^\dagger \after H^\dagger$,
        so $s^\perp = (h^\dagger)^\perp \after H^\dagger$,
        whence~$\langle s,s^\perp \rangle = \langle
                h^\dagger, (h^\dagger)^\perp \rangle \after H^\dagger$.
Thus, by uniqueness of~$H$, we must have~$H^\dagger = H$.
Thus both~$H^\dagger$ and $H$ are total,
    which forces~$H\after H^\dagger = H^\dagger \after H = \asrt_{1} = \id$,
    by uniqueness of~$\diamond$-positive maps.
Hence~$H \after H = \id$,
    $s \after H = h^\dagger$
    and~$h^\dagger \after H = s$.
    So~$H$ is similar to the Hadamard-gate
        --- indeed, in~$\op\vN$, we have~$H = \ad_H$ if~$e = \ketbra{0}{0}$.
\end{point}
\begin{point}{40}%
Do our additional assumptions (purity of~$s$, $\IM s = 1$, etc.)
follow from more general principles?  Can we define the other gates, like
    the CNOT? Do these gates interact in the usual way?
    Unfortunately, we do not have an answer to any of these questions.
\end{point}
\end{point}
\end{parsec}

\begin{parsec}{2230}%
\begin{point}{10}%
In~\sref{paschke-correspondence}
    we saw that for any ncp-map~$\varphi$
    with Paschke dilation~$(\scrP, \varrho, h)$,
       there  is a linear order
       isomorphism~$[0,1]_{\varrho(\scrA)^\square} \cong [0,\varphi]_\ncp$.
To finish the discussion of dilations,
    we mention how to state this correspondence
        in an~$\&$-effectus.
\end{point}
\begin{point}{20}[sefp]{Definition}%
In an~$\&$-effectus,
for any predicate~$p$,
    define~$\Define{\sef_p} \equiv \asrt_p \ovee \asrt_{p^\perp}$.
    \index{sefp@$\sef_p$}
This map models the side-effect of measuring~$p$.
    For any map~$f\colon X \to Y$, define
    \begin{equation*}
        \Define{\Inv f} \ \equiv \ \{p; \ p \in \Pred X;\ f \after \sef_p = f\}.
        \index{Inv@$\Inv f$}
    \end{equation*}
This is the set of predicates whose measurement does not disturb~$f$.
\end{point}
\begin{point}{30}[eff-inv-lemma]{Lemma}%
    In~$\op\vN$, for any nmiu-map~$\varrho\colon \scrA \to \scrB$,
        we have~$\Inv \varrho = [0,1]_{\varrho(\scrA)^\square}$ ---
        that is:~$\Inv \varrho$
is the set of effects of the commutant of the image of~$\varrho$.
\begin{point}{40}{Proof}%
Assume~$a \in [0,1]_{f(\scrA)^\square}$.
Simply unfolding definitions, we find~$\sef_a(\varrho(b)) = \sqrt{a} \varrho(b) \sqrt{a}
                        + \sqrt{1-a} \varrho(b) \sqrt{1-a}
                        = \varrho(b) $ for any~$b \in \scrA$, so~$a \in \Inv \varrho$.
For the converse, assume~$a \in \Inv \varrho$.
    Recall~$(\scrA, \varrho, \id)$ is a Paschke dilation of~$\varrho$.
    As
\begin{equation*}
    \varrho  \ =\ \sef_a \after \varrho
            \ = \  (\asrt_a \after \varrho)\ovee (\asrt_{1-a} \after \varrho )
            \ \geq_{\ncp} \ \asrt_{a} \after \varrho,
\end{equation*}
    we know by \sref{paschke-correspondence}
    that there is a~$t \in [0,1]_{\varrho(\scrA)^\square}$
    with~$\asrt_a(\varrho(b)) \equiv \sqrt{a} \varrho(b) \sqrt{a}
                =t  \varrho(b)$ for all~$b \in \scrA$,
        but then clearly~$a = \sqrt{a} \varrho(1) \sqrt{a} = t \varrho(1) = t$. \qed
\end{point}
\end{point}
\begin{point}{50}{Definition}%
Let~$C$ be an $\&$-effectus.
For a map~$f\colon X \to Y$,
    write
\begin{equation*}
    \Define{\downarrow\!f} \ \equiv \ 
    \{ g; \ g\colon X \to Y; \ g \leq f \}.
\end{equation*}
    We say a dilation~$(P, \varrho, h)$ of~$f$
        has \Define{the order correspondence} if
        \index{effectus!with dilations!and order correspondence}
        there is an order isomorphism~$\Theta\colon \downarrow\!f \to \Inv \varrho$
        such that for every~$g \in \downarrow\!f$,
        we have
\begin{equation*}
g \ =\  \varrho \after \asrt_{\Theta(g)} \after h.
\end{equation*}
\end{point}
\spacingfix{}
\begin{point}{60}{Example}%
By \sref{paschke-correspondence}
    every dilation in~$\op\vN$
    has the order correspondence.
\end{point}
\end{parsec}

\section{Comparisons}
\subsection{Dagger kernel categories}
\begin{parsec}{2240}%
\begin{point}{10}%
To finish this chapter, we relate the structures in a~$\dagger$-effectus
    with existing structures in the literature.
Just like we try to axiomatize~$\op\vN$,
    Heunen in the third chapter of his Ph.D-thesis attempted
    to axiomatize~$\mathsf{Hilb}$,
    the category of Hilbert spaces with bounded operators.
Heunen came very close:
    he proves that a~$\dagger$-category obeying
    certain additional axioms must embed into~$\mathsf{Hilb}$.
    \cite[3.7.18]{heunenphd}
We will discover that some of his axioms for~$\mathsf{Hilb}$
    hold in~$\Pure(C)$ for a~$\dagger$-effectus~$C$
    and others do not in general.
(We do not cover all his axioms.)
\end{point}
\begin{point}{20}{Definition}%
Let~$C$ be a~$\dagger$-category.
We say that an arrow~$f$
    is \Define{$\dagger$-mono}
    \index{*dagg@$\dagger$, dagger!-mono}
    iff~$f^\dagger \after f = \id$
    and dually~$f$ is \Define{$\dagger$-epi}
    \index{*dagg@$\dagger$, dagger!-epi}
    iff~$f\after f^\dagger = \id$.
An arrow~$f$ is a \Define{$\dagger$-partial isometry}
    \index{*dagg@$\dagger$, dagger!-partial isometry}
    if~$f = m \after e$
    for some~$\dagger$-mono~$m$
    and~$\dagger$-epi~$e$.

A~\Define{$\dagger$-kernel} of~$f$
    \index{kernel!$\dagger-$}
    \index{*dagg@$\dagger$, dagger!-kernel}
is an  equalizer of~$f$ with~$0$, which is~$\dagger$-mono.
A~\Define{$\dagger$-kernel category} is a~$\dagger$-category
    \index{*dagg@$\dagger$, dagger!-kernel!category}
    with zero object and where each arrow has a~$\dagger$-kernel
\cite[3.2.20]{heunenphd}.
\end{point}
\begin{point}{30}{Proposition}%
In~$\Pure(C)$ for some~$\dagger$-effectus~$C$,
    the following holds.
\begin{enumerate}
\item
    $f$ is $\dagger$-mono iff $f$ is a comprehension. \\
    Dually:
    $f$ is $\dagger$-epi iff $f$ is a quotient of a sharp predicate.
\item
    The $\dagger$-partial isometries are exactly the pristine maps, see \sref{dfn-pristine}.
\end{enumerate}
Furthermore: $\Pure C$ is a $\dagger$-kernel category:
    the~$\dagger$-kernel of~$f$ is given by~$\pi_{(1 \after f)^\perp}$.
\begin{point}{40}{Proof}%
Let~$f$ be any~$\dagger$-mono
pure map, say~$f \equiv \pi_s \after \alpha \after \zeta_{\ceil{p}}
        \after \asrt_p$
        for some iso~$\alpha$, $s \equiv \IM f$ and~$p \equiv 1 \after f$.
As we saw before (using \sref{asrt-absorp-rule}),
    we see~$\id = f^\dagger \after f = \asrt_{p^2}$.
Thus~$\andthen{p}{p} = p^2 =  1 = \andthen{1}{1}$
    and so by uniqueness of the square root
    we get~$p = 1$.
Hence~$f$ is a comprehension.

Dualizing, we see~$\dagger$-epis are exactly quotients of sharp predicates.
Now it is clear that the~$\dagger$-partial isometries
are exactly the pristine maps.
\begin{point}{50}%
By the previous~$\pi_{(1 \after f)^\perp}$ is~$\dagger$-mono.
To see it is the~$\dagger$-kernel of~$f$,
we have to show it is the equalizer of~$f$ with~$0$.
Clearly~$(1 \after f )^\perp \after \pi_{(1 \after f)^\perp} = 1$
and so~$1 \after f \after \pi_{(1 \after f)^\perp} = 0$,
whence~$f \after \pi_{(1 \after f)^\perp} = 0$.
Assume~$f \after g = 0$ for some pure map~$g$.
Then~$1 \after f \after g = 0$,
    so~$1 \after f \leq \IMperp g$,
    hence~$(1 \after f)^\perp \geq \IM g$,
    so~$g = \pi_{(1 \after f)^\perp} \after g'$
    for a unique~$g'$. \qed
\end{point}
\end{point}
\end{point}
\begin{point}{60}[exc-purec-no-biproduct]{Exercise*}%
Let~$C$ be a~$\dagger$-effectus.
In this exercise, you will show that
    in general $\Pure C$
    does not have finite coproducts.
In particular, $\Pure C$ does not have~$\dagger$-biproducts,
    see~\cite[3.2.15]{heunenphd}.
Consider~$C \equiv \op\vN$.
Reasoning towards contradiction,
    assume~$(\Pure \op\vN)^{\mathsf{op}}$
    has a product~$ \C \xleftarrow{\pi_1} \scrA \xrightarrow{\pi_2} \C$
    of~$\C $ and~$\C$.
First show that for any non-zero pure map~$f\colon \scrA \to \C$,
    there exists a Hilbert space~$\scrH$, an element~$x \in \scrH$,
    a von Neumann algebra~$\scrC$ and
    isomorphism~$\varphi\colon \scrB(\scrH)\oplus \scrC \to \scrA$
    with~$f (varphi(T,c)) = \langle x, T x\rangle $.
Use this on~$\pi_1$, $\pi_2$ and~$\langle\id_\C,\id_\C\rangle $
    to show there is an
    isomorphism~$\varphi\colon  \scrB(\scrH) \oplus \scrC \cong \scrA$
    with~$\pi_1 \after \varphi = \left<x,\,(\cdot\,)x\right>$
    and~$\pi_2 \after \varphi = \left<y,(\,\cdot\,)y\right>$
    for some von Neumann algebra~$\scrC$,
    Hilbert space~$\scrH$ and $x,y \in \scrH$.
Press on: show~$\scrC$ is trivial.
    Then prove~$\dim \scrH \leq 2$.
    Almost there: show~$\dim \scrH \geq 2$.
    Derive a contradiction.
\end{point}
\begin{point}{70}[exc-purec-equal]{Exercise*}%
In this exercise you will show that~$\Pure(\op\vN)$ does not have
    all coequalizers.  It is helpful to first consider
    two concrete coequalizers in~$\mathsf{Hilb}$ and~$\op\vN$.
(These coequalizers capture unordered pairs of qubits.)

Write~$\sigma\colon \C^2 \otimes \C^2 \to \C^2 \otimes \C^2$
    for the unitary
    fixed by~$\sigma \ket{ij} = \ket{ji}$.
The equalizer of~$\sigma$ with~$\id$ exists in~$\mathsf{Hilb}$
    and is given by~$e_{\mathscr{S}}$, the inclusion
    of the subspace~$\mathscr{S}$
    spanned by~$\{\ket{00}, \ket{11}, \ket{01}+\ket{10}\}$
    into~$\C^2\otimes \C^2$.
    ($\mathscr{S}$ is called the symmetric tensor of~$\C^2$ with itself.)
    The coequalizer of~$\sigma$ with~$\id$ is simply~$e_{\mathscr{S}}^\dagger$.
    There is also an equalizer of~$\ad_{\sigma}\colon M_4 \to M_4$ with~$\id$
    in~$\vN$, but curiously enough, it is given
    by~$e \colon M_3 \oplus \C \to M_4$,
    where~$e(a,\lambda) =
            \ad_{e^\dagger_{\mathscr{S}}}(a) +
            \ad_{e^\dagger_{\mathscr{A}}}(\lambda)$
     and~$\scrA$ is the subspace spanned by~$\ket{01} - \ket{10}$.
     For the proof and similar results, see \cite{bags}.

Assume~$\xi \colon \scrC \to M_4$
    is some filter (i.e.~quotient in the opposite category)
    with~$\ad_\sigma \after \xi = \xi$.
Show that for each~$b \in \scrC$,
        we have~$\xi(b) \sigma = \sigma \xi(b)$.
    From this, derive (perhaps in the same way as \cite{bags}),
    that~$\xi(b) = p_\scrA \xi(b) p_\scrA+ p_\scrS \xi(b) p_\scrS$
        for all~$b\in \scrC$,
        where~$p_\scrA = e_\scrA e_\scrA^\dagger$
        and~$p_\scrS = e_\scrS e_\scrS^\dagger$.
Prove that either~$\xi(b) \leq p_\scrA$ for all~$b\in \scrC$
    or~$\xi(b) \leq p_\scrS$ for all~$b \in \scrC$.
Conclude~$\Pure(\op\vN)$ does not have all coequalizers.
\end{point}
\begin{point}{80}%
To summarize:
    the category~$\Pure(C)$
    of a~$\dagger$-effectus~$C$
    is a~$\dagger$-category,
    has~$\dagger$-kernels
    and each~$\dagger$-mono is a~$\dagger$-kernel,
    but in general it does not have~$\dagger$-biproducts or
        $\dagger$-equalizers,
        which shows it is not, in general,
        a pre-Hilbert category as in \cite[3.7.1]{heunenphd}.
\end{point}
\begin{point}{81}%
Recently Tull axiomatized~\cite{tull}
    the $\dagger$-category~$\mathsf{Hilb}_\sim$
        of Hilbert spaces with bounded operators between
        them modulo global phase (i.e.~$T=S$ in~$\mathsf{Hilb}_\sim$
        iff~$T = \lambda S$ for some~$\lambda \in \C, |\lambda|=1$.)
Write~$\mathsf{Hilb}^c_\sim$
    for the restruction of~$\mathsf{Hilb}_\sim$
    to contractive operators.
This category~$\mathsf{Hilb}^c_{\sim}$
    is a full~$\dagger$-subcategory of~$\Pure(\op\vN)$
    via the functor
\begin{equation*}
    \scrH \ \mapsto \ \scrB(\scrH),  \quad
    \bigl(T\colon \scrH \to \scrK\bigr)
        \ \mapsto \ \bigl(\ad_T \colon \scrB(\scrK) \to \scrB(\scrH)\bigr).
\end{equation*}
The category~$\mathsf{Hilb}^c_\sim$
    (and in fact~$\mathsf{Hilb}_\sim$)
    do not have all (co)products.
Tull shows that~$\mathsf{Hilb}_\sim$ does have
    \emph{phased biproducts}. \cite{tull,tull2018quotient}
This raises the question: do the phased biproducts
    of~$\mathsf{Hilb}_\sim$ extend to~$\Pure(\op\vN)$.
If this is the case, then a
    phased product of~$\C$ with itself in~$\Pure(\op\vN)$
    is given by: $\ketbra{0}{0}, \ketbra{1}{1}\colon \C  \to M_2$.
Unfortunately this leads to a contradiction.
It hasn't been determined yet whether~$\Pure(\op\vN)$
    has phased products at all.
\end{point}
\end{parsec}

\subsection{Sequential product}
\begin{parsec}{2250}%
\begin{point}{10}%
The sequential product --- the
    operation~$\andthen{a}{b} \equiv \sqrt{a}b\sqrt{a}$
    on the effects of a von Neumann algebra
    --- has been studied before.
In \cite{gudder2001sequential,gheondea2004sequential}
    Gudder and coauthors establish some basic algebraic properties of~$\&$
    on~$\scrB(\scrH)$.
Most of them are surprisingly hard to prove ---
    for instance, the proof that~$\andthen{a}{b}=\andthen{b}{a}$
    implies~$ab = ba$, requires
    the Fuglede--Rosenblum--Putnam Theorem.
\begin{point}{20}%
Then, in \cite{gudder2008characterization},
    Gudder and Latr\'emoli\`ere (G\&L)
    characterize~$\&$ on~$\scrB(\scrH)$ as the unique operation satisfying
    (for effects~$a,b$ and density matrix~$\varrho$)
\begin{multicols}{2}
\begin{enumerate}
    \item $\TR [ (\andthen{a}{\varrho}) b] = \TR [\varrho
                    (\andthen{a}{b})]$
    \item $\andthen{a}{1} = \andthen{1}{a} = a$
    \item $ \andthen{a}{(\andthen{a}{b})} =
            \andthen{(\andthen{a}{a})}{b} =
            \andthen{a^2}{b}$
        \item $a \mapsto \andthen{a}{b}$ is strongly continuous
\end{enumerate}    
\end{multicols}
\noindent
In \sref{positive-map-uniqueness} we characterized~$\asrt_a \colon b \mapsto \andthen{a}{b}$
    as the unique~$\diamond$-positive map with~$\andthen{a}{1} = a$.
How do these characterizations compare?
G\&L's first axiom plays a very similar role
        as the~$\diamond$-self adjointness of~$\diamond$-positive maps for us.
Their third axiom is somewhat related to~$\diamond$-positivity.
Their fourth axiom seems unrelated to our characterization
    and conversely the purity of our~$\diamond$-positive maps
    has no counterpart in their axioms.
\end{point}
\begin{point}{30}%
A few years earlier, Gudder and Greechie started
    \cite{gudder2001sequential}
    the abstract study of some of the algebraic properties of the
    sequential product on arbitrary effect algebras,
    which has been picked up by several other authors
    \cite{li2011sequential,gudder2005open,shen2009not,gudder2005uniqueness,jun2009remarks,weihua2009uniqueness,tkadlec2008atomic,jia2010entropy,arias2004almost,van2018three,weteringseqprod}.
\end{point}
\end{point}
\begin{point}{40}{Definition}%
A \Define{sequential effect algebra} (SEA)
    \index{SEA}
    \index{effect algebra!sequential-}
    is an effect algebra~$E$ together
    with a binary operation~$\&$
    satisfying
\begin{enumerate}
    \item[(S1)] if~$a \perp b$,
        then~$\andthen{c}{a} \perp \andthen{c}{b}$
        and~$(\andthen{c}{a}) \ovee (\andthen{c}{b})
                = \andthen{c}{(a \ovee b)}$;
    \item[(S2)] $\andthen{1}{a} =a$;
    \item[(S3)] if~$\andthen{a}{b} = 0$,
            then~$\andthen{a}{b} = \andthen{b}{a}$;
    \item[(S4)]
        if~$\andthen{a}{b} = \andthen{b}{a}$,
        then~$\andthen{a}{b^\perp} = \andthen{b^\perp}{a}$
        and~$\andthen{(\andthen{a}{b})}{c}
            = \andthen{a}{(\andthen{b}{c})} $ \emph{and}
    \item[(S5)]
        if~$\andthen{c}{a} = \andthen{a}{c}$,
        $\andthen{c}{b} = \andthen{b}{c}$ and~$a \perp b$,\\
        then~$\andthen{c}{(\andthen{a}{b})}
                = \andthen{(\andthen{a}{b})}{c}$
                and~$\andthen{c}{(a \ovee b)} = \andthen{(a \ovee b)}{c}$.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{50}{Examples}%
The effect algebra~$[0,1]_\scrA$
    of effects on a von Neumann algebra~$\scrA$
    is a sequential effect algebra with~$\andthen{a}{b} = \sqrt{a}b\sqrt{a}$.
Any commutative effect monoid is a sequential effect algebra
    with~$\andthen{a}{b} = a \odot b$.
\end{point}
\begin{point}{60}{Proposition}%
In a~$\dagger$-effectus,
    the set of predicates~$\Pred X$ on any object~$X$
    with~$\andthen{p}{q} = q \after \asrt_p$
    satisfies axioms (S1), (S2) and (S3) of a SEA.
\begin{point}{70}{Proof}%
The proofs of (S1) and (S2) are obvious.
To show~(S3), assume~$\andthen{p}{q} = 0$
    for some predicates~$p,q$.
    Then~$1 \after \asrt_q \after \asrt_p  = \andthen{p}{q}= 0$
and so~$\asrt_q \after \asrt_p = 0 = \asrt_0$.
Applying the dagger, we find
$0 = \asrt_0^\dagger = \asrt_p^\dagger \after \asrt_q^\dagger
                = \asrt_p \after \asrt_q$.
    Thus~$\andthen{q}{p} = 0 = \andthen{p}{q}$, as desired. \qed
\end{point}
\begin{point}{80}{Remark}%
It's unclear whether the set of predicates in a~$\dagger$-effectus
    forms a sequential effect algebra.
A seemingly related open problem
    is whether~$\andthen{p}{q} = \andthen{q}{p}$
    implies that~$\asrt_p \after \asrt_q = \asrt_q \after \asrt_p$.
\end{point}
\end{point}
\end{parsec}

\subsection{Homological categories}
\begin{parsec}{2260}%
\begin{point}{10}%
Next we compare our effectuses
    to Grandis' homological categories \cite{grandis},
    which generalize abelian categories
    used in homological algebra.
First, we need a lemma.
\end{point}
\begin{point}{20}[homology-lemma]{Lemma}%
Suppose~$s,t$ are any sharp predicates on the same object in a~$\dagger$-effectus.
    If~$s^\perp \leq t$,
    then~$\andthen{s}{t}$ is sharp.
\begin{point}{30}{Proof}%
By \sref{diamond-oml},
it is sufficient to show
    $\andthen{s}{t^\perp}$ is sharp
as~$(\andthen{s}{t})^\perp = \andthen{s}{t^\perp} \ovee s^\perp$.
Note~$s^\perp \perp t^\perp$,
so by \sref{perp-sharp-is-orth},
    we find~$\andthen{t^\perp}{s^\perp} = 0$,
    hence~$\andthen{t^\perp}{s} = t^\perp$ is sharp.
By the same reasoning as in the final
    part of the proof of \sref{dagger-iso-mu},
    there exists a (unique) pristine map~$l$
    with~$\asrt_s \after \asrt_{t^\perp}
        = l\after \asrt_{\andthen{t^\perp}{s}}$,
        $l \after l^\dagger = \asrt_{\ceil{\andthen{t^\perp}{s}}}$
        and $l^\dagger \after l = \asrt_{\ceil{\andthen{s}{t^\perp}}}$.
It follows~$l \after \asrt_{\andthen{t^\perp}{s}} \after l^\dagger
    = \asrt_{\andthen{s}{t^\perp}}$ and so
\begin{align*}
    \asrt_{\andthen{s}{t^\perp}}^2
    & \ = \ l \after \asrt_{\andthen{t^\perp}{s}} \after
            l^\dagger \after l \after 
            \asrt_{\andthen{t^\perp}{s}} \after l^\dagger \\
    & \ = \ 
    l \after \asrt_{\andthen{t^\perp}{s}} \after
            \asrt_{\ceil{\andthen{s}{t^\perp}}} \after
            \asrt_{\andthen{t^\perp}{s}} \after l^\dagger \\
    & \ \overset{\mathclap{\sref{asrt-absorp-rule}}}{=} \ 
    l \after \asrt_{\andthen{t^\perp}{s}} \after
            \asrt_{\andthen{t^\perp}{s}} \after l^\dagger \\
    & \ \overset{\mathclap{\sref{sharp-prop}}}{=} \ 
    l \after \asrt_{\andthen{t^\perp}{s}} \after
            l^\dagger \\
    & \ = \ 
     \asrt_{\andthen{s}{t^\perp}},
\end{align*}
    which shows~$\andthen{s}{t^\perp}$ is sharp. \qed
\end{point}
\end{point}
\begin{point}{40}{Definition}%
A category~$C$ is a \Define{pointed semiexact category} \cite[\S1.1]{grandis}
    \index{semiexact category!pointed}
    if~$C$ has a zero object and all kernels and cokernels.
In a pointed semiexact category:
\begin{enumerate}
\item
We put a partial order on kernels in the usual way:
we write~$\Define{n \leq m}$
        \index{*leq@$\leq$!among kernels}
for kernels~$n\colon A \to X$ and~$m \colon B \to X$,
    if there is an~$f\colon A \to B$
    with~$n = m \after f$.
If both~$n \leq m$ and~$m \leq n$,
    then we write~$n \approx m$.
We denote the poset of kernels on~$A$ modulo~$\approx$
        by~$\Define{\Nsb A}$. (\textbf{N}ormal \textbf{s}ubo\textbf{b}jects,
        \index{Nsb@$\Nsb A$}
            \cite[\S1.5]{grandis}.)
\item
For every map~$f$
    there is a unique map~$g$
        with~$f = (\ker \cok f ) \after g \after (\cok \ker f)$.
    If this~$g$ is an iso, then~$f$ is called \Define{exact}.
        \index{exact}
\end{enumerate}
A pointed semiexact category~$C$
    is a \Define{pointed homological category} if
    \index{homological category!pointed}
\begin{enumerate}
    \item kernels are closed under composition;
    \item cokernels are closed under composition \emph{and}
    \item \emph{(homology axiom)}
        for any kernel~$m\colon M \to A$
        and cokernel~$q\colon A \to Q$
        with~$\ker q \leq m$,
        the composition~$q \after m$ is exact.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{50}{Theorem}%
Any~$\dagger$-effectus (in partial form) is a (pointed) homological category:
\begin{enumerate}
    \item 
        a map is a kernel iff it is a comprehension;
    \item
        a map is a cokernel iff it is a quotient of a sharp predicate \emph{and}
    \item
        a map is exact iff it is pristine.
\end{enumerate}
\spacingfix{}
\begin{point}{60}{Proof}%
Let~$C$ be a~$\dagger$-effectus.
By~\sref{effectus-kernels} and \sref{effectus-cokernels},
    we know~$C$ has all kernels and cokernels:
    a kernel of~$f$ is exactly a comprehension of~$(1 \after f)^\perp$
    and a cokernel of~$f$ is exactly a quotient of~$\IM f$.
By~\sref{upm-closed},
    comprehensions are closed under composition,
    and so kernels are closed under composition as well.
As for the cokernels,
    assume~$\zeta_1, \zeta_2$ are two composable cokernels.
Both~$\zeta_1$ and~$\zeta_2$ are quotients of a sharp predicate.
By \sref{quotients-composition} the composition  $\zeta_1 \after \zeta_2$
    is a quotient as well.
The map~$\zeta_2$ is sharp by \sref{quotients-composition}
    and so the predicate~$1 \after \zeta_1 \after \zeta_2$ is sharp.
Hence~$\zeta_1 \after \zeta_2$ is a cokernel too.
Unfolding definitions, it is easy to see exact maps correspond precisely
    to pristine maps.
\begin{point}{70}{Homology axiom}%
We have to show~$q \after m$
    is exact for any cokernel~$q$ and kernel~$m$ with~$\ker q \leq m$.
As~$q \after m$ is pure,
    it is sufficient to show~$1 \after q \after m$ is sharp.
By \sref{compr-is-full},
the assumption~$\ker q \leq m$
    is equivalent to~$(1 \after q)^\perp \equiv \IM \ker q \leq \IM m$
    and so~$\IMperp m \leq 1 \after q$.
Our lemma \sref{homology-lemma}
    shows~$\andthen{(\IM m)}{(1 \after q)}
    \equiv 1 \after q \after m \after m^\dagger$ is sharp
    and so
\begin{align*}
    \ceil{1 \after q \after m}
    &\ = \ \ceil{1 \after q \after m} \after m^\dagger \after m 
        &\quad&\text{as comprehensions are~$\dagger$-mono}\\
    &\ = \ \ceil{1 \after q \after m \after m^\dagger} \after m 
        &&\text{as $m^\dagger$ is sharp} \\
    &\ = \ 1 \after q  \after  m \after m^\dagger \after m  \\
    &\ = \ 1 \after q  \after  m,
\end{align*}
which show~$q \after m$ is sharp, as desired. \qed
\end{point}
\end{point}
\end{point}
\end{parsec}
\begin{parsec}{2270}%
\begin{point}{10}%
In any homological category, a generalization
    of the famous \emph{Snake Lemma} holds.
Before we can discuss it, we need some more homological category theory.
\end{point}
\begin{point}{20}{Definition}%
Let a (pointed) semiexact category be given.
\begin{enumerate}
\item
    We say the diagram~$A \xrightarrow{f} B \xrightarrow{g} C$
        is \Define{exact at} $B$,
        \index{exact!at}
        if~$\ker \cok (f) \approx \ker (g)$.
We say~$A_1 \xrightarrow{f_1} A_2 \to \cdots
            \to A_{n}$
            is a \Define{(long) exact sequence}
            \index{exact!sequence}
            if it is exact at~$A_2, \ldots, A_{n-1}$.
\item
The poset~$\Nsb A$ of kernels modulo~$\approx$
        is a bounded lattice with minimum~$0$ and maximum~$1\equiv \id$.
        \cite[\S1.5]{grandis}
\item
For any~$f\colon A \to B$,
    define~$f_*\colon \Nsb A \leftrightarrows \Nsb B \colon f^*$
        by~$\Define{f_*} (k) = \ker \cok (f \after k)$
        and~$\Define{f^*}(k) = \ker ((\cok k) \after f)$.
        \index{*par3@$(\ )_*$, $(\ )^*$}
\item
We say~$f$ is \Define{left-modular at} $k$
        \index{modular}
    if~$f^* (f_* (k)) = k \vee f^*(0)$
        and $f$ is \Define{right-modular at} $k$
        if~$f_*(f^* (k)) = k \wedge f_*(1)$.
We call~$f$ simply \Define{left-modular} (resp.~right-modular)
    if it is left-modular (resp.~left-modular) at every~$k$.
We say~$f$ is \Define{modular}
    if it is both left- and right-modular.
\end{enumerate}
\end{point}
\spacingfix{}
\begin{point}{30}{Example}%
In a~$\dagger$-effectus, the previous concepts are related
to our familiar notions as follows.
\begin{enumerate}
\item
    A diagram~$A \xrightarrow{f} B \xrightarrow{g} C$
        is exact at $B$
        if and only if~$\IMperp f = \ceil{1 \after f}$.
\item
    The lattice~$\Nsb A$ is isomorphic to the lattice~$\SPred A$
        via~$k \mapsto \IM k$.
\item
    For any~$f$, we
        have~$\IM f_*(k) = f_\diamond (\IM k)$
        and~$\IM f^*(k) = f^\BOX (\IM k)$.
\item
    A map~$f$ is left-modular at~$k$
            iff~$f^\BOX (f_\diamond ( \IM k)) = 
                (\IM k) \vee \ceil{1 \after f}$
        and right-modular at~$k$
            iff~$f_\diamond (f^\BOX ( \IM k)) = 
                (\IM k) \wedge \IM f$.
\end{enumerate}
\spacingfix{}
\begin{point}{40}{Notation}%
As~$\Nsb A$ and~$\SPred A$ are isomorphic,
    we will abbreviate~``$f$ is left-modular at~$\pi_s$''
    by~``$f$ is left-modular at~$s$''
    and similarly for right-modularity.
\end{point}
\end{point}
\begin{point}{50}[diamondboxlemma]{Lemma}%
In a~$\dagger$-effectus,
    we have~$\pi^\BOX \after \pi_\diamond = \id$
    and~$\zeta_\diamond \after \zeta^\BOX = \id$
    for any comprehension~$\pi$
    and sharp quotient~$\zeta$.
\begin{point}{60}{Proof}%
We start with~$\pi$.  The trick is to use~$\pi^\dagger$ is sharp:
    $\pi^\BOX \after \pi_\diamond (s) =
    \pi^\BOX \after (\pi^\dagger)^\diamond (s) =
    \lceil \lceil s \after \pi^\dagger \rceil^\perp \after \pi\rceil^\perp =
    \lceil(s \after \pi^\dagger)^\perp \after \pi\rceil^\perp =
    \lceil(s \after \pi^\dagger \after \pi)^\perp\rceil^\perp =
    \lceil s ^\perp\rceil^\perp = s $.
As for the other equality:
    $\zeta_\diamond \after \zeta^\BOX (s)
        = (\zeta^\dagger)^\diamond \after \zeta^\BOX (s)
        = \lceil\lceil s^\perp \after  \zeta \rceil^\perp \after \zeta^\dagger\rceil
        = \lceil(\lceil s^\perp \after  \zeta \rceil \after \zeta^\dagger)^\perp\rceil
        = \lceil(\lceil s^\perp\rceil \after \zeta \after \zeta^\dagger)^\perp\rceil
        = \lceil \lceil s^\perp\rceil^\perp \rceil = s $. \qed
\end{point}
\end{point}
\end{parsec}
\begin{parsec}{2280}%
\begin{point}{10}%
The following is a translation of (a part of) Grandis' Snake
    Lemma~\cite[\S3.4]{grandis}
    into~$\dagger$-effectus jargon.
We include a proof as it highlights how
    the reasoning in a homological category is subtly different
    from the reasoning we already saw in a~$\dagger$-effectus:
    maps~$l^\BOX$ appear, where we would have expected~$l^\diamond$.
\end{point}
\begin{point}{20}{Snake Lemma}%
Suppose we have a commuting
    diagram in~$\dagger$-effectus as follows.
\begin{equation*}
    \xymatrix{
        &A \ar[d]^{a} \ar[r]^f
    &B \ar[d]^{b} \ar[r]^g
    &C \ar[d]^{c} \ar[r]^0
    &0
    \\0 \ar[r]^{0}
    &A' \ar[r]^{h}
    &B' \ar[r]^{k}
    &C'
}
\end{equation*}
Furthermore, assume
\begin{enumerate}
    \item the diagram has exact rows;
    \item  $b$ is left-modular over~$\IM f$;
    \item $b$ is right-modular over~$\IM h$;
    \item $f$ is right-modular over~$\ceil{1 \after b}^\perp$ \emph{and}
    \item $k$ is left-modular over~$\IM b$.
\end{enumerate}
These additional assumptions are equivalent to the following conditions.
    \begin{multicols}{2}
    \begin{enumerate}
    \item
        $b^\BOX \after b_\diamond (\IM f) = \ceil{1 \after b}^\perp \vee \IM f$,
    \item
        $b_\diamond \after b^\BOX (\IM h)
                = (\IM h) \wedge \IM b$,
    \item
        $k^\BOX \after k_\diamond (\IM b) = (\IM h) \vee \IM b$,
    \item
        %$f_\diamond \after f^\BOX (\ceil{1 \after b}^\perp)
        $f_\diamond \after f^\BOX \after b^\BOX(0)
                = \ceil{1 \after b}^\perp \wedge \IM f$,
    \item
        $\IMperp f = \ceil{1\after g}$,
    \item
        $\IMperp h = \ceil{1\after k}$,
    \item
        $g$ is a sharp quotient \emph{and}
    \item
        $h$ is a comprehension.
    \end{enumerate}
\end{multicols}\noindent
\emph{Completing the diagram},
write~$a_\pi, b_\pi, c_\pi$ for kernels of~$a$, $b$ and~$c$, respectively;
$a_\zeta$, $b_\zeta$, $c_\zeta$ for the cokernels
    \emph{and}~$\overline{f},\overline{g},\overline{h}, \overline{k}$
    for the induced maps between the kernels and cokernels.
It is easy to see
\begin{align*}
   \overline{f} &= b_\pi^\dagger \after f \after a_\pi
     &   \overline{g} &= c_\pi^\dagger \after g \after b_\pi
     &   \overline{h} &= b_\zeta \after h \after a_\zeta^\dagger
     &   \overline{k} &= c_\zeta \after k \after b_\zeta^\dagger.
\end{align*}
Then: there is a map~$d \colon \ker c \to \cok a$
        that turns\footnote{%
            Beware: we use~$\ker a$ (and~$\cok$) inconsistently ---
         earlier in the text~$\ker f$ refers
            to a kernel map --- here it
            refers to a kernel object instead.}
\begin{equation}\label{thesnake}
    \xymatrix{
        \ker a \ar[r]^{\overline{f}}
        &\ker b \ar[r]^{\overline{g}}
        &\ker c \ar[r]^{d}
        &\cok a \ar[r]^{\overline{h}}
        &\cok b \ar[r]^{\overline{k}}
        &\cok c 
    }
\end{equation}
into a (long) exact sequence. This reveals the snake:
\begin{equation*}
\begin{tikzpicture}[
        every edge/.append style={font=\scriptsize}
        ]
    \matrix[matrix of math nodes,
            column sep={45pt,between origins},
            row sep={45pt,between origins},
            nodes={asymmetrical rectangle}] (s) {
        & |[name=ka]| \ker a
        & |[name=kb]| \ker b
        & |[name=kc]| \ker c \\
        & |[name=A]| A
        & |[name=B]| B
        & |[name=C]| C 
        & |[name=01]| 0\\
         |[name=02]| 0
        & |[name=A']| A'
        & |[name=B']| B'
        & |[name=C']| C' \\
        & |[name=ca]| \cok a
        & |[name=cb]| \cok b
        & |[name=cc]| \cok c \\
    };
\draw[->]
    (ka) edge node[auto] {$a_\pi$} (A)
    (kb) edge node[auto] {$b_\pi$} (B)
    (kc) edge node[auto] {$c_\pi$} (C)
    (A') edge node[auto] {$a_\zeta$} (ca)
    (B') edge node[auto] {$b_\zeta$} (cb)
    (C') edge node[auto] {$c_\zeta$} (cc)
    (C) edge node[auto] {$0$} (01)
    (02) edge node[auto] {$0$} (A')
    (A) edge node[auto] {$f$} (B)
    (B) edge node[auto] {$g$} (C)
    (A') edge node[auto] {$h$} (B')
    (B') edge node[auto] {$k$} (C')
    (A) edge node[auto] {$a$} (A')
    (B) edge node[auto] {$b$} (B')
    (C) edge node[auto] {$c$} (C')
;
\draw[->,darkgreen] 
    (ka) edge node[auto,text=black] {$\overline{f}$} (kb)
    (kb) edge node[auto,text=black] {$\overline{g}$} (kc)
    (ca) edge node[auto,below,text=black] {$\overline{h}$} (cb)
    (cb) edge node[auto,below,text=black] {$\overline{k}$} (cc)
;
\draw[->,darkgreen,rounded corners]
    (kc) 
        -| node[auto,text=black,pos=.7,font=\scriptsize]{$d$}
            ($(01.east)+(.5,0)$)
        |- ($(B)!.35!(B')$)
        -| ($(02.west)+(-.5,0)$)
        |- (ca);
;
\end{tikzpicture}
\end{equation*}
\spacingfix{}
\begin{point}{30}{Proof}%
Before we start, we give an overview of the proof.
We will first show
    there are comprehensions~$m,h'$
        and sharp quotients~$g',v$
        such that the left and right faces of the following cube commute.
\begin{equation*}
\xymatrix{
    & B \ar[rr]^b \ar@{->>}[dd]^g
    && B' \ar@{->>}[dd]^v
    \\ Z \ar@{^{(}->}[ru]^m \ar@{->>}[dd]_{g'}
    && A' \ar@{^{(}->}[ru]^h \ar@{->>}[dd]_{a_\zeta}
\\& C
&& Q
    \\ \ker c \ar@{^{(}->}[ru]_{c_\pi} \ar[rr]_{d}
    && \cok a \ar@{^{(}->}[ru]_{h'}
}
\end{equation*}
(These two faces are, what Grandis calls, subquotients.)
Then we will prove using exactness of the rows
    that there is a unique lifting of~$b$
    to~$b'\colon Z \to A'$ along the comprehensions~$m,h$.
In turn, $d$ is defined as the unique lifting of~$b'$
    along the sharp quotients~$h', a_\zeta$.
($d$ is the map regularly induced by~$b$ along the two subquotients.)
Before demonstrating the exactness of the snake,
    we need some non-trivial identities for~$d_\diamond$ and~$d^\BOX$.
(These also follow from Grandis' calculus of direct and inverse images
    along an induced morphism.)
\begin{point}{40}%
Define~$v \equiv \xi_{h_\diamond(\IM a)}$. 
As~$(v \after h)^\diamond(1) = h^\diamond ( h_\diamond(\IM a)) = \IM a
        = 1\after a_\zeta$,
        there must be a total pure map~$h'$
        such that~$v \after h = h' \after a_\zeta$.
Note~$\ceil{1 \after v}^\perp = h_\diamond(\IM a) \leq h_\diamond(1) = \IM h$.
So by the homology axiom, we know~$v \after h$ is pristine
    and so~$h'$ must be a comprehension.
Moving to the other side,
    define~$m \equiv \pi_{g^\BOX(\ceil{1\after c}^\perp)}$.
Reasoning in a similar way,
    we see there is a unique sharp quotient~$g'$
    with~$g \after m = c_\pi \after g'$.
\end{point}
\begin{point}{50}%
To show~$b$ lifts along~$m$ and~$h$,
    it suffices (by the universal property of comprehensions)
    to show~$(b \after m)_\diamond(1)
        \equiv \IM b\after m \leq \IM h
                    \equiv h_\diamond(1)$.
\begin{alignat*}{2}
    (b_\diamond \after m_\diamond) (1)
    &\ =\  (b_\diamond \after g^\BOX \after c^\BOX )(0) &\qquad& \text{by dfn.~$m$}\\
    &\ = \ (b_\diamond \after b^\BOX \after k^\BOX )(0) \\
    &\ = \ (b_\diamond \after b^\BOX \after h_\diamond )(1) && \text{by exactness at~$B'$} \\
    &\ \leq \  h_\diamond (1) && \text{as $b_\diamond \dashv b^\BOX$}.
\end{alignat*}
So there is a unique~$b'\colon Z \to A'$ with~$h \after b' = b \after m$.
Before we continue,
    we note~$b' = h^\dagger \after b \after m$
    (as ~$h^\dagger \after h= \id$)
    and so surprisingly:
\begin{equation}\label{snakeceilbprime}
    m^\BOX \after b^\BOX \after h_\BOX \ = \ 
    b'^\BOX \ \overset{\mathclap{\sref{diamondboxlemma}}}{=} \   b'^\BOX \after h^\BOX \after h_\diamond
            \ =\    m^\BOX \after b^\BOX \after h_\diamond.
\end{equation}
Next, to show~$b'$ lifts along~$g'$ and~$a_\zeta$,
    it is sufficient to prove~$(b'^\BOX \after a_\zeta^\BOX)(0)
        = \ceil{1\after b' \after a_\zeta}^\perp
                \geq \ceil{1 \after g'}^\perp
                = g'^\BOX (0)$.
\begin{alignat*}{2}
    (b'^\BOX \after a_\zeta^\BOX)(0)
        & \ = \ (b'^\BOX \after a_\diamond)(1)
                &\qquad& \text{by dfn.~$a_\zeta$} \\
        & \ = \ (m^\BOX \after b^\BOX \after h_\diamond \after a_\diamond)(1)
                && \text{by \eqref{snakeceilbprime}} \\
        & \ = \ (m^\BOX \after b^\BOX \after b_\diamond \after f_\diamond)(1) \\
        & \ \geq \ (m^\BOX \after f_\diamond )(1) 
                && \text{as $b_\diamond \dashv b^\BOX$}\\
        & \ =\ (m^\BOX \after g_\BOX )(0) 
                && \text{by exactness at $B$}\\
        & \ = \ (g'^\BOX \after (c_\pi)_\BOX )(0) 
                && \text{by dfn.~$g'$}\\
        & \ \geq \ g'^\BOX (0).
\end{alignat*}
Thus there is a unique~$d\colon \ker c \to \cok a$
    with~$d \after g' = a_\zeta \after b'$.
More concretely, using~$g' \after g'^\dagger = \id$,
    we see
    $ d  =  a_\zeta \after h^\dagger \after b \after m \after 
                g'^\dagger$.
\end{point}
\begin{point}{60}%
Our next goal is to show
\begin{align*}
    d_\diamond &\ =\ 
            (a_\zeta)_\diamond \after h^\BOX \after
                b_\diamond \after m_\diamond \after g'^\BOX
            \ = \ h'^\BOX \after v_\diamond \after
                b_\diamond \after m_\diamond \after g'^\BOX 
                \numberthis\label{snakedidents}
                \\
            &\ = \ (a_\zeta)_\diamond \after h^\BOX \after
                b_\diamond\after g^\BOX \after (c_\pi)_\diamond
            \ = \ h'^\BOX \after v_\diamond \after
                b_\diamond\after g^\BOX \after (c_\pi)_\diamond.
\end{align*}
As a first step,
    note~$\IM m = (g^\BOX \after c_\diamond )(1) \geq
        (g^\BOX\after (c_\pi)_\diamond)(s)$
    and so
\begin{alignat*}{2}
    (g^\BOX\after (c_\pi)_\diamond)(s)
       & \ =\ 
    (g^\BOX\after (c_\pi)_\diamond(s)) \wedge  (\IM m) \\
    &\ = \ (m_\diamond \after m^\BOX \after 
    g^\BOX\after (c_\pi)_\diamond)(s)
    &\qquad&\text{by \sref{spred-infimum}} \\
    &\ = \ (m_\diamond \after g'^\BOX \after
    c_\pi^\BOX\after (c_\pi)_\diamond)(s) &&\text{by dfn.~$g'$}\\
    &\ = \ (m_\diamond \after g'^\BOX)(s)
    &&\text{by \sref{diamondboxlemma}}.
\end{alignat*}
and so we only have to show the first two equalities of \eqref{snakedidents}.
The first is easy:
\begin{alignat*}{2}
    d_\diamond
    &\ = \ d_\diamond \after g'_\diamond \after g'^\BOX 
    &\qquad&\text{by \sref{diamondboxlemma}}\\
    & \ = \ (a_\zeta)_\diamond \after b'_\diamond \after g'^\BOX 
                &&\text{by dfn.~$d$}\\
    & \ = \ (a_\zeta)_\diamond \after
                    h^\BOX \after h_\diamond \after 
    b'_\diamond \after g'^\BOX
    &&\text{by \sref{diamondboxlemma}}\\
    &\ = \ (a_\zeta)_\diamond \after
                    h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX &&\text{by dfn.~$b'$}.
\end{alignat*}
The second is trickier.  We need some preparation.
    Recall~$v^\BOX(0) \leq h_\diamond(1)$
    and so
\begin{equation}\label{snakehdiamondone}
    h_\diamond(1) \ = \ 
    v^\BOX(0)  \vee h_\diamond(1) \ \overset{\mathclap{\sref{spred-sup}}}{=} \ 
    (v^\BOX \after v_\diamond \after h_\diamond)(1) \ = \ 
    (v^\BOX \after h'_\diamond)(1).
\end{equation}
As~$h_\diamond \after a^\BOX_\zeta$ is injective,
    the last equality follows from
\begin{alignat*}{2}
    &(h_\diamond \after a_\zeta^\BOX \after (a_\zeta)_\diamond \after
                    h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX )(s)\\
    &\qquad \ =\ 
    (h_\diamond ( h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX  )(s) \vee a_\zeta^\BOX(0)) 
        &\qquad&\text{by \sref{spred-sup}}\\
    &\qquad \ =\ 
    (h_\diamond \after  h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX )(s) \vee (h_\diamond \after a_\zeta^\BOX)(0)
        &\qquad&\text{as~$h_\diamond \dashv h^\BOX$}\\
    &\qquad \ =\ 
    (h_\diamond \after  h^\BOX \after b_\diamond \after
    m_\diamond \after g'^\BOX )(s) \vee v^\BOX(0)
        &\qquad&\text{by dfns.~$v$,$a_\zeta$}\\
    &\qquad \ =\ 
    (\,( b_\diamond \after
    m_\diamond \after g'^\BOX ) (s) \wedge h_\diamond(1)\,) \vee v^\BOX(0)
        &\qquad&\text{by \sref{spred-infimum}}\\
    &\qquad \ =\ 
    (b_\diamond \after
    m_\diamond \after g'^\BOX  )(s)  \vee v^\BOX(0)
        &\qquad&\text{as $b_\diamond \after m_\diamond (1) \leq h_\diamond(1)$}\\
    &\qquad \ =\ 
    (\, (b_\diamond \after
    m_\diamond \after g'^\BOX ) (s)  \vee v^\BOX(0)\,
    ) \wedge h_\diamond(1)
        &\qquad&\text{as $v^\BOX(0) \leq h_\diamond(1)$}\\
    &\qquad \ =\ 
    (v^\BOX \after v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  )(s)  \wedge h_\diamond(1)
        &\qquad&\text{by \sref{spred-sup}} \\
    &\qquad \ =\ 
    v^\BOX \after v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  (s)  \wedge v^\BOX \after h'_\diamond(1)
        &\qquad&\text{by \eqref{snakehdiamondone} } \\
    &\qquad \ =\ 
    v^\BOX (\,(v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX ) (s)  \wedge  h'_\diamond(1)\,)
        &\qquad&\text{as~$v^\BOX \vdash v_\diamond$} \\
    &\qquad \ =\ 
    (v^\BOX \after h'_\diamond
    \after h'^\BOX \after  v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX  )(s)
        &\qquad&\text{by \sref{spred-infimum}}\\
    &\qquad \ =\ 
    (h_\diamond \after a_\zeta^\BOX \after
    h'^\BOX \after  v_\diamond \after  b_\diamond \after
    m_\diamond \after g'^\BOX )(s),
\end{alignat*}
where~$
    h_\diamond \after a_\zeta^\BOX \after =
    v^\BOX \after h'_\diamond$
    is proven in the same way as $g^\BOX \after (c_\pi)_\diamond =
                                    m_\diamond \after g'^\BOX$.
\end{point}
\begin{point}{70}%
We are ready to show exactness of \eqref{thesnake}.
We will first derive exactness in~$\cok a$
    from the right-modularity of~$b$ over~$\IM h$.
\begin{alignat*}{2}%
    d_\diamond(1) &
    \ = \  ((a_\zeta)_\diamond \after h^\BOX \after b_\diamond
            \after g^\BOX \after (c_\pi)_\diamond)(1)
            &\qquad&\text{by \eqref{snakedidents}} \\
    & \ = \ ((a_\zeta)_\diamond \after h^\BOX \after 
                b_\diamond \after g^\BOX \after c^\BOX)(0) 
                &&\text{by dfn.~$c_\pi$}\\
    & \ = \ ((a_\zeta)_\diamond \after h^\BOX \after 
    b_\diamond \after b^\BOX \after k^\BOX)(0) \\
    & \ = \ ((a_\zeta)_\diamond \after h^\BOX \after 
    b_\diamond \after b^\BOX \after h_\diamond)(1) 
    &\qquad&\text{by exactness in~$B'$}\\
    & \ = \ ((a_\zeta)_\diamond \after h^\BOX) (
    b_\diamond(1) \wedge h_\diamond(1))
        &&\text{by right-modularity}\\
    & \ = \ ((a_\zeta)_\diamond \after h^\BOX \after 
    h_\diamond \after h^\BOX \after b_\diamond)(1)
    &&\text{by \sref{spred-infimum}} \\
    & \ = \ ((a_\zeta)_\diamond \after h^\BOX
    \after b_\diamond)(1)
    &&\text{as $h^\BOX \vdash h_\diamond$}\\
    & \ = \ ((a_\zeta)_\diamond \after h^\BOX
    \after b_\zeta^\BOX)(0)
    &&\text{by dfn.~$b_\zeta$} \\
    & \ = \ ((a_\zeta)_\diamond \after a_\zeta^\BOX
    \after \smash{\overline{h}^\BOX} )(0)
    &&\text{by dfn.~$\overline{h}$}\\
    & \ = \ \smash{\overline{h}^\BOX} (0)
    &&\text{by \sref{diamondboxlemma}.}
\end{alignat*}
    By a dual argument
    one derives exactness of~$\eqref{thesnake}$
        in~$\ker c$ from the left-modularity
        of~$b$ over~$\IM f$.
\end{point}
\begin{point}{80}%
    To show exactness of
    $\eqref{thesnake}$ in~$\cok b$,
    we will use left-modularity of~$k$ in~$\IM b$:
\begin{alignat*}{2}
    \overline{h}_\diamond(1) 
        & \ = \ (\overline{h}_\diamond \after (a_\zeta)_\diamond
                \after a_\zeta^\BOX)(1)
                &\qquad&\text{by \sref{diamondboxlemma}} \\
        & \ = \ (\overline{h}_\diamond \after (a_\zeta)_\diamond)(1)
                &&\text{as $a_\zeta^\BOX \dashv (a_\zeta)_\diamond$}\\
        & \ = \ ((b_\zeta)_\diamond \after h_\diamond)(1)
                &&\text{by dfn.~$\overline{h}$}\\
        & \ = \ ((b_\zeta)_\diamond \after
                b^\BOX_\zeta \after (b_\zeta)_\diamond \after
        h_\diamond)(1)
                &&\text{as~$(b_\zeta)_\diamond \dashv b^\BOX_\zeta$}\\
        & \ = \ (b_\zeta)_\diamond (
                    h_\diamond(1) \vee b_\zeta^\BOX(0))
                &&\text{by \sref{spred-sup}}\\
        & \ = \ (b_\zeta)_\diamond (
                    h_\diamond(1) \vee b_\diamond(1))
                &&\text{by dfn.~$b_\zeta$}\\
        & \ = \ (b_\zeta)_\diamond (
                    k^\BOX(0) \vee b_\diamond(1))
                &&\text{exactness in~$B'$}\\
        & \ = \ ((b_\zeta)_\diamond \after
                    k^\BOX \after k_\diamond \after b_\diamond)(1)
                &&\text{by left-modularity}\\
        & \ = \ ((b_\zeta)_\diamond \after
                    k^\BOX \after c_\diamond \after g_\diamond)(1) \\
        & \ = \ ((b_\zeta)_\diamond \after
                    k^\BOX \after c_\diamond )(1) 
                    && \text{as quotients are faithful}\\
        & \ = \ ((b_\zeta)_\diamond \after
                    k^\BOX \after c_\zeta^\BOX)  (0) 
                    && \text{by dfn.~$c_\zeta$}\\
        & \ = \ ((b_\zeta)_\diamond \after
                    b_\zeta^\BOX \after \smash{\overline{k}^\BOX} ) (0) 
                    && \text{by dfn.~$\overline{k}$}\\
        & \ = \ \smash{\overline{k}^\BOX}  (0) 
                    && \text{by \sref{diamondboxlemma}}.
\end{alignat*}
    Finally, the exactness of~\eqref{thesnake}
        in~$\ker b$ is shown with a dual argument
        using the right-modularity of~$f$ over~$\ceil{1\after b}^\perp$. \qed
\end{point}
\end{point}
\begin{point}{90}{Remark}%
As~$\op\vN$ is a~$\dagger$-effectus,
    Grandis' Snake Lemma also holds for von Neumann algebras.
This is somewhat puzzling for the following reason.
To study spaces,
    one associates in algebraic geometry
    to each space
    an object
    (or even a diagram of objects) of
    an abelian category representing some algebraic invariant.
The key point is that it is easier to compute and understand
    these algebraic invariants than it is to work with the spaces
    themselves.
One normally thinks of a category of spaces as being quite different
    from a category of algebraic invariants, hence it's surprising
    that~$\op\vN$, which is a rather complicated
    category of (non-commutative) spaces,
    behaves in this way, similar to an abelian category.
\end{point}
\end{point}
\end{parsec}

% vim: ft=tex.latex
