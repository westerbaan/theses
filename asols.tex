% vim:  indentexpr=
\documentclass[b5page]{book}
\input{common}
\externaldocument{a}
\externaldocument{b}

\newcommand{\TODO}[1]{\textcolor{darkred}{\textsc{\underline{todo}}}}

\begin{document}
\appendix
\chapter{Solutions, Addenda, Errata}
\begin{erratum}{parsec-40.160}%
    It should be assumed that $T$ is bounded.
\end{erratum}
\begin{erratum}{parsec-50.60}%
Don't follow the hints.
\end{erratum}
\begin{erratum}{parsec-60.30}%
    ``$\|x_\infty-x\|\leq \varepsilon$'' should read  ``$\|x_\infty-x_n\|\leq\varepsilon$''.
\end{erratum}
\begin{erratum}{parsec-110.60}
``$\|a\| < \|b\|$'' in point~2
    should read ``$\|a\|<  \|b^{-1}\|^{-1}$''.
\end{erratum}
\begin{erratum}{parsec-110.150}
In the hint for point 3,
``$a^n+1 = \prod_{k=1}^n a+\zeta^{2k+1}$''
should read
``$a^n+1 = \prod_{k=1}^n a-\zeta^{2k+1}$''.
\end{erratum}
\begin{erratum}{parsec-120.30}
``$(f\cdot g)'=f'\cdot g + g'\cdot f$'' should
    read ``$(f\cdot g)' = f'\cdot g + f\cdot g'$''.
\end{erratum}
\begin{erratum}{parsec-200.30}
Where  ``$\|f(a)\|\leq f(1)\,\|a\|\leq\|f(1)\|\,\|a\|$
    by \sref{parsec-170.60}''
is written
one should read
``$\|f(a)\|\leq\|f(1)\|\,\|a\|$ by \sref{parsec-170.60}''.
\end{erratum}
\begin{erratum}{parsec-220.60}
In the definition of~$J$,
one should read ``$q(\Real{b})$''
and~``$q(\Imag{b})$''
instead of~``$\Real{b}$''
and~``$\Imag{b}$'', respectively.
\end{erratum}
\begin{erratum}{parsec-230.50}
It should be assumed that $a$ and~$b$ are
positive in point~3.
\end{erratum}
\begin{addendum}{parsec-240.20}
Another property worth proving is:
\begin{enumerate}
\setcounter{enumi}{3}
\item
$\|a\|=\|a_+\|\vee \|a_-\|$.
\end{enumerate}
\end{addendum}
\begin{erratum}{parsec-270.120}
It's erroneously assumed that~$\left|a\right|\in J$.

Here's a corrected proof:
We'll show first that for~$a,b\in\scrA_+$
with~$ab=0$ either $a\in I$ or~$b\in I$.
To this end, consider
the Riesz ideal~$I+(a)_m$,
where~$(a)_m$ is the Riesz ideal generated by~$a$
from~\sref{parsec-270.100}(1).
Since~$I$ is maximal, either~$I+(a)_m=I$
or
$I+(a)_m=\scrA$.
In the former case, $a\in I$, 
and so we'd be done.
So we assume that~$I+(a)_m=\scrA$.
In particular, $1 \in (I+(a)_m)$,
and so~$1=x+a'$ for some~$x\in I$ and~$a'\in (a)_m$.
Upon taking the real part
we see that we may assume~$x$ and~$a'$ to be self-adjoint.
By definition of~$(a)_m$ there's $n\in \N$ with 
$\left|a'\right|\leq na$.
Then, $1=\left|1\right|=\left|x+a'\right|
\leq \left|x\right| + \left|a'\right|
\leq \left|x\right| + na$.
By a similar reasoning for~$b$,
we can find $y\in I\cap\Real{\scrA}$
and~$m\in\N$ with $1\leq\left|y\right|+mb$.
Then,
using~\sref{parsec-230.70}(2),
\begin{alignat*}{3}
1 \ \leq\ (\left|x\right| + na)(\left|y\right|+mb)
\ &= \ \left|x\right|\left|y\right| \,+\,
na\left|y\right|\,+\, mb\left|x\right|\,+\,nmab\\
\ &= \ \left|x\right|\left|y\right| \,+\,
na\left|y\right|\,+\, mb\left|x\right|
\ \in\ I\quad \text{by \sref{parsec-270.80}.}
\end{alignat*}
But then~$1\in I$, which is absurd.
Thus either~$I+(a)_m=I$ and thus~$a\in I$,
or~$I+(b)_m = I$ and thus~$b\in I$.

To see that~$I$ is a maximal order ideal,
let~$J$ be a proper order ideal with~$I\subseteq J$.
We must show that~$J=I$.
It suffices to show that~$J$ is a Riesz ideal
(since~$I$ is a maximal Riesz ideal).
Let~$a\in \Real{J}$ be given;
we must show that~$\left|a\right|\in J$.
Recall that $a=a_+-a_-$ and $a_+a_-=0$.
Thus the previous discussion either~$a_+\in I\subseteq J$
or~$a_-\in I\subseteq J$.
In fact, since~$a_+-a_- = a\in J$,
both $a_+\in  J$ and~$a_-\in J$.
But then~$a_++a_- = \left|a\right| \in J$.
Hence~$J$ is a Riesz ideal,
and so~$I=J$.
Thus~$I$ is a maximal order ideal.
\end{erratum}
\begin{erratum}{parsec-280.20}
In point 1,
``$ac=ca$'' should read
``$ac=ca$ and $a^*c=ca^*$''.
\end{erratum}
\begin{addendum}{parsec-280.40}
The statement ``$(a+\frac{1}{n})^\alpha$
norm converges to $a^\alpha$ as $n\to\infty$''
lacks an argument.
Here is one.
First note that~$a$ and all~$a+\frac{1}{n}$
are elements of a commutative $C^*$-subalgebra~$\scrB$
of~$\scrA$.
We'll show, more generally,
that given any uniformly continuous map $f\colon D\to\C$
on some subset~$D$ of~$\C$,
the assignment $b\mapsto f(b)$
where~$b\in \scrB$ with~$\spec(b)\subseteq D$
is uniformly continuous
with respect to the norm on~$\scrA$.
So let~$\varepsilon>0$ be given.
Since~$f$ is uniformly continuous,
there's $\delta>0$ with $\left|f(x)-f(y)\right|\leq\varepsilon$
for all~$x,y\in D$ with $\left|x-y\right|\leq \delta$.
Now, let~$a,b\in \scrB$ with
$\spec(a),\spec(b)\subseteq D$
and~$\left\|a-b\right\|\leq \delta$ be given. Then:
\begin{alignat*}{3}
\|f(a)-f(b)\|
\ &= \ \sup_{\varphi\in \spec(\scrB)}
\left|\,\varphi(\,f(a)\,-\,f(b)\,)\,\right|\qquad
&&\text{by~\sref{parsec-270.180}}
\\
\ &=\ \sup_{\varphi\in\spec(\scrB)}\left|
\,\varphi(f(a))\,-\,\varphi(f(b))\,\right|\qquad
&&
\\
\ &=\ \sup_{\varphi\in\spec(\scrB)}\left|
\,f(\varphi(a))\,-\,f(\varphi(b))\,\right|\qquad
&&\text{by~\sref{parsec-280.20}4}
\\
\ &\leq\ \varepsilon,
\end{alignat*}
because $\left|\varphi(a)-\varphi(b)\right|
\leq \|\varphi\|\,\|a-b\|\leq \delta$,
using here that~$\|\varphi\|\leq 1$
(see~\sref{parsec-200.50}).
\end{addendum}
\begin{erratum}{parsec-290.70}
``continuous bijection onto a compact Hausdorff space''
should read
``continuous bijection from a compact space
to a Hausdorff space''.

A continuous bijection into a compact Hausdorff space need not be a
homeomorphism; take, for example, the identity map from~$[0,1]$
with the discrete topology to~$[0,1]$ with the standard topology.
\end{erratum}
\begin{erratum}{parsec-300.40}
``$\|ab\|_\omega \leq \|\omega\|\,\|a\|\,\|b\|_\omega$''
should read
``$\|ab\|_\omega \leq\,\|a\|\,\|b\|_\omega$'',
and
``$\|ab\|_\omega \leq \|\omega\|\,\|a\|_\omega\,\|b\|$''
should read
``$\|ab\|_\omega \leq\,\|a\|_\omega\,\|b\|$''.
\end{erratum}
\begin{erratum}{parsec-300.60}
``$\|ab\|_\omega \leq \|\omega\|\,\|a\|\,\|b\|_\omega$''
should read
``$\|ab\|_\omega \leq\,\|a\|\,\|b\|_\omega$''.
\end{erratum}
\begin{erratum}{parsec-300.90}
We must have $(\varrho_\Omega(a)x)(\omega)
= \varrho_\omega(a)x$
for all~$\omega\in\Omega$,
so
``$\varrho_\Omega(a)x = \sum_{\omega\in\Omega}
\varrho_\omega(a)x(\omega)$''
should read
``$\varrho_\Omega(a)x = \bigoplus_{\omega\in\Omega}
\varrho_\omega(a)x(\omega)$''.
\end{erratum}
\begin{erratum}{parsec-320.150}
``vector state'' and ``$(X)_1$''
should read ``subunital vector functional''
and ``$(X)_{\leq 1}$'', respectively,
where $(X)_{\leq 1} := 
\{x\in X\colon \|x\|\leq 1\}$.
Indeed, there might
not be any vector states on $\scrB^a(X)$.
Also, ignore the hint.
\end{erratum}
\begin{erratum}{parsec-330.10}
In points~1 and~2,
``$N\times M$'' should read
``$M\times N$''.
\end{erratum}
\begin{erratum}{parsec-330.20}
In point~1,
``Hint: use~\sref{parsec-250.30}'' should read
``Hint: use~\sref{parsec-320.150}''.
\end{erratum}
\begin{erratum}{parsec-330.30}
Don't show that~$M_nf$ needn't be bounded
in point~3,
but on the contrary, that it is bounded by~$n^2\|f\|$.
\end{erratum}
\begin{erratum}{parsec-341.50}
In point~6, ``$u=\sqrt{a^{-1}(a^{-1})^*}$''
should read ``$u=a\sqrt{a^{-1}(a^{-1})^*}$''.
\end{erratum}
\begin{erratum}{parsec-370.50}
The strong operator topology is the topology
induced by the seminorms $T\mapsto \|Tx\|$ where~$x\in \scrH$
(which is not always the least topology that makes
all these seminorms continuous.)
\end{erratum}
\begin{erratum}{parsec-430.20}
The remark in point~3 that~$a_\alpha^*a_\alpha$
is norm-bounded is unwarranted.
\end{erratum}
\begin{erratum}{parsec-720.30}
``$\|\omega\|$''
should be removed
from
``$\left|\omega(a^*bc)\right|\,\leq\,
\|\omega\|\,\|a\|_\omega\,\|b\|\,\|c\|_\omega$''
and 
``$\|b\ast \omega-b'\ast \omega\|
\leq \|\omega\|\,\|b-b'\|_\omega\,(\|b\|_\omega+\|b'\|_\omega)$''
in point~1.
\end{erratum}
\begin{erratum}{parsec-750.30}
``we have $0\leq a_{nm}\leq \frac{1}{2}$''
should read ``we have $0\leq a_{nm}\leq 1$''.
\end{erratum}
\begin{solution}{parsec-40.30}%
Let~$\scrX$, $\scrY$ and~$\scrZ$ be normed (complex) vector spaces.
\begin{enumerate}
\item
To show that the operator norm does indeed
give a norm on~$\scrB(\scrX,\scrY)$,
the following
three observations
regarding $S,T\in\scrB(\scrX,\scrY)$
suffice.
\begin{enumerate}
\item
We have $\|S+T\|\leq \|S\|+\|T\|$.

To see this,
note that
given~$x\in \scrX$,
we have $\|Sx\|\leq \|S\|\|x\|$
and $\|Tx\|\leq \|T\|\|x\|$---because $\|S\|$ and $\|T\|$ are bounds
for~$S$ and~$T$, respectively,---and so 
\begin{equation*}
    \|(S+T)x\|
\ \leq\  \|Sx\|+\|Tx\|
\ \leq\  (\|S\|+\|T\|)\|x\|.
\end{equation*}
Thus~$\|S\|+\|T\|$ is a bound for~$S+T$.
Since~$\|S+T\|$ is the least bound for~$S+T$,
we get~$\|S+T\|\leq \|S\|+\|T\|$.

\item
We have
$\|\lambda S\|=\left|\lambda \right| \|S\|$
for any $\lambda \in \C$.

Surely this statement is correct when~$\lambda= 0$.
To see why it's correct for~$\lambda \neq 0$,
note that
$r\mapsto \left|\lambda\right| r$
sends bounds of~$S$ to bounds of~$\lambda S$.
Indeed,
if~$r\in[0,\infty)$ is a bound of~$S$,
then $\|Sx\|\leq r\|x\|$
for all~$x\in \scrX$,
and so~$\|\lambda Sx\| \equiv 
\left|\lambda \right|\|Sx\|\leq \left|\lambda\right| r \|x\|$
for all~$x\in\scrX$,
that is, $\left|\lambda\right|r$
is a bound for~$\lambda S$.
Similarly~$r\mapsto \left|\lambda\right|^{-1} S$
sends bounds of $\lambda S$
to bounds of~$S$.
Since the two aforementioned maps are each other's inverse,
and both are order preserving,
$r\mapsto \left|\lambda \right|r$
gives an order isomorphism from 
the bounds of~$S$ to the bounds of~$\lambda S$,
and, in particular,
    sends the least bound of~$S$ (being $\|S\|$)
to the least bound of~$\lambda S$
        (being~$\|\lambda S\|$),
that is,
$\left|\lambda\right|\|S\|=\|\lambda S\|$.
\item
We have $\|S\|=0$ iff~$S=0$.

Indeed, the following are equivalent:
$\|S\|=0$; the number~$0$ is a bound for~$S$;
$\|Sx\|\leq 0$ for all~$x\in\scrX$;
$Sx=0$ for all~$x\in\scrX$;
$S=0$.
\end{enumerate}
\item
Since $\|STx\|\leq \|S\| \|Tx\|
\leq \|S\|\|T\|\|x\|$
for all~$x\in \scrX$
the operator $ST$ is bounded by
$\|S\|\|T\|$.
\item
Indeed, $ \|\id x \|\equiv \|x\|\leq  1\cdot\|x\|$
for all~$x\in\scrX$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-40.40}%
Recall that we must prove that
    \begin{equation*}
r\|T\|\ = \ \sup_{x\in (\scrX)_r} \|Tx\|.
    \end{equation*}
Since $(\scrX)_r \equiv \{x\in\scrX\colon \|x\|\leq r\}
    = \{rx\colon x\in (\scrX)_1\}$
    the problem becomes
\begin{equation*}
r\|T\|\ = \ \sup_{x\in (\scrX)_1} \|Trx\|
    \,\equiv\, r\sup_{x\in (\scrX)_1} \|Tx\|.
\end{equation*}
So we've reduced the 
problem to the case~$r=1$, that is, to showing that
\begin{equation*}
    \|T\|\ = \ \sup_{x\in (\scrX)_1} \|Tx\|.
\end{equation*}
Since for~$x\in (\scrX)_1$
we have $\|x\|\leq 1$,
and so~$\|Tx\|\leq \|T\|\,\|x\|\leq \|T\|$,
we see that~$\sup_{x\in (\scrX)_1} \|Tx\|\leq \|T\|$.
For the other direction,
    $\|T\|\leq \sup_{x\in (\scrX)_1} \|Tx\|$,
    it suffices to show that
 $r:=\sup_{x\in(\scrX)_1} \|Tx\|$
is a bound for~$T$,
that is, we must show given~$x\in\scrX$
that $\|Tx\|\leq r\|x\|$.
When~$x=0$ this is obvious, so we'll assume that~$x\neq 0$.
Then~$\| \,x\|x\|^{-1}\,\|\leq 1$,
    so $\|x\|^{-1} \|Tx\|\equiv \|\,T x \|x\|^{-1}\, \| \leq r$,
    and thus $\|Tx\|\leq r\|x\|$,
    making $r$ is a bound for~$T$.
\end{solution}
\begin{solution}{parsec-40.100}%
Taking~$y:=x-x'$ we see that
$\|y\|^2 = \left<y,y\right>
= \left<y,x\right> - \left<y,x'\right> = 0$,
so~$\|y\|=0$,
so~$y\equiv x-x'=0$,
and thus~$x=x'$.

For the second part,
let~$T_1,T_2\colon \scrH\to\scrK$
be operators between pre-Hilbert spaces~$\scrH$
and~$\scrK$
that are both adjoint to an operator~$S\colon \scrK\to\scrH$.
We must show that~$T_1=T_2$.
Given $x\in\scrH$ we have
\begin{equation*}
\left<T_1x,y\right>
\ = \ 
\left<x,Sy\right>
\ = \ 
\left<T_2x,y\right>
\qquad 
    \text{for all~$y\in\scrK$,}
\end{equation*}
and so~$T_1x=T_2x$ by the previous part.
Whence~$T_1=T_2$.
\end{solution}
\begin{solution}{parsec-40.120}%
We prove slightly more than was requested.
Let~$\scrH$, $\scrK$ and~$\scrL$ be pre-Hilbert spaces.
\begin{enumerate}
\item
Let~$T\colon \scrH\to\scrK$ be an adjointable operator,
        so we know that~$T$ is adjoint to some (by~\sref{parsec-40.100}
        unique) operator~$T^*\colon \scrK\to\scrH$.
We must show that $T^*$ is adjoint to~$T$ too.

Let~$x\in\scrH$ and~$y\in\scrK$ be given.
Since~$T$ is adjoint to~$T^*$,
we know that~$\left<Tx,y\right>=\left<x,T^*y\right>$,
and so taking the complex conjugate, we get
        \begin{equation*}
\left<y,Tx\right>\  =\  
    \overline{\left<Tx,y\right>}
    \ =\ 
    \overline{\left<x,T^*y\right>}
    \ =\ \left<T^*y,x\right>,
\end{equation*}
and see that~$T^*$ is adjoint to~$T$.
        Thus~$T^{**}=T$ by definition, \sref{parsec-40.80}.

\item
Given adjointable operators
$S,T\colon \scrH\to\scrK$ 
and~$x\in \scrH$ and $y\in \scrK$,
\begin{equation*}
\left<(S+T)x,y\right>
\ =\  \left<Sx,y\right>\,+\,\left<Tx,y\right>
\ =\ \left<x,S^*y\right>\,+\,\left<x,T^*y\right>
    \ =\ \left<x,(S^*+T^*)y\right>,
\end{equation*}
so~$S+T$ is adjoint to~$S^*+T^*$,
and thus~$(S+T)^*=S^*+T^*$.

Given an adjointable operator~$S\colon \scrH\to\scrK$,
$\lambda\in\C$, $x\in\scrH$, and~$y\in\scrK$,
\begin{equation*}
\left<\lambda Sx,y\right>
\ = \ 
    \overline{\lambda} \left<Sx, y\right>
\ = \ 
    \overline{\lambda} \left<x, S^*y\right>
\ = \ 
     \left<x, \overline{\lambda}S^*y\right>,
\end{equation*}
so~$\lambda S$ is adjoint to $\overline{\lambda}S^*$,
and thus $(\lambda S)^*=\overline{\lambda}S^*$.
\item
Given adjointable operators
$S\colon \scrK\to\scrL$
and $T\colon \scrH\to\scrK$,
and
$x\in\scrH$  and $y\in\scrL$,
we have
\begin{equation*}
\left<STx,y\right>
\ = \ \left<Tx,S^*y\right>
\ = \ \left<x,T^*S^*y\right>,
\end{equation*}
so~$ST$ is adjoint to~$T^*S^*$,
        and thus~$(ST)^*=T^*S^*$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-40.150}%
We'll check the first two requirements
    for $\|x\|=\smash{\sqrt{\left<x,x\right>}}$
    to give a seminorm first.
Given $x\in V$,
we have $\left<x,x\right>\geq 0$,
    so~$\|x\|\equiv \smash{\sqrt{\left<x,x\right>}}\geq 0$.
Given $x\in V$ and $\lambda\in \C$,
we have $\left\|\lambda x\right\|^2
    = \left<\lambda x,\lambda x\right> = \overline{\lambda}\left<x,x\right>
    \lambda = \left|\lambda\right|^2\|x\|^2\geq 0$,
    so
    we get~$\|\lambda x\| = \left|\lambda\right|\|x\|$
    by taking the square root.

Verifying that the triangle inequality holds takes some 
preparations.
As the hint suggests, we prove the Cauchy--Schwarz inequality first.
For this, we must given $x,y\in V$  prove
    that $\left|\left<x,y\right>\right|^2 \leq \left<x,x\right>
    \left<y,y\right>$.
This inequality follows
by applying~\sref{positive-2x2matrix} 
to the matrix
$\smash{\bigl(\begin{smallmatrix}
\smash{\left<x,x\right>} & \smash{\left<x,y\right>} \\
\smash{\left<y,x\right>} & \smash{\left<y,y\right>}
\end{smallmatrix}\bigr)}$,
which is positive,
as for all~$u,v\in\C$,
    \begin{alignat*}{3}
        (
        \begin{smallmatrix}
            \bar{u} & \bar{v}
        \end{smallmatrix})
        \ 
        \bigl(
        \begin{smallmatrix}
\smash{\left<x,x\right>} & \smash{\left<x,y\right>} \\
\smash{\left<y,x\right>} & \smash{\left<y,y\right>}
\end{smallmatrix}\bigr)
        \ \bigl(
        \begin{smallmatrix}
            u \\ v
        \end{smallmatrix}
        \bigr)
        \ &=\  
        \bar{u}u\left<x,x\right>\,+\,
        \bar{u}v\left<x,y\right> \,+\,
        u\bar{v}\left<y,x\right> \,+\,
        \bar{v}v\left<y,y\right> 
        \\
        &=\ \left<\,ux+vy,\,ux+vy\,\right>\,\geq \,0.
    \end{alignat*}
Upon taking the square root
the Cauchy--Schwarz inequality
takes the forms
    \begin{equation*}
    \left|\left<x,y\right>\right|
    \ \leq\  \|x\|\,\|y\|\qquad\text{for all }x,y\in V.
    \end{equation*}
Next, note that~$\bar{z}+z \leq 2\left|z\right|$ for any~$z\in\C$,
    because writing $z\equiv a+ib$,
    we have $\left|\bar{z}+z\right|^2=(\bar{z}+z)^2 = 4a^2 \leq 4(a^2 + b^2) = 4\left|z\right|^2$,
    and so $\bar{z}+z \leq \left|\bar{z}+z\right|\leq 2\left|z\right|$.
In particular, we have,
for all~$x,y\in V$,
\begin{equation*}
\left<x,y\right>+\left<y,x\right>
\ \leq\  2\left|\left<x,y\right>\right|\ \leq\ 
2 \|x\|\,\|y\|.
\end{equation*}
Given $x,y\in V$,
the triangle inequality,
$\|x+y\|\leq \|x\|+\|y\|$,
holds,
because
\begin{alignat*}{3}
    \|x+y\|^2\ &=\ 
    \left<x+y,x+y\right> 
    \ =\ \left<x,x\right>\,+\,
    \left<x,y\right>\,+\,
    \left<y,x\right>\,+\,
    \left<y,y\right> \\
    &\leq \ \left<x,x\right>\,+\,
    2\|x\|\,\|y\|
    \,+\,
    \left<y,y\right>  
    \quad\equiv\ 
    \|x\|^2 \,+\, 2\|x\|\,\|y\| \,+\, \|y\|^2\\
    \ &=\   (\|x\|+\|y\|)^2.
\end{alignat*}

Whence~$\|x\|=\smash{\sqrt{\left<x,x\right>}}$ gives
a seminorm on~$V$.
Recall that for~$\|\,\cdot\,\|$ to be a \emph{norm},
the additional condition
$\|x\|=0\implies x=0$
for all~$x\in V$
must be met.
This is the case when
$\left<\,\cdot\,,\,\cdot\,\right>$
is definite,
because 
$\|x\|=0$
entails $0=\|x\|^2=\left<x,x\right>$,
which, by definiteness of~$\left<\,\cdot\,,\,\cdot\,\right>$,
entails $x=0$.

Let~$x,y\in V$ be given.
To complete this exercise we must establish three
identities.
\emph{Pythagoras' theorem}
holds since $\left<x,y\right>=0$ implies
\begin{alignat*}{3}
\|x+y\|^2\ \equiv  \ \left<x+y,x+y\right>
    \ &=\ 
\left<x,x\right>
\,+\, \left<x,y\right>
\,+\, \left<y,x\right>
\,+\, \left<y,y\right>\\
    \ &=\  
\left<x,x\right>\,+\,\left<y,y\right>
\ = \ \|x\|^2 + \|y\|^2.
\end{alignat*}
Similar to the first line of the display above, we have,
(for any~$x,y\in V$,)
\begin{equation*}
\|x-y\|^2\ =\ 
\left<x,x\right>
\,-\, \left<x,y\right>
\,-\, \left<y,x\right>
\,+\, \left<y,y\right>.
\end{equation*}
Taking the average of these two equations gives the \emph{parallelogram law}:
\begin{equation*}
    \textstyle \frac{1}{2}(\ \|x+y\|^2\,+\,\|x-y\|^2\ )
    \ =\ 
\left<x,x\right>
\,+\, \left<y,y\right>\ \equiv\ 
\|x\|^2 + \|y\|^2.
\end{equation*}
Concerning the \emph{polarisation identity},
note that for any~$n$, we have
\begin{equation*}
i^n\left<i^nx+y,i^nx+y\right>
\ = \ i^n\left<x,x\right>
\,+\, \left<x,y\right>
    \,+\, (-1)^n\left<y,x\right>
    \,+\, i^n\left<y,y\right>.
\end{equation*}
Since~$\sum_{n=0}^3 i^n = 0$
and $\sum_{n=0}^3 (-1)^n=0$,
we get 
\begin{equation*}
    \textstyle
    \sum_{n=0}^3i^n\left\|i^nx+y\right\|^2
\ = \ 4\left<x,y\right>.
\end{equation*}
\end{solution}
\begin{solution}{parsec-40.180}%
Let~$\scrS \subseteq \scrB(\scrH)$
denote the set of bounded adjointable operators $\scrH\to\scrH$.
Since by Exercise~\sref{parsec-40.120},
a linear combination
of adjointable operators is again adjointable,
$\scrS$ is a linear subspace of~$\scrB(\scrH)$.

To show that~$\scrS$ is a closed subset of~$\scrB(\scrH)$,
we must prove that 
the limit~$T$ in $\scrB(\scrH)$
of
a
sequence  $T_1,T_2,\dotsc$
in~$\scrS$
is adjointable.

Note that the sequence $T_1^*,\,T_2^*,\,\dotsc$
is Cauchy, because,
by~\sref{parsec-40.160}, for all~$n,m$,
    \begin{equation*}
    \|T_n^*-T_m^*\|\ =\ \|(T_n-T_m)^*\|\ =\ \|T_n-T_m\|.
    \end{equation*}
Since~$\scrB(\scrH)$ is complete
by~\sref{parsec-40.50},
we may define $S:=\lim_n T_n^*$.
We claim that~$T$ is adjoint to~$S$.
Let~$x,y\in \scrH$ be given.
To prove our claim,
we must show that
that~$\left<Tx,y\right> = \left<x,Sy\right>$.

Note that $T_n^*y$ converges to~$Sy$ as~$n\to\infty$,
because~$\|T_n^*y-Sy\|\leq \|T_n^*-S\|\,\|x\|$
and $\|T_n^*-S\|$ vanishes as~$n$ increases
    by definition of~$S$.
As a result,
$\lim_n \left<x,T_n^*y\right> = \left<x,Sy\right>$.
Note that we use here
that the map $\left<x,\,\cdot\,\right>$,
being bounded by Cauchy--Schwarz
(\sref{parsec-40.150}),
is continuous.
On the other hand,
by a similar reasoning,
$\left<x,T_n^*y\right>
\equiv \left<T_nx,y\right>$
converges to~$\left<Tx,y\right>$ too
as~$n$ increases,
and so~$\left<x,Sy\right>=\left<Tx,y\right>$.
Whence~$T$ is adjoint to~$S$,
and thus~$\scrS$ is closed.
\end{solution}
\begin{solution}{parsec-40.190}%
That~$\ketbra{x}{y}\equiv \left<y,\,\cdot\,\right>x\colon \scrH\to\scrH$ 
is linear is pretty obvious.
    
    Since $\|\,\ketbra{x}{y}z\,\|
    = \|\left<y,z\right>x\|
    =\left|\left<y,z\right>\right|\,\|x\|
    \leq \|y\|\,\|z\|\,\|x\|$
    for all~$z\in\scrH$,
    we see that~$\ketbra{x}{y}$
    is bounded by~$\|y\|\,\|x\|$,
    and so~$\|\ketbra{x}{y}\|\leq \|x\|\,\|y\|$.
    For the other direction,
    note that $\|\ketbra{x}{y}\| \,\|y\|\geq 
    \|\ketbra{x}{y}y\|=\|\left<y,y\right>x\|
    = \|y\|^2\,\|x\|$,
    and so~$\|\ketbra{x}{y}\|\geq \|y\|\,\|x\|$.
    (Even when~$\|y\|=0$.)
    Whence $\|\ketbra{x}{y}\|=\|x\|\,\|y\|$.

Finally,  $\ketbra{x}{y}$
    is adjoint~$\ketbra{y}{x}$,
    because, for all~$w,z\in\scrH$,
    \begin{equation*}
        \left<\,\ketbra{x}{y}z,\, w\,\right>
        \ = \ 
        \left<z,y\right>\,\left<x,w\right>
        \ = \ 
        \left<\, z,\,(\ketbra{y}{x}w)\,\right>.
    \end{equation*}
\end{solution}
\begin{solution}{parsec-50.30}%
Let~$x$ be an element of~$\ell^2\backslash c_{00}$
    (so $x_n$ is non-zero for infinitely many~$n$s.)
We must show that there are no element of~$c_{00}$ with minimal
distance to~$x$.
So let~$y$ be an element of~$c_{00}$,
and suppose (towards a contradiction)
that~$\|x-y\|\leq \|x-y'\|$
for all~$y'\in c_{00}$.

Since~$y$ is in $c_{00}$,
there's~$N$ such that~$y_n=0$ for all~$n> N$.
We claim that~$x_n=y_n$ for all~$n\leq N$.
    Indeed, (if not) define $y'\in c_{00}$
    by $y_n' = x_n$ for all~$n\leq 0$, and~$y_n'=0$ for all~$n >N$.
    Then
\begin{alignat*}{3}
\textstyle
    \|x-y'\|^2\ &=\ 
\textstyle
    \sum_{n=N+1}^\infty \left|x_n\right|^2\\
    \ &\leq \ 
\textstyle
    \sum_{n=0}^N \left|x_n-y_n\right|^2 
    \ +\ \sum_{n=N+1}^\infty \left|x_n\right|^2
    \ = \ \|x-y\|^2.
\end{alignat*}
Thus~$\|x-y'\|\leq \|x-y\|$.
But since~$y$ is assumed to have minimal
distance to~$x$ among the elements of~$c_{00}$,
we already had $\|x-y\|\leq \|x-y'\|$,
and so~$\|x-y\|=\|x-y'\|$.
    Whence~$\sum_{n=0}^N \left|x_n-y_n\right|^2
    = 0$,
    and so~$x_n=y_n$ for all~$n\leq N$.
    In particular, $y=y'$.

It's now easy to find a better approximation
    of~$x$ in~$c_{00}$ than~$y$.
    Indeed, since~$x_n$ is non-zero for infinitely many~$n$s,
    there's an~$M\geq 0$ with 
    \begin{equation*}
        \textstyle
        \sum_{n=M+1}^\infty \left|x_n\right|^2
    \ <\  \sum_{n=N+1}^\infty \left|x_n\right|^2.
    \end{equation*}
    Writing $y''$ for the element of~$c_{00}$
    with $y_n''=x_n$ for all~$n\leq M$ and~$y_n''=0$
    for all~$n > M$,
    we have 
    $\|x-y''\|^2=\sum_{n=M+1}^\infty \left|x_n\right|^2
    < \sum_{n=N+1}^\infty \left|x_n\right|^2 = \|x-y'\|^2 = \|x-y\|^2$,
    which contradicts $\|x-y\|\leq \|x-y''\|$.
    Hence no such~$y$ exists.
\end{solution}
\begin{solution}{parsec-50.60}%
Surely, if $y$ is closest to~$x$
among all elements of~$C$,
it is among all elements of~$y\C\subseteq C$.
Whence~$y$ is a projection of~$x$ on~$y\C$.

We claim that~$\|y\|^2 = \left<x,y\right>$.  When~$y=0$
    this is obvious, so we may assume that~$y\neq 0$,
    so that we can define $e:= y\|y\|^{-1}$.
Since~$y$ is the projection of~$x$ on~$y\C\equiv e\C$,
we know by~\sref{parsec-50.40} that
$y=\left<e,x\right>e$,
and so $\|y\|^2 y = \left<y,x\right>y$.
Whence~$\|y\|^2 = \left<y,x\right>$.
Note that the claim implies that $\left<x-y,y\right>=0$:
\begin{equation*}
0\ =\ \|y\|^2-\left<x,y\right> \ =\  \left<y,y\right>-\left<x,y\right>
\ =\  \left<y,x-y\right>.
\end{equation*}
Let~$c\in C$ be given.
Note that when~$y_1$ is a projection of
    $x$ on~$C$, then~$y_1+c$ is a projection
of~$x+c$ on~$C$, because
    $\|(y_1+c)-(x+c)\|=\|y_1-x\|\leq \|(y'-c)-x\|\equiv \|y'-(x+c)\|$
    for all~$y'\in C$.

Let~$y_1$ and~$y_2$ be projections of~$x$ on~$C$;
we will show that~$y_1=y_2$.
By the previous paragraph,
$0\equiv y_1-y_1$ and~$y_2-y_1$ are projections of~$x-y_1$ on~$C$,
and thus on~$y_1\C$.
But since there's at most one projection of~$x-y_1$ on~$y_1\C$
    by~\sref{parsec-50.40} (even when~$y=0$),
    we get~$0=y_2-y_1$, and so~$y_1=y_2$.

Let~$y'\in C$ be given.
Recall that~$y$ is a (and thus the unique) projection of~$x$
on~$C$. It remains to be shown that
$\left<y',x-y\right>=0$.
Since~$y' \equiv y+y'-y$ is a projection
of $x':=x+y'-y$ on~$C$,
    we get 
\begin{equation*}
0\ =\ \left<y',x'-y'\right>\ \equiv \ 
    \left<y',(x+y'-y)-y'\right>\ \equiv\  \left<y',x-y\right>.
\end{equation*}
\end{solution}
\begin{solution}{parsec-50.110}%
Let~$T\colon \scrH\to\scrK$
be a bounded linear map between Hilbert spaces
$\scrH$ and~$\scrK$.
We'll show that~$T$ is adjointable.

Let~$y \in \scrK$ be given. 
    Then~$\left<y,T(\,\cdot\,)\right>\colon \scrH\to\C$
    is a linear map,
    bounded by $\|y\|\|T\|$,
    because $\left|\left<y,Tx\right>\right|\leq
    \|y\|\, \|Tx\|\leq \|y\|\,\|T\|\,\|x\|$
    for all~$x\in \scrH$.
Thus $\left<y,T(\,\cdot\,)\right>\equiv \left<Sy,\,\cdot\,\right>$
    for some unique $Sy\in \scrH$ by~\sref{parsec-50.90}.

The resulting map~$S\colon \scrK\to\scrH$
is linear, because
    \begin{alignat*}{3}
\left<S(y_1+\lambda y_2),\,\cdot\,\right>
        &=\  \left< y_1+\lambda y_2, T(\,\cdot\,)\right>
    \ =\  \left<y_1,T(\,\cdot\,)\right> + 
    \bar\lambda\left<y_2,T(\,\cdot\,)\right>\\
        \ &=\  \left<Sy_1,\,\cdot\,\right> + 
    \bar\lambda\left<Sy_2,\,\cdot\,\right>
    \ =\  \left<(Sy_1+\lambda Sy_2),\,\cdot\,\right>,
\end{alignat*}
for all $y_1,y_2\in\scrK$ and~$\lambda\in\C$.
Since $\left<Sy,x\right>=\left<y,Tx\right>$
for all~$x\in\scrH$ and~$y\in\scrK$,
 $S$ is adjoint to~$T$ (and~$T$ is adjoint to~$S$).

Finally, note that~$S$ is bounded by~$\|T\|$,
because
$\|Sy\|^2 = \left<Sy,Sy\right>
= \left<y,TSy\right>
\leq \|y\|\,\|T\|\,\|Sy\|$,
and so~$\|Sy\|\leq \|y\|\|T\|$,
for all~$y\in\scrK$.
\end{solution}
\begin{solution}{parsec-70.30}
Let~$a$ be an element of a $C^*$-algebra~$\scrA$.
\begin{enumerate}
    \item[1.]
$\Real{a}$ is self-adjoint, because
$(\Real{a})^*
        = \frac{1}{2}(a^{*}+a^{**}) = \frac{1}{2}(a^*+a) = \Real{a}$.
To see that~$\Imag{a}$ is self-adjoint, recall
        that $\bar{i}=-i$,
so
        $(\Imag{a})^*
        = -\frac{1}{2i}(a^*-a) 
        = \Imag{a}$.

The identity $a=\Real{a}+i\Imag{a}$
follows from
        $2(\Real{a}+i\Imag{a})
        = a+a^* \,+\, (a-a^*)
        = 2a$.
    \item[2.]
    Since $a^*=b^*+\bar{i}c^* =b-ic$,
        we have $2\Real{a}=a+a^* = b+ic\,+\,b-ic = 2b$,
        and $2i\Imag{a} = a-a^* = b+ic \,-\, (b-ic) = 2ic$,
        so~$\Real{a}=b$, and~$\Imag{a}=c$.

\item[3.]
Since $a^* = (\Real{a}+i\Imag{a})^*
        = \Real{a} - i\Imag{a}$ by point~1,
        we get $\Real{(a^*)}=\Real{a}$
        and $\Imag{(a^*)} = -\Imag{a}$ by point~2.

\item[4.]
Indeed,
$a$ is self-adjoint iff~$a=a^*$
        iff $a+a^*=2a$
        iff $\Real{a} \equiv \frac{1}{2}(a+a^*) = a$
        iff $a-a^* = 0$
        iff $\Imag{a}\equiv \frac{1}{2i}(a-a^*) = 0$.

\item[5.]
    $\Real{(\,\cdot\,)}$
        and $\Imag{(\,\cdot\,)}$
        are $\R$-linear,
        because~$(\,\cdot\,)^*$
        is $\R$-linear.

\item[6.]
    Apply point~2 to
    $ia = i(\Real{a}+i\Imag{a}) = \Imag{a}-i\Real{a}$.

\item[7.]
The element
$a^*a$ is self-adjoint,
        because $(a^*a)^*=a^*a^{**}=a^*a$.

Further,
        $a^*a = (\Real{a}-i\Imag{a})(\Real{a}+i\Imag{a})
        = \Real{a}^2 + \Imag{a}^2 + i(\Real{a}\Imag{a}-\Imag{a}\Real{a})$.

\item[8.]
It suffices to find self-adjoint elements~$b$ and~$c$
of some~$C^*$-algebra~$\scrA$ with~$bc\neq cb$,
because then~$a:= b+ic$ will do the job.

Given any linearly independent vectors
$x$ and~$y$
from some Hilbert space~$\scrH$
with $\left<x,y\right>\neq 0$.
define~$b:=\ketbra{x}{x}$ and $c:=\ketbra{y}{y}$.
Then~$bc = \ketbra{x}{y}\,\left<x,y\right> $
and~$cb=\ketbra{y}{x}\,\left<y,x\right>$.
So if~$bc=cb$,
then~$\left|\left<x,y\right>\right|^2x = bcx
= cbx = \left<y,x\right>\|x\|^2y$,
contradicting the linear independence of~$x$ and~$y$.

\item[9.]
Combine point~3 and point~7.

\item[10.]
Indeed, $bc$ is self-adjoint
iff~$bc=(bc)^*\equiv c^*b^*\equiv cb$.

So~$x$ and~$y$ are non-orthogonal linearly independent vectors
of a Hilbert space~$\scrH$ as in point~8,
then~$\ketbra{x}{x}\ketbra{y}{y}\equiv \left<x,y\right>\,\ketbra{x}{y}$
is not self-adjoint.

\item[11.]
Surely, if~$a=0$,
then~$a^*=0$, and so~$\|a\|=0=\|a^*\|$.
So we may assume that~$a\neq 0$
(and so~$a^*\neq 0$).
Then, since~$\|a\|^2=\|a^*a\|\leq \|a^*\|\,\|a\|$,
we have $\|a\|\leq \|a^*\|$.
Since similarly $\|a^*\|\leq \|a\|$,
we get~$\|a\|=\|a^*\|$.

\item[12.]
Note that
$\|\Real{a}\|\leq
\frac{1}{2}\|a\|+\frac{1}{2}\|a^*\|
= \|a\|$
and $\|\Imag{a}\|\leq
\frac{1}{2}\|a\| + \frac{1}{2}\|a^*\|
= \|a\|$
by the triangle inequality and $\|a^*\|=\|a\|$.

\item[13.]
When~$a$ is self-adjoint,
$\|a^2\| = \|a^*a\| = \|a\|^2$.

Let~$x$ and~$y$ be non-zero orthogonal vectors
from some Hilbert space~$\scrH$.
Then~$\ketbra{x}{y}^2 = 0$, and so~$\|\ketbra{x}{y}^2\|=0$,
while $\|\ketbra{x}{y}\|^2 = \|x\|^2\|y\|^2$
(see~\sref{parsec-40.190}) is non-zero.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-80.20}
For the sake of clarity,
we'll denote the zero and unit of a $C^*$-algebra~$\scrA$
in this exercise
by~$0_\scrA$ and~$1_\scrA$, respectively.
\begin{enumerate}
\item
Since~$0_\scrA=1_\scrA$ when~$\scrA=\{0_\scrA\}$,
then also $0_\C=\|0_\scrA\|=\|1_\scrA\|$.
\item
We claim that~$\|1_\scrA\|\leq 1_\C$.
Indeed, since $\|1_\scrA\|=\|1_\scrA^*1_\scrA\|=\|1_\scrA\|^2$,
we either have $\|1_\scrA\|=1_\C$
        or $\|1_\scrA\|=0_\C$.
        In either case, $\|1_\scrA\|\leq 1_\C$.

Thus $\|\lambda 1_\scrA\| = \left|\lambda\right|\|1_\scrA\|\leq
        \left|\lambda\right|$, in~$\C$.
\item
Since $\|\lambda 1_\scrA\|1_\scrA
= \left|\lambda\right| \,\|1_\scrA\|\, 1_\scrA$,
it suffices to show that $\|1_\scrA\|\, 1_\scrA = 1_\scrA$,
        that is, that $\left| 1_\C-\|1_\scrA\|\right|\,\|1_\scrA\| =0$.
But as we already saw that~$\|1_\scrA\|$
is equal to either~$1_\C$ or~$0_\C$,
this is indeed the case.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-90.20}
Showing that the first three points are equivalent is not too difficult.
$\text{1.}\implies\text{2.}$:
    If~$f(x)\geq 0$ for all~$x\in X$,
    then~$g\colon X\to\C$ given by~$g(x)=\sqrt{f(x)}$
    for all~$x\in X$ is continuous,
    and~$g^2=f$.
$\text{2.}\implies\text{3.}$:
is obvious.
$\text{3.}\implies\text{1.}$:
If~$f\equiv g^*g$ for some~$g\in C(X)$,
    then~$f(x)=\smash{\overline{g(x)}}g(x)=\left|g(x)\right|^2\geq 0$
    for all~$x\in X$.
Of course,
$\text{5.}\implies \text{4.}$ is obvious.
For the remainder,
note that given~$t\in \R$ we have
    $\|f-t\|\equiv \sup\{\left|f(x)-t\right|\colon x\in X\}\leq t$
    iff $\left|f(x)-t\right|\leq t$ for all~$x\in X$
    iff $-t\leq f(x)-t \leq t $ for all~$x\in X$
    iff $0\leq f(x)\leq 2t$ for all~$x\in X$
    iff $0\leq f\leq 2t$
    iff $0\leq f$ and~$\frac{1}{2}\|f\|\leq t$.
Hence $\text{4.}\implies\text{1.}\implies\text{5.}$.
\end{solution}
\begin{solution}{parsec-90.30}
Since only~$0$ is not invertible in~$\C$,
    we see that an element $f$ of $C(X)$
    is invertible (with inverse given by~$f^{-1}(x)=f(x)^{-1}$ 
    for all~$x\in X$) precisely when~$f(x)\neq 0$ for all~$x\in X$,
    that is, when $0\notin f(X)$.
In particular,
    $f-\lambda $ is \emph{not} invertible
    iff $0\in (f-\lambda)(X)$
    iff $f(x)=\lambda$ for some~$x\in X$
    iff $\lambda \in f(X)$.
\end{solution}
\begin{solution}{parsec-90.90}
Given an element~$a$ of a $C^*$-algebra,
we have that
    $a$ is an effect iff $0\leq a\leq 1$
    iff both $a$ and~$a^\perp \equiv 1-a$ 
    are positive (using the definition of~$\leq$ here)
    iff both $a^{\perp\perp}\equiv a$ and~$a^\perp$ are positive
    iff $0\leq a^\perp\leq 1$
    iff $a^\perp$ is an effect.
\end{solution}
\begin{solution}{parsec-90.100}
\begin{enumerate}
\item[1.]
$0$ is positive, because~$0^*=0$ and~$\|0-0\|\leq 0$.

That~$a+b\in\scrA_+$ when~$a,b\in\scrA_+$
was proven in~\sref{parsec-90.70}.

To show that~$\lambda a$ is positive
for~$a\in\scrA_+$ and~$\lambda\in[0,\infty)$,
pick~$t\in \R$ with~$\|a-t\|\leq t $.
Then~$\lambda a$ is self-adjoint,
        and~$\|\lambda a -\lambda t\| = \lambda \|a-t\|\leq  \lambda t$,
so~$\lambda a$ is positive.

Since~$0$ is positive,
we have $a\leq a$ for all~$a\in\scrA$.
Further, when~$a\leq b\leq c$ for some~$a,b,c\in\scrA$,
then~$b-a$ and~$c-b$ are positive,
so~$c-a\equiv (c-b)+(b-a)$
    is positive,
        that is~$a\leq c$.
Hence~$\leq$ is a preorder, on~$\scrA$.

\item[2.]
The unit, $1$, is self-adjoint since
$1^*=1^*1 = (1^*1)^* = (1^*)^*=1$,
and positive, because $\|1-1\|\leq 1$.

Given self-adjoint $a$ in~$\scrA$,
$\|a\|+a$ and~$\|a\|-a$ are self-adjoint,
and positive,
because~$\|\,(a+\|a\|)\,-\,\|a\|\,\|\leq\|a\|$
        and $\|\,(\|a\|-a)\,-\,\|a\|\,\|\leq \|a\|$.
    Hence~$-\|a\|\leq a \leq \|a\|$
        for self-adjoint~$a\in\scrA$.

\item[3.]
Let~$x$ and~$y$ be non-orthogonal linearly independent
vectors of a Hilbert space~$\scrH$.
        Then~$\ketbra{x}{x}$ and~$\ketbra{y}{y}$ are self-adjoint.

To see that~$\ketbra{x}{x}$ is positive,
note that~$\ketbra{x}{x}^2 = \ketbra{x}{x}\|x\|^2$,
and   
\begin{alignat*}{3}
    \|\,\ketbra{x}{x}\,-\,\|x\|^2\,\|^2
        &=\  \|\,\ketbra{x}{x}^2 
        \,-\, 2\|x\|^2\ketbra{x}{x}\,+\,\|x\|^4\,\|\\
        \ &=\  \|x\|^2 \ \|\,\ketbra{x}{x}-\|x\|^2\,\|,
\end{alignat*}
        so $\|\,\ketbra{x}{x}-\|x\|^2\,\| \leq \|x\|^2$,
        and hence~$\ketbra{x}{x}$ is positive.

Similarly, $\ketbra{y}{y}$ is positive,
but their product
$\ketbra{x}{x}\,\ketbra{y}{y} 
\equiv \ketbra{x}{y}\,\left<x,y \right>$
isn't even self-adjoint,
        as we saw in 
        the solution to~\sref{parsec-70.30}(10).
\item[4.]
Note that~$\|a\|_o\leq \|a\|$, because
we saw that $-\|a\|\leq a \leq \|a\|$ in point~2.
In particular, $\|a\|_o < \infty$.
Also, clearly, $\|a\|_o\geq 0$ for all~$a\in\Real\scrA$.

Note that~$\|a\|_o = \|-a\|_o$
for all~$a\in\Real\scrA$,
because $-\lambda \leq a\leq \lambda$
iff $\lambda\geq -a \geq -\lambda$
for all~$\lambda\in[0,\infty)$.

Let~$\mu\in\R$ and~$a\in\scrA$ be given;
we want to show that $\|\mu a \|_o = \left|\mu\right|\|a\|_o$.
Since this identity holds when~$\mu=0$,
we may assume that~$\mu\neq 0$.
Suppose for now that~$\mu>0$;
we'll deal with the case that~$\mu<0$ in a moment.
Note that for~$\lambda\in [0,\infty)$,
with $-\lambda \leq \mu a \leq \lambda$
we have~$-\smash{\frac{\lambda}{\mu}}\leq a \leq \smash{\frac{\lambda}{\mu}} $,
so~$\|a\|_o\leq \smash{\frac{\lambda}{\mu}}$,
that is~$\mu \|a\|_o \leq \lambda$.
Taking the infimum, we get~$\mu \|a\|_o\leq \|\mu a\|_o$.
For the other direction,
replace~$\mu$ and $a$ by $\mu^{-1}$ and~$\mu a$,
to get $\mu^{-1} \|\mu a\|_o \leq \|\mu^{-1} \mu a\|_o$,
and so~$\|\mu a\|_o \leq \mu \|a\|_o$.
Thus~$\|\mu a\|_o = \mu\|a\|_o$,
for~$\mu>0$.
In the other case, $\mu<0$,
we have~$-\mu=\left|\mu\right| >0$, 
and so $\|\mu a\|_o = \|-(-\mu)a\|_o
= -\mu \|a\|_o = \left|\mu\right|\|a\|_o$.

Let~$a$ and~$b$ be self-adjoint elements of~$\scrA$.
To show that~$\|\,\cdot\,\|_o$ is a seminorm,
it remains to be shown that
$\|a+b\|_o\leq \|a\|_o+\|b\|_o$.
Given~$\lambda,\mu\in [0,\infty)$
with $-\lambda \leq a\leq \lambda$
and $-\mu \leq b\leq \mu$,
we have $-(\lambda+\mu)\leq a+b\leq \lambda+\mu$,
and so~$\|a+b\|_o\leq \lambda+\mu$.
Taking the infimum over all such~$\lambda$ and~$\mu$,
we get $\|a+b\|_o\leq \|a\|_o + \|b\|_o$.

\item[5.]
Please contact me if you've found a short and elementary proof for any of these
five problems.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-110.60}
\begin{enumerate}
\item[1.]
Since~$\|a\|<\left|\lambda\right|$,
we have $\| \, a\lambda^{-1}\,\|
= \left|\lambda\right|^{-1}\|a\| <1$.
Thus by~\sref{parsec-110.20},
$1-a\lambda^{-1}$ is invertible.
But then~$\lambda-a \equiv \lambda (1-a\lambda^{-1})$
is invertible too.
\item[2.]
(There is an erratum to the printed
        version of this exercise.)

Since~$a-b = b(1-ab^{-1})$
it suffices to show
        that~$1-ab^{-1}$ is invertible.
    Indeed it is, by~\sref{parsec-110.20},
        because $\|ab^{-1}\|\leq \|a\|\,\|b^{-1}\| < 
        \|b^{-1}\|^{-1}\,\|b^{-1}\| = 1$.

\item[3.]
Let~$b\in U$ be given.
To show that~$U$ is open,
we must find~$\varepsilon>0$
with $a\in U$ for all~$a\in\scrA$ with $\|a-b\|\leq \varepsilon$.

Take~$\varepsilon:= \|b^{-1}\|^{-1}$. 
By the previous point,
        $a\equiv (a-b)-(-b)$
        is invertible
        provided that~$\|a-b\|\leq \varepsilon \equiv \|(-b)^{-1}\|^{-1}$,
        because~$-b$ is invertible.
\end{enumerate}
\end{solution}

\begin{solution}{parsec-110.150}
\begin{enumerate}
\item
Since~$\lambda \in \C\backslash \R$,
        we have~$\Imag{\lambda}\neq 0$.
        Then~$\smash{\frac{a-\lambda}{\Imag{\lambda}}}
        = \smash{\frac{a-\Real{\lambda}}{\Imag{\lambda}}}-i$
        is invertible by~\sref{parsec-110.130},
        since $\smash{\frac{a-\Real{\lambda}}{\Imag{\lambda}}}$
        is self-adjoint.
        Upon multiplication with~$\Imag{\lambda}$
        we
        see that~$a-\lambda$ is invertible too.

    \item
We already know that~$a^2-\lambda$ is invertible
for all~$\lambda \in\C\backslash\R$,
so the only thing that remains to be shown is that
$a^2+\lambda$ is invertible
        for $\lambda \in (0,\infty)$.
For this,
        note that since~$a-\sqrt{\lambda}i$ and~$a+\sqrt{\lambda}i$
        are invertible by point~2,
        so is their product $(a-\sqrt{\lambda}i)(a+\sqrt{\lambda}i)
        = a^2+\lambda$.
\item
We already know that~$a^n-\lambda$
is invertible for all~$\lambda\in \C\backslash \R$,
by point~1, so we only need to show
that~$a^n+\lambda$ is invertible for all~$\lambda>0$
iff $a+\lambda$ is invertible for all~$\lambda>0$.
In fact, we'll show that for any~$\lambda>0$ 
the element~$a+\lambda$ is invertible
        iff~$a^n+\lambda^n$ is invertible.
    Since~$a+\lambda = \lambda(\lambda^{-1}a+1)$
    and $a^n+\lambda^n = \lambda^n((\lambda^{-1}a)^n + 1)$,
    it suffices to show that
    $b+1$ is invertible iff $b^n+1$ is invertible, where~$b:=\lambda^{-1}a$.

    Since~$\zeta^2, \zeta^4,\zeta^6,\dotsc,\zeta^{2n}$
are the $n$ roots
of the polynomial~$x^n-1$,
        we have $x^n-1 = \prod_{k=1}^n (x-\zeta^{2k})$.
Substituting~$\zeta^{-1} b$ for~$x$,
and
multiplication by~$-1\equiv \zeta^n$ gives
\begin{equation}
\label{eq:11XV3}
b^n+1 \ =\  \zeta^n(\zeta^{-1}b)^n - \zeta^n
        \ =\  \prod_{k=1}^n b-\zeta^{2k+1}.
\end{equation}
Note that~$\zeta^{2k+1}\notin \R$ when~$k\neq \frac{1}{2}(n-1)$,
and so~$b-\zeta^{2k+1}$
is invertible for such~$k$, by point~1
of this exercise.

Thus in light of~\eqref{eq:11XV3},
$b^n+1$ is invertible
iff $b-\zeta^n\equiv b+1$ is invertible.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-110.180}
Let~$a$ be an element of a $C^*$-sublalgebra~$\scrA$
of a $C^*$-algebra~$\scrB$,
    and assume~$a$ has an inverse~$a^{-1}$ in~$\scrB$.
    We must show that~$a^{-1}\in\scrA$.

Note that~$a^*a$ is invertible in~$\scrB$
    with inverse~$a^{-1} (a^{-1})^*$.
This inverse
$(a^*a)^{-1}$ is in the subalgebra~$\scrA$
by~\sref{parsec-110.160},
because~$a^*a$ is self-adjoint.
    Thus~$(a^*a)^{-1}a^*\equiv a^{-1} (a^{-1})^* a^*
    \equiv a^{-1} (aa^{-1})^* = a^{-1}$
    is in the subalgebra~$\scrA$ as well.
\end{solution}
\begin{solution}{parsec-110.200}
\begin{enumerate}
    \item
Given~$\lambda\in\C$, we have
        $\lambda \in \spec(f)$
        iff $f-\lambda$ is not invertible
        iff~$\lambda \in f(X)$,
using~\sref{parsec-90.30} in the last step.
        Thus~$\spec(f)=f(X)$.
    \item
        A square matrix is invertible iff its kernel is not~$\{0\}$.
In particilar, $A-\lambda$
        is not invertible iff $(A-\lambda)v=0$
        for some non-zero vector~$v\in \C^n$.
In that case, we have $Av=\lambda v$, and so~$\lambda$
is an eigenvalue for~$A$.  Conversely,
for any eigenvalue~$\lambda$ of~$A$
the kernel of~$A-\lambda$ will consist
of the associated eigenvectors, and so~$A-\lambda$ will not be invertible.
Hence the spectrum of~$A$ 
is the set of eigenvalues of~$A$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-110.210}
\begin{enumerate}
\item[1.]
That~$\spec(a)\subseteq \R$ for self-adjoint~$a$
follows from \sref{parsec-110.150}(1).

        To see that  $ \spec(\,\smash{\bigl(\begin{smallmatrix} 0 & 2 \\ 0 & 0
        \end{smallmatrix}\bigr)}\,)=\{0\}$
we must show that~$0$ is the only eigenvalue of
        $ \smash{\bigl(\begin{smallmatrix} 0 & 2 \\ 0 & 0
        \end{smallmatrix}\bigr)}$,
that is,
that~$0$ is the only root of the characteristic polynomial
        $\det(
        \smash{\bigl(\begin{smallmatrix} 0 & 2 \\ 0 & 0
        \end{smallmatrix}\bigr)}
        -\lambda ) = \lambda^2$,
        which is so.
\item[2.]
This follows immediately from \sref{parsec-110.150}(2).
\item[3.]
This follows directly from~\sref{parsec-110.60}(1).
\item[4.]
Let~$\lambda_1,\lambda_2,\dotsc$
        be a sequence in~$\spec(a)$
        that converges to some~$\lambda\in \C$;
        we must show that~$\lambda\in\spec(a)$.
Note that since the set of invertible elements of~$\scrA$
        is open by~\sref{parsec-110.60}(3),
        the set of non-invertible elements of~$\scrA$
        is closed.
Thus, as the $a-\lambda_1,\,a-\lambda_2,\,\dotsc$
are all non-invertible,
and converge to~$a-\lambda$,
this element~$a-\lambda$ is non-invertible as well.
        Hence~$\lambda\in\spec(a)$.

Thus, $\spec(a)$, being a closed and bounded subset of~$\C$,
is compact.
\item[5.]
Given $\lambda\in\C$
        we have $\lambda\in \spec(a)$
        iff $a-\lambda\equiv a+z-(\lambda+z)$ is not invertible
        iff $\lambda+z\in \spec(a+z)$.
        Thus $\spec(a)+z = \spec(a+z)$.
\item[6.]
Let~$\lambda\in \C$ be given.
    Since~$\lambda-a = \lambda a (a^{-1}-\lambda^{-1})$,
    we see that~$\lambda-a$ is invertible
    iff $a^{-1} - \lambda^{-1}$ is invertible.
        Hence~$\spec(a^{-1})=\spec(a)^{-1}$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-120.30}
\begin{enumerate}
\item[1.]
Let~$U:= \dom(f)\equiv\dom(g)$.
Given~$x\in U$ the expression
        \begin{equation*}
            \frac{(f+g)(x)-(f+g)(y)}{x-y}
            \ =\  \frac{f(x)-f(y)}{x-y}
            \ +\ \frac{g(x)-g(y)}{x-y}
        \end{equation*}
        converges to~$f'(x)+g'(x)$ as $y\in U\backslash\{x\}$
        tends to~$x$.  
Thus $f+g$ is holomorphic, and $(f+g)'=f'+g'$.

Given~$x\in U$ the expression
\begin{equation*}
            \frac{(f\cdot g)(x)-(f\cdot g)(y)}{x-y}
            \ =\  \frac{f(x)-f(y)}{x-y}\cdot g(x)
            \ +\ f(y)\cdot \frac{g(x)-g(y) }{x-y}
\end{equation*}
converges to $f'(x)g(x)+f(x)g'(x)$ as $y\in U\backslash\{x\}$
tends to~$x$. Hence~$f\cdot g$ is holomorphic, 
        and $(f\cdot g)' = f'g + fg'$.

\item[2.]
Since for all $x,y\in\C$ with $x\neq y$, 
        we have
\begin{equation*}
\frac{f(x)-f(y)}{x-y} \ = \ 
    \frac{x-y}{x-y} \ = \ 1,
\end{equation*}
$f$ is holomorphic, and $f'(x)=1$ for all~$x\in \C$.

\item[3.]
    Since we have, for all $x,y\in U$ with $x\neq y$,
\begin{equation*}
\frac{f(x)-f(y)}{x-y} \ = \ 
    \frac{a-a}{x-y} \ = \ 0,
\end{equation*}
$f$ is holomorphic, and $f'=0$.

\item[4.]
That~$f$ is holomorphic follows from the previous three points.

The only thing that's not immediately clear
about the expression for~$f'$
is that $(\chi^{n+1})'=(n+1)\chi^n$,
where $\chi$ denotes the holomorphic
function with~$\dom(\chi)=\C$
given by~$\chi(z)=z$ for all~$z\in \C$.

This is, however, easily proven with induction as follows.
The case~$n=0$ follows from point~2.
Further, if~$(\chi^{n+1})'=(n+1)\chi^n$
        for some~$n$,
        then we have~$(\chi^{n+2})'
        = (\chi^{n+1}\cdot\chi)'
        = (\chi^{n+1})'\cdot \chi + \chi^{n+1}\cdot\chi'
        = (n+1)\chi^n\cdot \chi + \chi^{n+1}\cdot 1
        = (n+2)\chi^{n+1}$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-130.60}
Let~$f$ denote the holomorphic
    function on the disk $\dom(f)=\{z\in \C\colon \left|z\right|<R\}$
    given by the power series $\sum_n a_n z^n$.
Let~$r>0$ be the radius of a disk around~$0$ on  which~$f$ is zero,
    so~$f(z)=0$ for all~$z\in \C$ with $\left|z\right|<r$.
Then~$f'(z)=0$ for all~$z\in \C$ with~$\left|z\right|<r$,
    (because~$f'$ is zero on an open neighbourhood around~$z$.)
In particular~$f'(0)=0$.
On the other hand,
    since~$f'(z)=\sum_{n=1}^\infty
    n a_{n} z^{n-1}$ for all~$z\in \C$
by~\sref{parsec-130.40},
    we get~$f'(0)=a_1$.
    Thus~$a_1=0$.

Writing $f^{n\prime }$ for the $n$-th derivative of~$f$,
we get by induction 
that $f^{n \prime }(z)=0$ for all~$z\in \C$
    with $\left|z\right|< r$,
    and~$0=f^{n\prime }(0)=na_n$, for all~$n$.

    Thus~$0=a_0=a_1=a_2=\dotsb$,
    and so~$f=0$.
\end{solution}
\begin{solution}{parsec-140.20}
\begin{enumerate}
    \item[1.]
Following the hint
it suffices to show that
we have
$\sum_n a_n\left|I_n\right| = 0$
for any intervals~$I_1,\dotsc,I_N$ 
and~$a_1,\dotsc,a_N\in \scrA$
with $\sum_n a_n \mathbf{1}_{I_n}=0$.

Note that when an interval $I$ is the disjoint
union of two intervals $I'$ and~$I''$,
        we have both
        $\mathbf{1}_{I} = \mathbf{1}_{I'} + \mathbf{1}_{I''}$,
        and $\left|I\right| = \left|I'\right|+\left|I''\right|$.

It's therefore possible
by splitting the intervals~$I_1,\dotsc,I_N$ as needed,
        to find intervals~$I_1',\dotsc,I_M'$
    and~$a_1',\dotsc,a_M'\in\scrA$
with~$\sum_n a_n \mathbf{1}_{I_n}
= \sum_n a_n' \mathbf{1}_{I_n'}$
and~$\sum_n a_n\left|I_n\right|
= \sum_n a_n'\left|I_n'\right|$,
and the property
that if~$I_n'\cap I_m'\neq \varnothing$,
then~$I_n'=I_m'$.
    Furthermore, by aggregating the~$a_n'$'s of intersecting (and thus equal)
    intervals, we can get  $I_n'\cap I_m'\neq \varnothing$
        to imply that~$n=m$.

We can also arrange the~$I_m'$ to be non-empty, by discarding
        the empty $I_m'$'s (which
        doesn't affect the values of  $\sum_n a_n'\mathbf{1}_{I_n'}$
        and $\sum_n a_n'\left|I_n'\right|$.)

Let~$m$ be given,
        and pick some~$x\in I_m'$.
Since~$I_m'$ intersects none of the intervals $I_1',\dotsc,I_M'$
except itself, we have
\begin{equation*}
    \textstyle
    0\ \equiv\  (\sum_n a_n \mathbf{1}_{I_n})(x)
        \ \equiv\ 
        (\sum_n a_n' \mathbf{1}_{I_n'})(x) \ =\  a_m'.
\end{equation*}
Hence~$a_m'=0$ for all~$m$,
and so~$\sum_n a_n \left|I_n\right|
 = \sum_n a_n' \left|I_n'\right| = 0$.
\item[2.]
We already showed in point~1 that any step function~$f$
        may be written as 
        $f=\sum_n a_n \mathbf{1}_{I_n}$,
        using disjoint and non-empty intervals 
$I_1,\dotsc,I_N$, and~$a_1,\dotsc, a_N\in\scrA$.

We'll show that~$\|f\|=\sup_n\|a_n\|$.
Let~$x\in [0,1]$ be given.
Since the~$I_n$ are disjoint,
        either $f(x)=0$,
        or $f(x)=a_n$ for some~$n$.
In either case, $\|f(x)\|\leq \sup_n \|a_n\|$,
so that~$\|f\|=\sup_{x\in [0,1]}\|f(x)\|\leq \sup_n\|a_n\|$.
On the other hand,
since each~$I_n$ is non-empty,
$f(x)=a_n$ for some~$x$,
and so~$\|a_n\|\leq \|f\|$ for all~$n$,
Hence~$\|f\|=\sup_n \|a_n\|$.

That~$\sum_n\left|I_n\right| \leq 1$ is rather obvious,
but useful in
\begin{equation*}
    \textstyle
    \|\int f \|
\ \equiv\  \|\sum_n a_n \left|I_n\right| \|
\ \leq\  \sum_n \|a_n\| \left|I_n\right|
\ \leq\  \|f\| \sum_n \left|I_n\right|
\ \leq\  \|f\|,
\end{equation*}
to show that the linear operator~$\int\colon S_\scrA\to \scrA$
is bounded by~$1$.

Let~$g\in \overline{S}_\scrA$ be given,
and let
$f_1,f_2,\dotsc$ be a sequence in~$S_\scrA$ converging
to~$g$.
Then since~$\|\int (f_n-f_m)\|\leq \|f_n-f_m\|$
for all~$n$ and~$m$,
the sequence~$\int f_1, \,\int f_2,\dotsc$
is Cauchy,
and therefore convergent.
If~$f_1',f_2',\dotsc$ is a sequence in~$S_\scrA$
that converges to~$g$ too,
then the differences $f_1-f_1',\ f_2-f_2',\ \dotsc$
converge to~$0$,
so $\int f_1 - \int f_1',\ \int f_2-\int f_2',\ \dotsc$
converges to~$\int 0 = 0$.
Since that sequence also converges to
$\lim_n \int f_n - \lim_n \int f_n'$,
we
get~$\lim_n \int f_n = \lim_n \int f_n'$.

We may thus define a map $\int\colon \overline{S}_\scrA \to\scrA$
by setting~$\int g = \lim_n \int f_n$
for any sequence~$f_1,f_2,\dotsc $ in~$S_\scrA$
that converges to~$g$.

It's not hard to see that~$\int$ is linear
using the facts that addition and scalar multiplication
are continuous on~$S_\scrA$ and~$\scrA$.

To see that the map~$\int\colon \overline{S}_\scrA\to\scrA$
is bounded,
let $g\in\overline{S}_\scrA$ be given,
and let~$f_1,f_2,\dotsc$ be a sequence in~$S_\scrA$
that converges to~$g$.
Since~$f_1,f_2,\dotsc$ converges to~$g$,
we have~$\lim_n \|f_n\| = \|g\|$.
We already know that~$\| \int f_n \| \leq \|f_n\|$.
Taking the limit on both sides, we get
$\|\int g\| \equiv \lim_n \|\int f_n\| = \lim_n \|f_n\| \equiv
\|g\|$,
and so~$\int$ is bounded.

That~$\int\colon \overline{S}_\scrA\to \scrA$
is the only bounded linear extension of~$\int\colon S_\scrA\to\scrA$
is rather obvious.

\item[3.]
Let~$g\colon [0,1]\to\scrA$
be a continuous map,
and let~$\varepsilon>0$ be given.
We must find a step function~$f\in S_\scrA$
with $\|f-g\|\leq \varepsilon$.
Since~$g$ is continuous,
there is
for each~$x\in [0,1]$
a $\delta_x>0$
such that $\|g(x)-g(y)\|\leq \varepsilon$
for all~$y\in I_x:=(x-\delta_x,x+\delta_x)\cap[0,1]$.
Since these in-$[0,1]$-open interval~$I_x$
cover the compact set~$[0,1]$,
there are~$x_1,\dotsc,x_N\in [0,1]$
with~$I_{x_1}\cup \dotsb\cup I_{x_N} = [0,1]$.
Pick disjoint intervals~$J_1,\dotsc,J_N$
with $J_n\subseteq I_{x_n}$ for all~$n$,
and~$J_1\cup \dotsb\cup J_N=[0,1]$,
and define $f:= \sum_n g(x_n) \mathbf{1}_{J_n}$.

We claim that~$\|f-g\|\leq \varepsilon$.
To proof this, let~$x\in [0,1]$ be given.
There's exactly one~$n$ with~$x\in J_n$,
and so~$f(x) = g(x_n)$.
Thus $\|g(x)-f(x)\|= \|g(x)-g(x_n)\|\leq \varepsilon$
since~$x\in J_n\subseteq I_{x_n}$.
Hence~$\|f-g\|\leq \varepsilon$.

\item[4.]
Let~$a\in\scrA$ be given.
We must show that
$\int af = a\int f$
for all continuous $f\colon [0,1]\to \C$.
Since such~$f$ can be written as the limit
of linear combinations
of indicator functions,
we may assume without loss of generality
that $f=\mathbf{1}_I$ for some interval~$I$.
Now,
$\int a \mathbf{1}_I = a \left|I\right|
= a \int \mathbf{1}_I$.
\end{enumerate}

\end{solution}
\begin{solution}{parsec-140.80}
    \begin{enumerate}
    \item
   Since~$\bar{z}z=\left|z\right|^2$,
            we have $z (\bar{z} \left|z\right|^{-2})=1$,
            and so~$z^{-1} = \bar{z} (\left|z\right|^2)^{-1}$.
This yields the required identity since
            $\bar{z}=\Real{z}-i\Imag{z}$
            and $\left|z\right|^2 = \Real{z}^2+ \Imag{z}^2$.
    \item
        To the first computation
            I've got nothing to add,
            except $$\textstyle \frac{1}{2}\log(a^2+b^2)
            \ =\  \smash{\log(\sqrt{a^2+b^2})} \ =\  
            \log\left|a+ib\right|.$$
    Concerning the second integral:
            \begin{alignat*}{3}
                \int_{a+ib}^{ib} z^{-1} \,dz 
                \ &=\ \int_a^0
                \frac{t-ib}{t^2+b^2}\,dt \\
                \ &=\ 
                \int_a^0
                \frac{-ib}{t^2+b^2}\,dt 
                \ +\ 
                \int_a^0
                \frac{t}{t^2+b^2}\,dt 
                \\
                \ &=\  i\arctan(\,b/a\,)
                \ + \  \log\left|b\right|
                \ + \ \log\left|a+ib\right|.
            \end{alignat*}
\item
The problem is easily reduced to the case that~$z_0=0$.
In other words,
we must show that
\begin{equation}
    \label{eq:14VIII}
    \int_w^{w'} z^{-1}
    \,dz \ =\ i\measuredangle(w,0,w')\ +\ \log\frac{\left|w'\right|}{\left|w\right|}.
\end{equation}
            Suppose that~$\Imag{w}=\Imag{w'}=:b$
            then the equation above
            follows easily
            from the expression for $
                \int_{a+ib}^{ib} z^{-1} \,dz $ computed above,
                because
                $$\int_w^{w'}
                z^{-1}\,dz\ = \ 
                \int_{\Real{w}+ib}^{ib} z^{-1}\,dz\ - \ 
                \int_{\Real{w'}+ib}^{ib} z^{-1}\,dz
                \ = \ \dotsb
                \ =\  i\measuredangle(w,0,w')
                \ + \ \log\frac{\left|w'\right|}{\left|w\right|},$$
            using here that
            $\arctan(\,\Real{w}/\Imag{w}\,)
            = 2\pi - \arctan(\,\Imag{w}/\Real{w}\,)
            = 2\pi - \measuredangle(1,0,w)$,
            and so~$\arctan(\,\Real{w}/\Imag{w}\,)
            -\arctan(\,\Real{w'}/\Imag{w'}\,) =
            \measuredangle(w,0,w')$.

Similarly, \eqref{eq:14VIII}
follows easily from the first integral computed in point~2
when $\Real{w}=\Real{w'}$.

For the general case we consider
the triangle~$T$ with vertices~$w$, $w'$ and~$w''$
where either $w''=\Real{w}'+i\Imag{w}$
or 
$w''=\Real{w}+i\Imag{w}'$
such that~$0$ is not on the closure of~$T$.
Then Goursat's Theorem, \sref{parsec-140.40}
implies that
\begin{equation*}
    \int_w^{w''} z^{-1}\,dz  \ +\ 
    \int_{w''}^{w'} z^{-1}\,dz \ +\ 
    \int_{w'}^{w} z^{-1}\,dz\ = \ 0,
\end{equation*}
and so
\begin{alignat*}{3}
    \int_{w}^{w'} z^{-1}\,dz \ &= \ 
    \int_w^{w''} z^{-1}\,dz  \ +\ 
    \int_{w''}^{w'} z^{-1}\,dz \\
    &=\ i\measuredangle(w,0,w'')\ 
    +\ \log\frac{\left|w''\right|}{\left|w\right|}
    \ +\ \ i\measuredangle(w'',0,w')\ 
    +\ \log\frac{\left|w'\right|}{\left|w''\right|}\\
    &=\ i(\,\measuredangle(w,0,w'')\,+\measuredangle(w'',0,w')\,)\ 
    +\ \log\frac{\left|w''\right|}{\left|w\right|}\frac{\left|w'\right|}{\left|w''\right|}\\
    &=\ i\measuredangle(w,0,w')\ 
    +\ \log\frac{\left|w'\right|}{\left|w\right|}.
\end{alignat*}
\item
This is obvious if one notes
that the ``$\log$'' terms  will cancel.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-160.50}%
    If~$\spec(a)=\varnothing$,
    then~$\|a\|=\sup\varnothing=\infty$ by~\sref{parsec-160.20},
    which is absurd.
\end{solution}
\begin{solution}{parsec-160.60}%
Given~$\mu\in \C$,
the scalar~$\lambda - \mu$ 
is invertible in~$\scrA$
iff it is invertible in~$\C$
iff~$\lambda\neq \mu$.
Hence~$\spec(\lambda)=\{\lambda\}$.

For the other direction,
suppose that~$a$ is a self-adjoint element of~$\scrA$
    with $\spec(a)=\{\lambda\}$ for some $\lambda\in\C$.
Then $\spec(a-\lambda)=\spec(a)-\lambda = \{0\}$.
    Hence~$\|a-\lambda\|=\sup\{0\}=0$
    by~\sref{parsec-160.20},
    and so~$a=\lambda$.
\end{solution}
\begin{solution}{parsec-160.61}
    Let~$a$ from~$\scrA$ be given.
    Since~$\spec(a)$ is not empty by~\sref{parsec-160.60},
    there is~$\lambda\in\C$ such that~$a-\lambda$ is not intertible.
    As~$0$ is the only non-invertible element of~$\C$,
    we get $a-\lambda = 0$, and so~$a=\lambda$.
    Whence every element of~$\scrA$ is a scalar.
    Thus~$\scrA=\C$ or~$\scrA=\{0\}$.
\end{solution}
\begin{solution}{parsec-170.20}
    We already saw this in~\sref{parsec-90.20},
    but here's the argument again.
We have $\left|\lambda - t\right| \leq t$
iff $-t\leq \lambda - t\leq t$
iff $0\leq \lambda \leq 2t$.
\end{solution}
\begin{solution}{parsec-170.50}
    Note that
2$\implies$1 is obvious, and
1$\iff$4 is true by definition of ``positive'',
so it suffices to prove 
that 1$\implies$ 3$\implies$ 2.

Concerning~1$\implies$ 3, if
$\|a-t\|\leq t$,
    then~$\spec(a)\subseteq [0,2t]\subseteq [0,\infty)$
    by~\sref{parsec-170.30}.

Ad~3$\implies$ 2,
    if~$\spec(a)\subseteq [0,\infty)$,
    then given~$t\geq \frac{1}{2}\|a\|$,
    we have $\spec(a)\subseteq [0,\|a\|]\subseteq [0,2t]$,
    and so~$\|a-t\|\leq t$ by~\sref{parsec-170.30}.
\end{solution}
\begin{solution}{parsec-170.60}
\begin{enumerate}
\item
If~$0\leq a\leq 0$,
then~$\spec(a)\subseteq [0,\infty)$,
and~$\spec(a)=-\spec(-a)= (-\infty,0]$,
so that~$\spec(a)=\{0\}$,
which entails that~$a=0$.
\item
Let~$a_1,a_2,\dotsc$ be a sequence of positive elements
of~$\scrA$ that converges to some element~$a$ of~$\scrA$;
we must show that~$a$ is positive.
Then it's easy to see that~$a$ is self-adjoint,
using the fact that~$(\,\cdot\,)^*$ is continuous.

To show that~$a$ is positive,
it suffices to show that~$\|a-t\|\leq t$ for some~$t\in \R$.
Since the sequence $a_1,a_2,\dotsc$  converges,
it is bounded,
so there is some~$t>0$ with $\|a_n\|\leq t$ for all~$n$.
Since~$a_n$ is positive,
we have~$\|a_n-t\|\leq t$ for all~$n$
by~\sref{parsec-170.50}.
Taking the limit over~$n$,
we get $\lim_n\|a_n-t\|\equiv \|a-t\|\leq t$.
Hence~$a$ is positive, and so~$\scrA_+$ is closed.

\item
We have
$\|a\|\leq \lambda$
iff (\sref{parsec-160.20}) $\left|\mu\right|\leq \lambda$
for all~$\mu\in\spec(a)$
iff $-\lambda \leq \mu \leq \lambda$
for all~$\mu\in\spec(a)$
iff
$\lambda-\mu\geq 0$ and~$\lambda+\mu\geq 0$
for all~$\mu\in\spec(a)$
iff
$\lambda-\spec(a)\equiv\spec(\lambda-a)\subseteq [0,\infty)$
and $\lambda+\spec(a)\equiv\spec(\lambda+a)\subseteq [0,\infty)$
iff (\sref{parsec-170.50})
$\lambda -a$ and~$\lambda+a$ are positive
iff~$-\lambda \leq a\leq \lambda$.

Next,
writing $\|a\|_o = \inf\{\lambda\in \R\colon -\lambda\leq a \leq \lambda\}$
we must show that~$\|a\|=\|a\|_o$.
In~\sref{parsec-90.100},
we already saw that~$\|a\|_o\leq \|a\|$.
For the other direction,
let~$\lambda_1\geq \lambda_2\geq\dotsb\geq \|a\|_o$
be such that~$-\lambda_n \leq a\leq \lambda_n$
for all~$n$,
and~$\inf_n \lambda_n = \|a\|_o$.
Then~$\|a\|\leq \lambda_n$
(by the previous paragraph,)
and so~$\|a\|\leq \inf_n\lambda_n = \|a\|_o$.
Whence~$\|a\|=\|a\|_o$.

Finally,
given self-adjoint elements~$a,b\in\scrA$ with~$0\leq a\leq b$,
we have~$-\|b\|\leq 0\leq a \leq b\leq \|b\|$,
and so $\|a\|\leq\|b\|$.
\item
All this follows from~\sref{parsec-110.150},
using the fact (from~\sref{parsec-170.50}) that self-adjoint~$b\in\scrA$
is positive iff~$\spec(b)\subseteq[0,\infty)$.
\item
This follows from~\sref{parsec-110.210}(6).
\item
First note that~$\frac{1}{n}\leq a$
iff~$a-\frac{1}{n}$ is positive
iff $\spec(\,a-\frac{1}{n}\,)\equiv \spec(a)-\frac{1}{n} \subseteq [0,\infty)$
iff $\spec(a)\subseteq [\frac{1}{n},\infty)$.

Recall that~$a$ is invertibe iff~$0\notin\spec(a)$.
Surely, if~$\spec(a)\subseteq [\frac{1}{n},\infty)$,
then~$0\notin \spec(a)$, and so~$a$ is invertible.
For the other direction,
suppose that~$a$ is not invertible,
then~$0\notin \spec(a)\subseteq [0,\infty)$,
and so (since~$\spec(a)$ is closed),
there's $n$ such that~$\lambda\notin \spec(a)$
for all~$\lambda\in \C$ with $\left|\lambda\right|\leq \frac{1}{n}$.
Thus $\spec(a)\subseteq[\frac{1}{n},\infty)$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-201.10}
Note that the projections
$\pi_j\colon\bigoplus_i \scrA_i\to \scrA_j$
are miu-maps.

Let~$a$ be an element of~$\bigoplus_i \scrA_i$.
Note that since
    $\|a\|=\sup_i\|a(i)\|$, we have $\|a(i)\|\leq \|a\|$ for all~$i\in I$.
Thus, $a$ is positive iff
$\|\,a-\|a\|\,\|\leq\|a\|$
    iff $\|\,a(i)-\|a\|\,\|\leq \|a\|$
    for all~$i\in I$
    iff $a(i)$ is positive for all~$i\in I$.
In particular,
every projection $\pi_j\colon \bigoplus_i\scrA_i\to\scrA_j$
is positive,
    (which also follows from~\sref{parsec-200.50}.)

Let~$\scrB$ be a $C^*$-algebra,
and for each~$i\in I$,
let $f_i\colon \scrB \to \scrA_i$ be an pu-map.
We must show that there is a unique
    pu-map $g\colon \scrB\to \bigoplus_i \scrA_i $
    with~$\pi_i\circ g = f_i$ for all~$i\in I$.
Given~$b\in \scrB$,
    we have~$\|f_i(b)\|\leq 2\|b\|$
    by~\sref{parsec-200.20},
    and so $g(b)(i)=f_i(b)$
    defines an element~$g(b)$ of~$\bigoplus_i\scrA_i$,
    and a map~$g\colon \scrB\to\bigoplus_i\scrA_i$.
Clearly, $g$ is linear, unital,
    and $\pi_i\circ g = f_i$ for all~$i\in I$.
Also, $g$ is positive:
given positive~$b\in \scrB_+$,
we know that~$g(b)(i)=f_i(b)\geq 0$ for every~$i\in I$,
    and so~$g(b)\geq 0$.

The only thing left to show
before we know~$\bigoplus_i \scrA_i$
is the product of the~$\scrA_i$
    in~$\Cstar{pu}$
    is the uniqueness of~$g$.
So let~$g'\colon \scrB\to\bigoplus_i\scrA_i$
be a pu-map
with $\pi_i\circ g' =f_i$ for all~$i\in I$.
Then 
    $g'(b)(i)=\pi_i(g'(b))
    = f_i(b) = g(b)(i)$
    for all~$i\in I$ and~$b\in\scrB$.
    Hence~$g=g'$.

Since the projections $\pi_i$ are all miu-maps,
and the map~$g$ in the proof above is clearly miu when all~$f_i$'s are miu,
we see that $\bigoplus_i\scrA_i$ is also the product
    of the~$\scrA_i$ in~$\Cstar{miu}$.
Since clearly $\bigoplus_i \scrA_i$ is commutative
when all~$\scrA_i$ are commutative,
the full subcategories
    $\cCstar{miu}$ and~$\cCstar{pu}$
    of~$\Cstar{pu}$
    are closed under products.
\end{solution}
\begin{solution}{parsec-201.20}
The only non-trivial part to proving that~$\scrE$
is a $C^*$-subalgebra of~$\scrA$ is
showing that~$\scrE$ is a closed subset of~$\scrA$.
So let~$a_1,a_2,\dotsc$ be a sequence from~$\scrE$
converging to some element~$a$ of~$\scrA$;
we must show that~$a\in \scrE$.
Since~$a_1,a_2,\dotsc$ converges to~$a$,
    the sequence $f(a_1),\,f(a_2),\,\dotsc$
    converges to~$f(a)$,
since $f$, being bounded, is continuous.
    Similarly, $g(a_1),\,g(a_2),\,\dotsc$
    converges to~$g(a)$.
But since  $f(a_n)=g(a_n)$
    for all~$n$ (as~$a_n\in\scrE$)
these sequences
    are the same, and thus their
    limits are equal too.  Thus~$f(a)=g(a)$ and~$a\in\scrE$.

That the inclusion $e\colon \scrE\to\scrA$
is a miu-map is obvious. To see that it's also the equaliser
    of~$f$ and~$g$ in~$\Cstar{pu}$, let~$\scrC$ be a $C^*$-algebra,
and let $\gamma\colon \scrC\to\scrA$ be a pu-map with
$f\circ \gamma = g\circ \gamma$.
We must show that there's a unique pu-map $h\colon \scrC\to\scrE$
with~$e\circ h = g$.
Since~$e$ is injective, uniqueness is clear.
Concerning existence, note
that~$f(\gamma(c))=g(\gamma(c))$
for all~$c\in\scrC$,
and so~$\gamma(c)\in\scrE$.
We may thus define $h\colon \scrC\to\scrE$ by
$h(c)=\gamma(c)$ for all~$c\in\scrC$.
Clearly, $h$ is linear, unital, and~$\gamma=e\circ h$.
Also~$h$ is positive, 
since the elements of~$\scrE$ that are positive in~$\scrA$
are positive in~$\scrE$ too.
    Thus~$e$ is the equaliser of~$f$ and~$g$ in~$\Cstar{pu}$.

Note that since~$e$ is a miu-map,
and the map~$h$ in the proof above is miu provided that~$\gamma$
is miu,
    we see that~$e$ is the equaliser of~$f$ and~$g$ in~$\Cstar{miu}$ too.

Since~$\scrE$ is commutative when~$\scrA$ is commutative,
    $e$ is the equaliser of~$f$ and~$g$ in~$\cCstar{miu}$
    and~$\cCstar{pu}$
    when~$\scrA$ and~$\scrB$ are commutative.
\end{solution}
\begin{solution}{parsec-210.50}
If~$a$ is self-adjoint,
then given $\omega\in\Omega$
we have~$\omega(a)^* = \omega(a^*)=\omega(a)$,
using here that~$\omega$ is involution preserving,
    so~$\omega(a)$ is self-adjoint.

    Conversely,
    if~$\omega(a)$ is self-adjoint for every $\omega\in\Omega$,
then $\omega(a-a^*)=\omega(a)-\omega(a^*)=
    \omega(a)-\omega(a)^*=0$ for every $\omega\in\Omega$,
    and so~$a-a^*=0$, because~$\Omega$ is separating.
    Hence~$a$ is self-adjoint.
\end{solution}
\begin{solution}{parsec-210.100}
Let~$a$ be an element of~$\scrA$
such that~$\omega'(a)\geq 0$
for all~$\omega'\in \Omega'$;
we must show that~$a\geq 0$.
    It suffices to show that~$\omega(a)\geq 0$
    for all~$\omega\in \Omega$,
    since~$\Omega$ is order separating.
    So let~$\omega\in \Omega$ be given,
    and let~$\omega_1',\omega_2',\dotsc$
    be a sequence in~$\Omega'$ converging to~$\omega$
    with respect to the operator norm.
    Then $\omega_1'(a),\,\omega_2'(a),\,\dotsc$
    are all positive, by assumption, and converge
    to~$\omega(a)$.  Thus~$\omega(a)\geq 0$, and so~$a=0$.
    Hence~$\Omega'$ is order separating.
\end{solution}
\begin{solution}{parsec-220.30}
\begin{enumerate}
\item
Let~$f\colon \scrA\to\C$ be a state,
and let~$I$ be an order ideal of~$\scrA$
with~$\ker(f)\subsetneq I$.
Then there's an element~$x\in I$ with~$f(x)\neq 0$.
By scaling~$x$ if necessary,  we may assume that~$f(x)=1$.
Note that~$f(1-x)=f(1)-f(x)=1-1=0$,
and so~$1-x\in\ker(f)\subseteq I$.
But since~$x\in I$, too, we get $1\equiv(1-x)+x\,\in I$.
Hence~$I=\scrA$, and so~$\ker(f)$ is maximal.
\item
By Zorn's lemma,
it suffices to show that a non-empty
chain~$\mathcal{I}$ of proper order ideals
containing~$I$ has an upper bound.
We claim that $J:=\bigcup\mathcal{I}$
is such an upper bound.
For this, we only need to check that~$J$
is an order ideal.  Indeed,
if it is, it'll be an upper bound for~$\mathcal{I}$,
and proper, because~$1\in J\equiv\bigcup \mathcal{I}$
would imply that~$1\in I$
for some $I \in\mathcal{I}$.

Let~$a,b\in J$
be given.
Then $a\in I_1$, and~$b\in I_2$ for some~$I_1,I_2\in\mathcal{I}$.
Since~$\mathcal{I}$ is a chain,
either $I_1\subseteq I_2$ or~$I_2\subseteq I_1$.
Letting~$I$ denote the largest one,
we have~$a,b\in I$, and so~$a+b\in I\subseteq J$.
You get the idea;
by such reasoning we see that~$I$
is an order ideal.

\item
Define $(a):=\Real{(a)}+i\Real{(a)}$,
where
$$\Real{(a)}\ :=\ \{\ b\in \Real{\scrA}\colon \exists\lambda,\mu\in\R\ 
[ \ \lambda a \leq b \leq \mu a\ ]\ \}.$$
Then clearly~$(a)$ is a linear subpace of~$\scrA$
that contains~$a$.
Moreover,
given~$b\in\scrA$
we have $b\in(a)$
iff~$\Real{b},\Imag{b}\in \Real{(a)}$.
Thus~$b\in(a)\implies b^*\in (a)$.

To show that~$(a)$ is an order ideal,
let~$b\in (a)\cap \scrA_+$ 
and $c\in\scrA$ with $-b\leq c\leq b$ be given;
we must show that~$c\in(a)$.

Since~$b$ being positive is self-adjoint,
we have~$b=\Real{b}\in \Real{(a)}$,
and so there are $\lambda,\mu\in \R$
with $\lambda a\leq b\leq \mu a$.
Then $-\mu \leq-b \leq c \leq b  \leq \mu a$,
and so~$c\in \Real{(a)}\subseteq (a)$.
Hence~$(a)$ is an order ideal.

It remains to be shown that~$(a)$ is the least order ideal
that contains~$a$. 
To this end, let an order ideal~$I$ that contains~$a$ be given;
we must show that~$(a)\subseteq I$.
It suffices to show that~$\Real{(a)}\subseteq I$,
and for this,
we must show given~$\lambda,\mu\in \R$
and~$b\in \Real{\scrA}$ with $\lambda a \leq b \leq \mu a$,
that~$b\in I$.

Since then $(\mu-\lambda)a \geq 0$
is a positive element of~$I$,
and $-(\mu-\lambda)a\leq 0 \leq b-\lambda a \leq (\mu-\lambda)a$,
we get $b-\lambda a \in I$,
and thus $b\in I$ too, (since~$\lambda a\in I$).

Hence~$(a)$ is the least order ideal that contains~$a$.

Suppose that~$0\nleq a\nleq 0$,
and let~$b\in \Real{(a)}$ be given.
Pick~$\lambda,\mu \in \R$ with $\lambda a \leq b \leq \mu a$.
Then~$(\mu-\lambda)a\geq 0$.
There are now three cases to consider:
if~$\mu-\lambda >0$, then~$a\geq 0$;
if~$\mu-\lambda < 0$, then~$a\leq 0$;
and if~$\mu-\lambda = 0$, then~$\lambda a = b = \mu a$.
Since the latter case is the only possibility,
we see that~$\Real{(a)}=a\R$, and so~$(a)=a\C$.

Suppose that~$1\in(a)$.
If $0\nleq a\nleq 0$, then we have~$(a)=a\C$,
so~$a$ is a real scalar, which contradicts
$0\nleq a\nleq 0$.
So either~$0\leq a$ or~$a\leq 0$.
In any case,
since~$1\in (a)$,
we have~$1\in \Real{(a)}$,
and so $\lambda a\leq 1\leq \mu a$
for some~$\lambda,\mu\in \R$.
If~$a\geq 0$,
then~$1\leq \mu a$ entails that~$\mu\geq 0$, 
and
$\frac{1}{\mu}\leq a$,
so~$a$ is invertible, by~\sref{parsec-170.60}(6).
If~$a\leq 0$,
then~$1\leq \mu a$ entails that~$\mu\leq 0$,
and
$-\frac{1}{\mu} \leq -a$,
so~$-a$ is invertible,
thus $a$ is invertible too.
\item
Since~$a$ is not invertible,
$(a)$ is proper, by point~3,
and~$(a)$ is thus contained in a maximal order ideal, by point~2.
\item
Recall that $\|a\|=\sup\{\left|\lambda\right|\colon \lambda\in \spec(a)\}$
by~\sref{parsec-160.20}.
Let~$\lambda_1,\lambda_2,\dotsc$
be a sequence in~$\spec(a)$
such that~$\left|\lambda_1\right|\,\leq\,
\left|\lambda_2\right|\,\leq\,
\dotsb$ converges to~$\|a\|$.
Then since~$\spec(a)$ is compact,
a subsequence~$\lambda_{n_1},\,\lambda_{n_2},\,\dotsc$
of  $\lambda_1,\lambda_2,\dotsc$
converges to some~$\lambda\in\spec(a)$.
Since $\left|\lambda_{n_1}\right|,\,\left|\lambda_{n_2}\right|,\,\dotsc$
is a subsequence of 
$\left|\lambda_1\right|\,\leq\,
\left|\lambda_2\right|\,\leq\,$
it must converge to~$\|a\|$, too.
Thus~$\left|\lambda\right|=\|a\|$,
and so either~$\lambda=\|a\|$ or~$\lambda=-\|a\|$.
Thus either~$\|a\|\in \spec(a)$
or~$-\|a\|\in \spec(a)$.
So at least one of
$\|a\|-a$ and~$\|a\|+a$
is not invertible.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-220.80}
Since by~\sref{parsec-220.30}(5)
either~$\|a\|-a$ or~$\|a\|+a$ is not invertible,
there is
by~\sref{parsec-220.30}(4)
a maximal order ideal~$I$
that contains either~$\|a\|-a$
or~$\|a\|+a$.
Writing $\omega\colon\scrA\to\C$
for a state
with~$\ker(\omega)=I$
(see~\sref{parsec-220.40}),
we either have~$\omega(a)=\|a\|$
or~$\omega(a)=-\|a\|$,
so in any case, $\left|\omega(a)\right|=\|a\|$.
\end{solution}
\begin{solution}{parsec-230.70}
This all follows without much effort from~\sref{parsec-230.20}.
\end{solution}
\begin{solution}{parsec-240.20}
\begin{enumerate}
\item
Since~$a$ commutes with~$a^2$,
and~$a^2\leq a^2$,
we have $a\leq \smash{\sqrt{a^2}}\equiv\left|a\right|$,
by~\sref{parsec-230.70}.
Similarly, since $-a$ commutes with~$a^2$,
and $(-a)^2\leq a^2$,
we get $-a\leq \left|a\right|$.
Hence~$-\left|a\right|\leq a\leq \left|a\right|$.
Further, $\|\,\left|a\right|\,\|^2
= \|a^2\|=\|a\|^2$, so~$\|\,\left|a\right|\,\|=\|a\|$.
\item
Note that $a_+\equiv \frac{1}{2}(\left|a\right|+a)$
is positive
since~$-\left|a\right|\leq a$ by point~1.
Similarly, $a_-\equiv \frac{1}{2}(\left|a\right|-a)$
is positive, since~$a\leq \left|a\right|$.

The identity~$a=a_+-a_- $ is trivial.

We have~$a_+a_-=0$, because $4a_+a_- = (\left|a\right|+a)(\left|a\right|-a)
= \left|a\right|^2 - a^2=0$,
using here that~$\left|a\right|^2 = a^2$.
Upon applying~$(\,\cdot\,)^*$,
we see that~$a_-a_+=0$ too.

\item
The hint gives the solution away.

\item
(From the addendum.)
We must show that~$\|a\|=\|a_+\|\vee \|a_-\|$.

Since $-\|a_+\|\vee \|a_-\| 
\leq -\|a_-\| \leq -a_- \leq a \leq
a_+ \leq \|a_+\|\leq \|a_+\|\vee \|a_-\|$,
we have $\|a\|\leq \|a_+\|\vee \|a_-\|$.

For the other direction,
note that $a_+^2 + a_-^2=(a_+-a_-)^2\equiv a^2$,
because $a_+a_-=0$.
In particular, $a_+^2\leq a^2$,
so $\|a_+\|^2 \equiv \|a_+^2\|\leq
\|a^2\|\equiv \|a\|^2$,
and~$\|a_+\|\leq \|a\|$.
Since similarly $\|a_-\|\leq \|a\|$,
we get $\|a_+\|\vee \|a_-\|\leq \|a\|$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-250.10}
This exercise
only adds to our previous observation
in~\sref{parsec-170.50},
that~$a$ is positive iff
$a\equiv c^*c$ for some~$c\in\scrA$.
That~$c^*c$ is positive for all~$c\in\scrA$
was already shown in~\sref{parsec-240.40}.
For the converse, note that when~$a$ is positive,
we have $a=c^*c$
for $c:=\sqrt{a}$,
see~\sref{parsec-230.70}.
\end{solution}
\begin{solution}{parsec-250.20}
\begin{enumerate}
\item
Since~$b\leq c$,
the element $d:=c-b$ is positive.
Note that to prove that $a^*ba \leq a^*ca$,
we must show that $a^*ca - a^*ba=a^*da$
is positive.
Using~\sref{parsec-250.10} to write 
$d\equiv e^* e$ for some~$e\in \scrA$,
we see that~$a^*da =a^*e^*ea=(ea)^*(ea)$,
which is positive,
by~\sref{parsec-250.10}.
\item
An mi-map $f\colon \scrA \to\scrB$
between $C^*$-algebras~$\scrA$ and~$\scrB$
(which preserves multiplication and involution)
sends a positive element of the form~$a^*a$
to $f(a)^*f(a)$,
which is positive too.
Thus such~$f$ is positive.

A completely positive map $f\colon \scrA\to\scrB$
between $C^*$-algebras~$\scrA$
and~$\scrB$,
for which, by definition, $\sum_{i,j} b_i^* f(a_i^*a_j) b_j^*$ is positive
for all tuples $a_1,\dotsc,a_N\in\scrA$
and $b_1,\dotsc,b_N\in\scrB$,
is a positive map too,
because upon taking $N=1$ and~$b_1=1$,
we see that~$f(a^*a)\geq 0$
for all~$a\in\scrA$,
using here that any positive element of~$\scrA$
is of the form~$a^*a$ for some~$a\in\scrA$,
by~\sref{parsec-250.10}.

\item
We need the following observation 
first: we claim that given a positive invertible element~$a$
of a $C^*$-algebra~$\scrA$,
the element~$\sqrt{a}$ is invertible too,
and~$\smash{\sqrt{a}^{-1}} = \smash{\sqrt{a^{-1}}}$.
(Note that~$a^{-1}$ is positive, by~\sref{parsec-170.60}(5).)

That~$a$ is positive and invertible
means that $a\geq \frac{1}{n}$ for some~$n$,
by~\sref{parsec-170.60}(6).
In particular, $a\geq (\frac{1}{n})^2$
for some (greater)~$n$.
For this latter~$n$,
we have~$\sqrt{a}\geq \frac{1}{n}$,
by~\sref{parsec-230.70}---$\sqrt{\,\cdot\,}$
is monotone on a commutative subset,---and 
thus~$\sqrt{a}$ is invertible.

To see that~$\smash{\sqrt{a}^{-1}}=\smash{\sqrt{a^{-1}}}$,
it suffices to show,
by the unique property of the square root
from~\sref{parsec-230.70},
that~$\smash{\sqrt{a}^{-1}}$ commutes with
$a^{-1}$,
(which it does,
because $a$ commutes with~$\sqrt{a}$,)
and that~$\smash{\sqrt{a}^{-1}\cdot\sqrt{a}^{-1}}
= a^{-1}$,
(which is indeed so,
because~$\sqrt{a}\cdot \sqrt{a}=a$.)
Whence~$\smash{\sqrt{a}^{-1}=\sqrt{a^{-1}}}$.

To complete this part of the exercise 
we must show that given
invertible elements~$a$ and~$b$ of
a $C^*$-algebra~$\scrA$
the following are equivalent.
\begin{multicols}{2}
\begin{enumerate}
\item 
\label{S25II3a}
$a\leq b^{-1}$
\item 
\label{S25II3b}
$\sqrt{b}a\sqrt{b} \leq 1$
\item 
\label{S25II3c}
$\|\sqrt{a}\sqrt{b}\|\leq 1$
\item 
\label{S25II3d}
$b\leq a^{-1}$
\end{enumerate}
\end{multicols}
\ref{S25II3a}$\iff$\ref{S25II3b}.
If~$a\leq b^{-1}$,
then~$\sqrt{b} a\sqrt{b}\leq \sqrt{b}b^{-1}\sqrt{b} = 1$,
by part~1 of this exercise,
where we used that~$\smash{\sqrt{b^{-1}}}$
is the inverse of~$\sqrt{b}$.
On the other hand,
if~$\sqrt{b}a\sqrt{b}\leq 1$,
then~$a\equiv \smash{\sqrt{b}^{-1} \sqrt{b} a \sqrt{b}\sqrt{b}^{-1}}
\leq b^{-1}$, 
again using part~1 of this exercise.

\ref{S25II3b}$\iff$\ref{S25II3c}
follows from~\sref{parsec-170.60}(3)
for by it
$(-1\leq)\sqrt{b}a\sqrt{b}\leq 1$
iff $\|\sqrt{a}\sqrt{b}\|^2\equiv \|\sqrt{b}a\sqrt{b}\|\leq 1$
iff $\|\sqrt{a}\sqrt{b}\|\leq 1$.

\ref{S25II3a}$\iff$\ref{S25II3d}.
Note that since $\|\sqrt{a}\sqrt{b}\| = 
\|(\sqrt{a}\sqrt{b})^*\|=\|\sqrt{b}\sqrt{a}\|$,
we have
$a\leq b^{-1}$
iff~$\|\sqrt{a}\sqrt{b}\|\leq 1$
iff~$\|\sqrt{b}\sqrt{a}\|\leq 1$
iff~$b\leq a^{-1}$.
\item
Since~$0\leq a\leq b$,
both~$1+a$ and~$1+b$
are invertible and positive,
and $1+a\leq 1+b$,
Thus, by the previous point,
$(1+b)^{-1}\leq (1+a)^{-1}$, and so:
\begin{alignat*}{3}
a(1+a)^{-1}
\,&+\, (1+a)^{-1}
\,+\, (1+b)^{-1}\\
&\ =\ 
(1+a)(1+a)^{-1}\,+\, (1+b)^{-1} \\
&\ =\ 1+(1+b)^{-1} \\
&\ \leq\ 1+(1+a)^{-1} \\
&\ =\ 
b(1+b)^{-1}
\,+\, (1+b)^{-1}
\,+\, (1+a)^{-1}.
\end{alignat*}
Whence
$a(1+a)^{-1} \leq b(1+b)^{-1}$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-260.20}
\begin{enumerate}
\item
We already know that~$a\leq \left|a\right|$
and $-a\leq \left|a\right|$ by~\sref{parsec-240.20}(1).
So to show that~$\left|a\right|$
is the least upper bound for~$a$ and~$-a$
    in~$\Real{\scrA}$,
we must show
    given an upper bound~$b$ for~$a$, and~$-a$ in~$\Real{\scrA}$
that~$\left|a\right|\leq b$.
        Since~$\sqrt{\,\cdot\,}$ is monotone
        on commuting positive elements,
        and~$a$ and~$b$ are positive, and commute (because
        $\scrA$ is commutative),
        it suffices to show that
        $\left|a\right|^2\equiv a^2 \leq b^2$.
In other words,
we must show that~$b^2-a^2\equiv (b+a)(b-a)$ is positive,
which it is,
by~\sref{parsec-230.70}(2),
being the product of commuting positive elements.
\item
Note that $c+(\,\cdot\,)\colon \Real{\scrA}\to\Real\scrA$
is order preserving,
and, in fact,
an order isomorphism
with inverse $(-c)+(\,\cdot\,)$.
Since order isomorphisms preserve suprema,
$c+a\vee b$ is the supremum
of~$c+a$ and~$c+b$.
\item
Let~$a$ and~$b$ in~$\Real\scrA$
be given.
To prove that~$\Real\scrA$
is a Riesz space
it suffices to show that~$a$ and~$b$ have a supremum
(in~$\Real\scrA$).
By part~1 of this exercise,
we know that~$\left|a-b\right|=(a-b)\vee (b-a)$.
Thus,
by part~2, 
$a+b+\left|a-b\right|$
is the supremum of $2a\equiv a-b+a+b$
and~$2b=b-a+a+b$.
Since~$c\mapsto \frac{1}{2}c\colon \Real\scrA\to\Real\scrA$
is easily seen to be an order isomorphism,
which preserves suprema,
we see that $\frac{1}{2}(a+b+\left|a-b\right|)$
is the supremum of~$a$ and~$b$.
\item
Let~$f\colon \scrA\to\scrB$
be a miu-map between commutative 
$C^*$-algebras~$\scrA$ and~$\scrB$.
Note first that~$f$ preserves the square root
of a positive element~$a\in\scrA$
in the sense that~$\sqrt{f(a)} = f(\sqrt{a})$.
Indeed, 
by~\sref{parsec-230.70}
$\sqrt{f(a)}$
 is the unique element~$b$ of~$\scrB_+$
with~$bf(a)=f(a)b$ and~$b^2=f(a)$.
Since clearly  $f(\sqrt{a})^2 = f(\sqrt{a}\sqrt{a})=f(a)$
and~$f(\sqrt{a})f(a)=f(\sqrt{a}a)=f(a\sqrt{a})=f(a)f(\sqrt{a})$,
we see that~$f(\sqrt{a})$ has this unique property of~$\sqrt{f(a)}$
too,
and so $f(\sqrt{a})=\sqrt{f(a)}$.

As a result~$f(\left|a\right|)=\left|f(a)\right|$
for any~$\Real\scrA$ (since $\left|a\right|=\smash{\sqrt{a^2}}$,)
and thus~$f(a\vee b)=f(a)\vee f(b)$
for all~$a,b\in\Real\scrA$
(since $a\vee b=\frac{1}{2}(a+b+\left|a+b\right|)$,)
and so $f(a\wedge b)=f(a)\wedge f(b)$
for all~$a,b\in\Real\scrA$
(since~$a\wedge b = -((-a)\vee(-b))$.)
\item
We claim that~$\left|a+b\right|\leq \left|a\right|+\left|b\right|$
(in this commutative setting.)
Indeed,
\begin{alignat*}{3}
\left|a\right| \,+\, \left|b\right|
\ &= \ 
a\vee -a\,+\, b\vee -b
\qquad &&\text{by point~1} \\
\ &= \ 
(\,a\,+\,b\vee -b\,)\vee (\,-a \,+\, b\vee -b\,)
\qquad &&\text{by point~2} \\
\ &= \ 
(a+b)\vee(a-b)\vee (-a+b)\vee (-a-b)
\qquad &&\text{by point~2} \\
\ &= \ 
\left|a+b\right| \vee \left | a-b\right|
\qquad &&\text{by point~1} \\
\ &\geq \ 
\left|a+b\right|.
\end{alignat*}
\end{enumerate}
\end{solution}
\begin{solution}{parsec-260.30}
Define $a' = a-(a+b-c)\wedge a$.
Then clearly~$0\leq a' \leq a$.
Further, since $-a' = (a+b-c)\wedge a-a
= b\wedge c -c$,
writing $b':= c-a'=b\wedge c$ 
we have~$0\leq b'\leq b$,  and $a'+b'=c$.
\end{solution}
\begin{solution}{parsec-270.40}
Let~$a\in \scrA$ be given.
The map $\gamma(a)\colon \spec(\scrA)\to \C$
sending~$f$ to~$f(a)$
is continuous as
a direct result
of putting the topology of pointwise convergence
on~$\spec(\scrA)$.
Thus we get a map $\gamma\colon \scrA\to C(\spec(X))$.

To see that~$\gamma$ is miu,
note that given~$a,b\in\scrA$,
we have $\gamma(a+b)=\gamma(a)+\gamma(b)$,
because $\gamma(a+b)(f)
=f(a+b)=f(a)+f(b)=\gamma(a)(f)+\gamma(b)(f)
= (\gamma(a)+\gamma(b))(f)$ for all~$f\in \spec(X)$.
Thus~$\gamma$ preserves addition,
essentially because each~$f$ in~$\spec(\scrA)$
preserves addition.
Similarly,
since each~$f\in\spec(\scrA)$
preserves (scalar) multiplication,
involution, and the unit,
so does~$\gamma$.
Whence~$\gamma$ is miu.
\end{solution}
\begin{solution}{parsec-270.100}
Let~$I$ be a Riesz ideal with~$a\in I$;
we'll show that~$(a)_m \subseteq I$.
Let~$b\in (a)_m$ be given.
By definition of~$(a)_m$ we can
find $n\in \N$ with 
$$\textstyle 0\ \leq\  \left|\Real{b}\right|,
\left|\Imag{b}\right|\ \leq\  n\left|a\right|.$$
Since~$a\in I$, and so~$\left|a\right|\in I$,
the inequalities displayed above imply
$\left|\Real{b}\right|,\left|\Imag{b}\right|\in I$
(since~$I$ is an order ideal, 
see~\sref{parsec-220.20}.)
Further, as $-\left|\Real{b}\right|\leq \Real{b} \leq \left|\Real{b}\right|$
by~\sref{parsec-240.20}(1),
we get $\Real{b}\in I$.
Since similarly $\Imag{b}\in I$,
we see that~$b\equiv \Real{b}+i\Imag{b}\in I$.
Whence~$(a)_m\subseteq I$.

Thus, if~$(a)_m$ is a Riesz ideal,
then~$(a)_m$  will automatically the least Riesz ideal that contains~$a$.
We'll show that~$(a)_m$ is a linear subspace first.
Let $b,b'\in (a)_m$
and~$z\in\C$
be given, and pick~$n,n',k\in \N$ 
with $\left|\Real{b}\right|,\left|\Imag{b}\right|
\leq n \left|a\right|$, 
$\left|\Real{b}'\right|,\left|\Imag{b}'\right|\leq n'a$,
and~$\left|z\right|\leq k$.
Then 
$$\textstyle 
\left|\Real{(b+zb')}\right|
\ =\ \left|\Real{b}+z\Real{b}'\right|
\ \leq\  \left|\Real{b}\right|+\left|z\right| \left|\Real{b}'\right|
\ \leq\  (n+kn')\,\left|a\right|,
$$
using item~5 of the solution to~\sref{parsec-260.20} here.
Since along similar lines, $\left|\Imag{(b+zb')}\right|
\leq (n+kn')\,\left|a\right|$,
we get~$b+zb'\in (a)_m$.
Thus~$(a)_m$ is a linear subspace of~$\scrA$.

Further, note that~$b\in (a)_m\implies b^*\in(a)_m$,
almost trivially,
because  $\Real{(b^*)}=\Imag{b}$
and~$\Imag{(b^*)}=\Real{b}$
for any~$b\in\scrA$.

To see that~$(a)_m$ is an order ideal,
let~$b\in ((a)_m)_+$ and~$c\in \Real\scrA$
with~$-b\leq c\leq b$ be given;
we must show that~$c\in (a)_m$.
By definition of~$(a)_m$,
and using that~$b$ is positive,
we know there is~$n\in\N$ with
$0\leq b\leq n \left|a\right|$.
Then 
$-n\left|a\right| \leq -b \leq c \leq b \leq n\left| a\right| $,
and so~$\left|c\right| \leq n\left|a\right|$,
(since $\left|c\right|= c\vee -c$ by~\sref{parsec-220.20}.)
Thus~$c\in (a)_m$
(since~$\Real{c}=c$ and~$\Imag{c}=0$.)

To show that~$(a)_m$ is a Riesz ideal,
it remains to be shown that~$\left|b\right|\in (a)_m$
for any self-adjoint~$b\in (a)_m$.
For such~$b$ we can find~$n\in\N$ with
$ \left|b\right|  \leq n\left|a\right|$.
Since then
 $\left| \,\left|b\right|\,\right|
\equiv \left|b\right| \leq n\left|a\right|$,
we get~$\left|b\right|\in(a)_m$ too.
Whence~$(a)_m$ is the least Riesz ideal of~$\scrA$
that contains~$a$.

The second order of business
is showing that~$(a)_m=\scrA$ iff~$a$ is invertible.
Suppose that~$a$ is invertible,
then, by~\sref{parsec-270.80},
$b\equiv (ba^{-1})a\in (a)_m$
for all~$b\in\scrA$, so~$\scrA=(a)_m$.
Conversely, suppose that~$(a)_m=\scrA$;
we must show that~$a$ is invertible.
It suffices to show that~$a^2$ is invertible,
because then~$a (a^2)^{-1}$ will the inverse of~$a$.
For this, in turn,
it suffices to show that~$\left|a\right|\equiv \smash{\sqrt{a^2}}$
is invertible,
because then~$(\left|a\right|^{-1})^2$
will be the inverse of~$a^2$.
Since~$(a)_m=\scrA$,
we have~$1\in(a)_m$,
and so~$1\leq n\left|a\right|$ for some~$n\in \N$.
Since this inequality remains valid if we increase~$n$,
we may assume that~$n\neq 0$.
Then~$\frac{1}{n} \leq \left|a\right|$,
and so~$\left|a\right|$ is invertible,
by~\sref{parsec-170.60}6.

The next task is to prove that~$(a)=(a)_m$ when~$a$ is positive.
It suffices to show that~$(a)$ is a Riesz ideal for such positive~$a$.
That is, given self-adjoint $b\in (a)$ we must show 
that~$\left|b\right|\in(a)$.
By the description of~$(a)$ 
from the solution to~\sref{parsec-220.30}3,
we know that there are $\lambda,\mu\in \R$ with
$\lambda a \leq b\leq \mu a$.
Then since writing~$\nu:= \mu\vee -\lambda$,
we have $\mu\leq \nu$ and $-\nu\leq -\lambda$,
and so
$$-\nu a \ \leq\  \lambda a \ \leq\  b\ \leq\  
\mu a\ \leq\  \nu a,$$ using here that~$a$ is positive.
Whence $\left|b\right|\leq \nu a$,
and thus~$\left|b\right| \in (a)$.

Finally,
we must show that~$(a)\neq (a)_m$ may occur for non-positive~$a$.
In fact,
we have~$(a)=(a)_m$ iff either~$0\leq a$ or~$a\leq 0$.
Indeed,
``$\Longleftarrow$'' follows easily from the previous discussion.
For the converse,
suppose that~$(a)=(a)_m$,
and, towards a contradiction,
that neither~$0\leq a$ nor~$a\leq 0$.
Then~$(a)=\C a$
by~\sref{parsec-220.30}3,
and so~$\left|a\right|=\lambda a$ for some~$\lambda\in \C$,
because~$\left|a\right| \in (a)_m=(a)$.
What can~$\lambda$ be?
Note first that~$a\neq 0$ (because otherwise~$0\leq a$,)
and so~$\left|a\right| \neq 0$.
With this we can see that~$\lambda$ must be real:
since
$\lambda a = \left|a\right| = \left|a\right|^* = \bar\lambda a^*
=\bar\lambda a$,
we have $\lambda=\bar\lambda$.
Moreover,
since $\left|a\right|=\left|\,\left|a\right|\,\right|
= \left|\lambda a\right| = \left| \lambda\right|\,\left|a \right|$,
we get~$\left|\lambda\right| = 1$,
and thus~$\lambda = \pm 1$.
If~$\lambda =1$,
then~$a = \left|a\right|\geq 0$, quod non.
On the other hand,
if~$\lambda=-1$,
then~$a=-\left|a\right|\leq 0$, quod non.
So we reach a contradiction in any case.
Whence, if~$(a)=(a)_m$,
then either~$0\leq a$ or~$a\leq 0$.
\end{solution}
\begin{solution}{parsec-270.170}
Given~$\lambda\in\C$,
we have: $\lambda\in \spec(a)$
iff $a-\lambda$ is not invertible,
(by definition of~$\spec(a)$, \sref{parsec-110.190};)
iff $f(a-\lambda)=0$ for some~$f\in \spec(\scrA)$
(by~\sref{parsec-270.150};)
that is, iff~$\lambda=f(a)$ for some~$f\in \spec(\scrA)$.
Whence $\spec(a)=\{\,f(a)\colon\, f\in \spec(\scrA)\,\}$.
\end{solution}
\begin{solution}{parsec-270.180}
Given an  element~$a$ of~$\scrA$
we have
\begin{alignat*}{3}
\|a\|^2  \ &=\ \|a^*a\|
&& \text{by the $C^*$-identity}\\
\ &=\  \sup\{\, \left|\lambda\right|\colon\, 
\lambda\in\spec(a^*a)\,\}
&&\text{by~\sref{parsec-160.20}}\\
\ &=\  \sup\{\, \left|f(a^*a)\right|\colon\, 
f\in\spec(\scrA)\,\}
&&\text{by~\sref{parsec-270.170}}
\\
\ &=\  \sup\{\, \left|f(a)^*f(a)\right|\colon\, 
f\in\spec(\scrA)\,\}
&&\text{as such~$f$ are miu-maps}\\
\ &=\  \sup\{\, \left|(\,\gamma(a)^*\gamma(a)\,)(f)\right|\colon
f\in \spec(\scrA)\,\}
\qquad&&\text{by def.~of~$\gamma$, \sref{parsec-270.30}} \\
\ &=\ \|\gamma(a)^*\gamma(a)\|&&
\text{by def.~of~$\|\,\cdot\,\|$ on~$C(\spec(\scrA))$,
\sref{parsec-30.60}}\\
\ &=\ \|\gamma(a)\|^2
&&\text{by the $C^*$-identity},
\end{alignat*}
and so~$\|\gamma(a)\|=\|a\|$.
It follows that~$\gamma\colon \scrA\to C(\spec(\scrA))$
is injective,
for if $\gamma(a)=0$ for some~$a\in\scrA$,
then~$\|\gamma(a)\|=\|a\|=0$,
and so~$a=0$ too.

To see that~$\gamma(\scrA)$ is closed,
let~$a_1,\,a_2,\,\dotsc$
be a sequence in~$\scrA$
such that $\gamma(a_1),\,\gamma(a_2),\,\dotsc$
converges to some element~$g$ of~$C(\spec(\scrA))$;
we must show that~$g\in\gamma(\scrA)$.
The sequence~$\gamma(a_1),\,\gamma(a_2),\,\dotsc$
being convergent is Cauchy,
and so~$a_1,a_2,\dotsc$ is Cauchy too
(since~$\|\gamma(a)\|=\|a\|$ for all~$a\in\scrA$,)
and thus converges to some~$a\in\scrA$
(since~$\scrA$ is complete.)
But then~$\gamma(a_1),\,\gamma(a_2),\,\dotsc$
converges not only to~$g$, but also to~$\gamma(a)$.
Thus~$g=\gamma(a)\in\gamma(\scrA)$,
and so~$\gamma(\scrA)$
is closed.
It follows that~$\gamma(\scrA)$ is a $C^*$-subalgebra of~$C(\spec(\scrA))$
as~$\gamma(\scrA)$ is clearly a linear subspace
of~$C(\spec(\scrA))$
that contains~$1$ and is closed under multiplication and involution,
see~\sref{parsec-30.40}.
\end{solution}
\begin{solution}{parsec-280.20}
\begin{enumerate}
\item
We define~$C^*(a)$ to be
the norm closure of
\begin{equation*}
\C[a,a^*]\ \equiv\  \{\,f(a,a^*)\colon \,f\in \C[x,y]\,\},
\end{equation*}
where~$\C[x,y]$ denotes the ring
of polynomials over the non-commuting variables~$x$ and~$y$.
Our task then is to show that~$C^*(a)$
defined thus is the least $C^*$-subalgebra
that contains~$a$.
Clearly, $\C[a,a^*]$ is a linear subspace of~$\scrA$
that contains~$1$, $a$, and is
closed under involution and multiplication.
From this it follows easily that its closure, $C^*(a)$,
is a $C^*$-subalgebra of~$\scrA$ that contains~$a$.
Any $C^*$-subalgebra~$\scrS$ of~$\scrA$
that contains~$a$, contains $\C[a,a^*]$, 
and thus its closure, $C^*(a)$, too.
Whence~$C^*(a)$ is the least $C^*$-subalgebra of~$\scrA$ that 
contains~$a$.

For the second part
we must show that an element~$b$ of~$C^*(a)$
commutes with any~$c\in \scrA$
that commutes with both~$a$ and~$a^*$.
To this end it's conventient 
to already bring up the notion
of a \emph{commutant} $S^\square$ of 
a subset~$S$ of~$\scrA$
(treated properly in~\sref{parsec-650.20},)
which is defined by
\begin{equation*}
S^\square\ := \ \{\,
b\in \scrA\colon\, \forall s\in S\,[\ bs=sb\ ]\,\}.
\end{equation*}
Indeed,
in this notation
our goal is to prove that
$C^*(a)\subseteq \{a,a^*\}^{\square\square}$.
Since $a\in \{a,a^*\}^{\square\square}$
it suffices  to show that $\{a,a^*\}^{\square\square}$
is a $C^*$-subalgebra of~$\scrA$.

In general, $S^\square$ is only a closed linear subspace
of~$\scrA$ that contains~$1$,
and is closed under multiplication.
But when~$S$ is closed under involution,
(that is, $s\in S\implies s^*\in S$,)
then~$S^\square$
is closed under involution too
(because then $b^*s=(s^*b)^*=(bs^*)^*=sb^*$
for all~$b\in S^\square$ and $s\in S$.)
In particular, $\{a,a^*\}^\square$
is closed under involution,
and 
so  $\{a,a^*\}^{\square\square}$,
is closed under involution too,
making $\{a,a^*\}^{\square\square}$ a $C^*$-subalgebra of~$\scrA$.

\item 
When~$C^*(a)$ is commutative,
we have
$aa^*=a^*a$ since~$a,a^*\in C^*(a)$.
Conversely,
suppose that $aa^*=a^*a$,
and let~$b\in C^*(a)$ be given;
we must show that~$b$ commutes with all~$c\in C^*(a)$.
Note first that
since~$a$ commutes with both itself and~$a^*$,
we know by part~1 of this exercise
that~$a$ commutes with all elements of~$C^*(a)$,
and, in particular, with~$b$.
Since similarly~$a^*$ commutes with~$b$,
we get (again by part~1)
that~$b$ commutes with all~$c\in C^*(a)$.

It remains to be shown that $a$ and~$a^*$
commute precisely when~$\Real{a}$ and~$\Imag{a}$ commute.
Since $a=\Real{a}+i\Imag{a}$
and $a^*=\Real{a}-i\Imag{a}$ (by~\sref{parsec-70.30}),
we see that~$a$ and~$a^*$ commute provided that $\Real{a}$ and~$\Imag{a}$
commute.
The other direction follows from the equalities
$\Real{a}=\frac{1}{2}(a+a^*)$
and~$\Imag{a}=\frac{1}{2i}(a-a^*)$
(see~\sref{parsec-70.20}).

\item
Note that~$j(\varrho)\equiv 
\varrho(a)\in\spec(a)$ for all~$\varrho\in\spec(C^*(a))$ 
by~\sref{parsec-270.170},
so we indeed get a map $j\colon \spec(C^*(a))\to\spec(a)$.
Since $\spec(C^*(a))$
is endowed with the topology of pointwise convergence,
$j\colon \varrho\mapsto \varrho(a)$
is continuous, almost by definition.

Let~$a\in \scrA_+$ and~$\alpha\in (0,\infty)$ be given.
Since~$\spec(a)\subseteq[0,\infty)$,
the continous map 
$[0,\infty)\to \C$
given
by the assignment $x\mapsto x^\alpha$
can be restricted
to a continuous map $(-)^\alpha\colon \spec(a)\to\C$,
and thus~$a^\alpha$ is defined,
by $a^\alpha = \Phi(\,(-)^\alpha\,)$.
Since this~$\Phi\colon C(\spec(a))\to\scrA$
is a miu-map,
we have,
\begin{alignat*}{3}
a^{\alpha +\beta} \ &=\  \Phi(\,(-)^{\alpha+\beta}\,)
\\
\ &=\  \Phi(\,(-)^\alpha\,(-)^\beta\,) 
\\
&=\  \Phi(\,(-)^\alpha\,)\ \Phi(\,(-)^\beta\,) 
\\
&=\  a^\alpha a^\beta
\end{alignat*}
for all~$\alpha,\beta\in(0,\infty)$ and~$a\in\scrA_+$.
\item
By definition,
$f(a)=\Phi(f)=\gamma_{C^*(a)}^{-1}(f\circ j)$,
where
$$ \gamma_{C^*(a)}\colon\ \ 
C^*(a)\longrightarrow C(\spec( C^*(a))),\ \ 
b\,\mapsto\, (\varrho \mapsto \varrho(b))
$$
is the miu-isomorphism from~\sref{parsec-270.270}.
Since~$\gamma_{C^*(a)}$
is injective,
$f(a)$ is uniquely determined by
$\gamma_{C^*(a)}(f(a))=f\circ j$.
In other words,
$f(a)$ is the unique
element of~$C^*(a)$
with
$f(a)(\varphi)\equiv \gamma_{C^*(a)}(f(a))(\varphi)
= f(j(\varphi))\equiv f(\varphi(a))$
for all~$\varphi \in \spec(C^*(a))$.
\item
We have:
\begin{alignat*}{3}
f(\spec(a))
\ &=\ 
\{\, f(\varphi(a))\colon \, \varphi\in \spec(C^*(a))\,\}
\qquad&&\text{by~\sref{parsec-270.170}} \\
\ &=\ 
\{\, \varphi(f(a))\colon \, \varphi\in \spec(C^*(a))\,\}
\qquad&&\text{by the previous point} \\
\ &=\ 
\spec(f(a))\qquad&&\text{by~\sref{parsec-270.170},}
\\
&&&\quad\text{since~$f(a)\in C^*(a)$}.
\end{alignat*}
\item
We'll first show that~$\spec(\varrho(a))\subseteq \spec(a)$.
So let~$\lambda\in \spec(\varrho(a))$ be given.
We know that~$\varrho(a)-\lambda$
isn't invertible,
and we must show that neither is~$a-\lambda$.
Indeed,
if~$a-\lambda$ were invertible,
then so would be $\varrho(a-\lambda)\equiv \varrho(a)-\lambda$,
which it isn't,
so $a-\lambda$ isn't either.

Next,
to prove that $f(\varrho(a))=\varrho(f(a))$,
it suffices, by point~4,
to show that~$\varrho(f(a))\in C^*(\varrho(a))$,
and,
for all
$\varphi\in\spec(C^*(\varrho(a)))$,
\begin{equation}
\label{eq:28II6}
\varphi(\varrho(f(a)))
\ =\ f(\varphi(\varrho(a))).
\end{equation}
The first condition
follows from the observation
that~$\varrho(\,C^*(a)\,)\subseteq C^*(\varrho(a))$.
Indeed,
let~$b\in C^*(a)$ be given.
Then, by the concrete description
for~$C^*(a)$ from point~1, we know that there's a sequence
$b_1,b_2,\dotsc$ in~$\C[a,a^*]$
that converges to~$b$.
Since~$\varrho$ is a miu-map,
we clearly have $\varrho(b_n)\in \C[\varrho(a),\varrho(a)^*]$
for all~$n$.
Moreover, $\varrho(b_1),\,\varrho(b_2),\,\dotsc$
converges to~$\varrho(b)$,
since~$\varrho$ is bounded
by~\sref{parsec-200.50}.
Whence~$\varrho(b)\in \overline{\C[\varrho(a),\varrho(a)^*]}
\equiv C^*(\varrho(a))$.

Finally,
\eqref{eq:28II6}
follows immediately from point~4,
since~$b\mapsto \varphi(\varrho(b))$
gives a miu-map $C^*(a)\to \C$,
using here that~$\varrho(b)\in C^*(\varrho(a))$
for all~$b\in C^*(a)$.
\item 
To prove that $g(f(a))=(g\circ f)(a)$
it suffices by point~4
to show that $g(f(a))\in C^*(a)$
and~$\varphi(g(f(a))=g(f(\varphi(a)))$
for all $\varphi\in\spec(C^*(a))$.

Note first that~$C^*(f(a))\subseteq C^*(a)$,
because~$f(a)\in C^*(a)$.
So we  indeed get $g(f(a))\in C^*(f(a))\subseteq C^*(a)$.
Finally,
for all~$\varphi\in \spec(C^*(a))$,
\begin{alignat*}{3}
g(f(\varphi(a)))
\ &=\ 
g(\varphi(f(a)))\qquad
&&\text{by point~4} \\
\ &=\ 
\varphi(g(f(a))),
\end{alignat*}
where the latter equality
follows from point~4 too,
using here that~$\varphi$
restricts to an element of~$\spec(C^*(f(a)))$
since~$C^*(f(a))\subseteq C^*(a)$.

The identity $(a^\alpha)^\beta = a^{\alpha\beta}$
for $\alpha,\beta\in(0,\infty)$
and~$a\in\scrA_+$
is a trivial corollary,
as $x\mapsto x^\alpha$
gives a continuous map $[0,\infty)\to [0,\infty)$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-290.70}
Let~$x\in X$ be given;
  we must  prove that~$\delta_x\colon C(X)\to\C$ is a miu-map.
Note that~$\delta_x$ is multiplicative,
because for~$f,g\in C(X)$,
we have $\delta_x(fg)=(fg)(x)=f(x)g(x)=\delta_x(f)\delta_x(g)$.
Similarly, any operation on~$C(X)$ that is defined `coordinatewise'
is preserved by~$\delta_x$. In particular,
$\delta_x$ is unital, since $\delta_x(1)=1(x)=1$,
and $\delta_x$ is involution preserving,
since~$\delta_x(f^*)=f^*(x)=\smash{\overline{f(x)}}=\delta_x(f)^*$
for all~$f\in C(X)$.

The map~$x\mapsto \delta_x\colon X\to \spec(C(X))$
is 
\begin{itemize}
\item
continuous,
because for each~$f\in C(X)$
the map  $x\mapsto \delta_x(f)\colon X\to\C$ (being just~$f$) is continuous,
using here that the topology on~$\spec(C(X))$ 
is the one of pointwise convergence;
\item
surjective,
because by~\sref{parsec-290.20}
each~$\tau \in \spec(C(X))$
is of the form~$\tau\equiv \delta_x$
for some~$x\in X$;
\item
injective,
because for~$x\neq y$ in~$X$
a function~$f\in C(X)$ with $f(x)\neq f(y)$
    can be found (using Urysohn's lemma,)
and so~$\delta_x\neq \delta_y$,
because for one $\delta_x(f)=f(x)\neq f(y)=\delta_y(f)$.
\end{itemize}
Whence~$x\mapsto \delta_x\colon X\to \spec(C(X))$
is a continuous bijection,
  from the compact space~$X$
  to the Hausdorff space~$\spec(C(X))$,
  and thus a homeomorphism
  by e.g.~Theorem~17.14 of~\cite{willard}.
\end{solution}
\begin{solution}{parsec-290.80}
\begin{enumerate}
\item
When~$f\colon X\to Y$ in~$\CH$ is injective,
it is monic~$\Cat{Set}$ and thus a mono in~$\CH$ too.
Conversely,
when~$f$ is mono in~$\CH$,
then it must be injective:
given~$x,y\in X$
with~$f(x)=f(y)$
we have~$f\circ \hat{x}=g\circ \hat{y}$
for the morphisms $\hat{x},\hat{y}\colon \{\ast\}\to X$
in~$\CH$
given by~$\hat{x}(\ast)=x$ and~$\hat{y}(\ast)=y$,
so that~$\hat{x}=\hat{y}$
by monicity of~$f$,
entailing that~$x=y$.
\item
A surjective map is epi in~$\Cat{Set}$, and thus epi in~$\CH$ too.
Conversely, 
when~$f\colon X\to Y$ in~$\CH$ is not surjective,
and there is thus a~$y\in Y\backslash f(X)$,
we can find by complete regularity of~$Y$
a continuous map~$g\colon Y\to \R$ 
that is zero on
the closed set~$f(X)$,
and~$g(y)=1$.
Then $g\circ f$ and~$(2g)\circ f$ are equal,
being both zero,
but~$2g\neq g$
since~$2g(y)=2\neq 1=g(y)$,
and so~$f$ is not epi.
\item
Thus the proposition
that morphisms that are both epi and mono are isomorphisms
holds
in~$\CH$ (by the previous two point,)
in~$\op{\CH}$ (because of symmetry,)
and whence in~$\cCstar{miu}$ (as
it is
equivalent to $\op{\CH}$ by~\sref{parsec-290}.)
\item
\label{S29VIII3}
Let~$\varrho\colon \scrA\to\scrB$
be an injective miu-map between $C^*$-algebras;
we will show that~$\varrho$ is an isometry,
that is, 
that~$\|\varrho(a)\|=\|a\|$ given~$a\in \scrA$.

Suppose for now that~$a$ is self-adjoint.
We claim that~$\varrho(C^*(a))\subseteq C^*(\varrho(a))$.
To this end note
that~$C^*(a)$
is the norm closure
of
$$\C[a]\ \equiv\  \{\ f(a)\colon \ f\in\C[x]\ \},$$
where~$\C[x]$ denotes the ring of polynomials over a variable~$x$.
(Compare this with the expression for~$C^*(a)$
for not-necessarily-self-adjoint~$a$ from 
point~1 of our solution to~\sref{parsec-280.20}.)
Of course, given~$f\in \C[x]$,
we have~$\varrho(f(a))=f(\varrho(a))\in \C[\varrho(a)]\subseteq
C^*(\varrho(a))$,
and so~$\C[a]$ is mapped by~$\varrho$ into~$C^*(\varrho(a))$.
But then into~$C^*(\varrho(a))$
will be mapped too
by~$\varrho$
any~$b\in C^*(a)$ being the norm limit
of a sequence $b_1,b_2,\dotsc\in \C[a]$,
because $\varrho(b)$
is the norm limit of
the sequence 
$\varrho(b_1),\,\varrho(b_2),\,\dotsc$ in $C^*(\varrho(a))$
using here that $\varrho$ is bounded by \sref{parsec-200.50}.

The restriction $\sigma\colon C^*(a)\to C^*(\varrho(a))$
is an isomorphism by point~\ref{S29VIII3} because~$\sigma$
is both mono and epi in~$\cCstar{miu}$.
(Note that $C^*(a)$ and~$C^*(\varrho(a))$ are commutative,
because~$a$ is self-adjoint.)
That $\sigma$ is mono follows simply form the fact
that~$\sigma$ like~$\varrho$ is injective.
To see that~$\sigma$ is epi,
note that if~$g_1,g_2\colon C^*(\varrho(a))\to\scrC$
are miu-maps into some commutative $C^*$-algebra~$\scrC$
with~$g_1\circ \sigma = g_2\circ \sigma$,
then~$g_1$ and~$g_2$ coincide on~$\varrho(a)=\sigma(a)$,
and thus
on~$\C[\varrho(a)]$ too (since~$g_1$ and~$g_2$ preserve sums and products,)
and finally on all of~$C^*(\varrho(a))$
(since~$C^*(\varrho(a))$ is
the norm closure of~$\C[\varrho(a)]$
and~$g_1$ and~$g_2$ are norm continuous.)

Since mi(u)-maps are positive (by~\sref{parsec-250.20}(2))
$\sigma$ is an isomorphism in~$\cCstar{pu}$ too,
and in particular $\sigma$ is bipositive,
(meaning that $\sigma(b)\geq 0$ iff~$b\geq 0$ for all~$b\in C^*(a)$,)
and so by~\sref{parsec-200.60}
$\sigma$ is an isometry on the self-adjoint elements
of~$C^*(a)$, yielding (among other things) that
$\|\varrho(a)\|\equiv\|\sigma(a)\|= \|a\|$.

For arbitrary~$a\in \scrA$,
we have
$\|\varrho(a)\|^2
= \|\varrho(a)^* \varrho(a)\|
= \|\varrho(a^*a)\|=\|a^*a\|=\|a\|^2$
using the $C^*$-identity here twice,
and so~$\varrho$ is an isometry.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-290.90}
Let~$b_1,b_2,\dotsc$ be a sequence in~$\varrho(\scrA)$
that converges to~$b\in \scrB$. 
To prove that~$\varrho(\scrA)$ is closed,
we must show that~$b\in \varrho(\scrA)$.
Since~$\varrho$ is injective,
there are unique~$a_1,a_2,\dotsc$ in~$\scrA$ with
$\varrho(a_n)=b_n$ for all~$n$.
Since~$\varrho$ is by~\sref{parsec-290.80}
 an isometry,
we have $\|a_n-a_m\|=\|\varrho(a_n - a_m)\|
= \|\varrho(a_n)-\varrho(a_m)\|= \|b_n-b_m\|$
for all~$n$ and~$m$,
which implies that~$a_1,a_2,\dotsc$
(like $b_1,b_2,\dotsc$) is a Cauchy sequence,
and therefore ($\scrA$ as $C^*$-algebra being complete)
converges to some~$a\in\scrA$.
Then~$\varrho(a)=\varrho(\lim_n a_n)=
\lim_n \varrho(a_n)=\lim_n b_n=b$
gives us~$b\in \varrho(\scrA)$.

Whence~$\varrho(\scrA)$ is norm closed in~$\scrB$.
Since $\varrho$ preserves (scalar) multiplication, addition and the unit,
it is clear that~$\varrho(\scrA)$ is closed too
under these operations,
and is thus a $C^*$-subalgbra of~$\scrB$.
Restricting~$\varrho$ gives a miu-map $\scrA\to\varrho(\scrA)$
which is both injective and surjective, and therefore a miu-isomorphism.
\end{solution}
\begin{solution}{parsec-300.40}
\begin{enumerate}
\item
$\left|\omega(a^*b)\right|^2
\,\equiv\, \left|[a,b]_\omega\right|^2
\,\leq\, [a,a]_\omega^2\,[b,b]_\omega^2
\,\equiv\, \omega(a^*a)\,\omega(b^*b)$.

\item
\begin{enumerate}
\item
We must show that~$\|ab\|_\omega\leq \|a\|\, \|b\|_\omega$
and not~$\|ab\|_\omega\leq \|\omega\|\,\|a\|\,\|b\|_\omega$
(see erratum).
In fact, the inequality
$\|ab\|_\omega\leq \|\omega\|\,\|a\|\,\|b\|_\omega$
is false\footnote{But
$\|ab\|_\omega\leq \smash{\|\omega\|^{\frac{1}{2}}}\,\|a\|\,\|b\|$
does hold.} unless $\|\omega\|\geq 1$;
indeed taking~$a=b=1$ the inequality
gives $\smash{\left|\omega(1)\right|^\frac{1}{2}
\leq \|\omega\|\,  \left|\omega(1)\right|^\frac{1}{2}}$,
and so~$1\leq \|\omega\|$.

Since~$a^*a\leq \|a^*a\|= \|a\|^2$ (by~\sref{parsec-90.100}(2)
and the $C^*$-identity),
we have $$
\|ab\|_\omega^2
\ \equiv\ 
\omega(b^*a^*ab)\ \leq\  \|a\|^2\, \omega(b^*b)
\ \equiv \ \|a\|^2\,\|b\|_\omega^2
$$
($b^*(\,\cdot\,)b$ being order preserving by~\sref{parsec-250.20}(1))
and so~$\|ab\|_\omega \leq \|a\|\|b\|_\omega$.
\item
We must show that $\|ab\|_\omega\leq \|a\|_\omega\,\|b\|$
(see erratum)
does not always hold.
Indeed, following the hint,
we see that for
$a=\smash{\bigl(\begin{smallmatrix}
0&0\\0&1
\end{smallmatrix}\bigr)}$
and
$b=\frac{1}{2}\smash{\bigl(\begin{smallmatrix}
1&1\\1&1
\end{smallmatrix}\bigr)}$
from~$M_2$,
and~$\omega\colon M_2\to \C$
given by~$\omega(\,\smash{\bigl(\begin{smallmatrix}
1&1\\1&1
\end{smallmatrix}\bigr)}\,)=c$,
we have~$a^*a = a$, so~$\|a\|_\omega$,
but
$(ab)^*(ab) = \frac{1}{2} b $,
and thus~$$\textstyle{}\|ab\|_\omega\,=\,\frac{1}{2} \,\nleq\, 0
\,=\, \|a\|_\omega\,\|b\|.$$

\item
Similarly  $\|ab\|_\omega = \frac{1}{2} \nleq
0 = \|a\|_\omega\,\|b\|_\omega$
(where $a$, $b$ and~$\omega$ are the same as before.)

\item
Note that~$b^*b=b$ so $\|b^*b\|_\omega= \|b\|_\omega$,
which means that the $C^*$-type-identity
$\|b^*b\|_\omega = \|b\|_\omega^2$
holds only when~$\|b\|_\omega^2=\|b\|_\omega$,
but~$\|b\|_\omega=\frac{1}{\sqrt{2}}$.
\item
Finally,
since $ab(ab)^* = \frac{1}{2}a$,
we see that
$\textstyle{}
\|(ab)^*\|_\omega =0\neq \frac{1}{2}= \|ab\|_\omega.$
\end{enumerate}
\end{enumerate}
\end{solution}
\begin{solution}{parsec-300.50}
\begin{enumerate}
\item
\emph{(kernel of~$\eta$)}
Given~$a,b\in V$,
 $\eta(a)=\eta(b)$
iff $\lim_n \|a-b\|=0$
iff $\|a-b\|=0$.
\item
\emph{(pseudometric on the Cauchy sequences)}
Given Cauchy sequences~$a_1,a_2,\dotsc$ and~$b_1,b_2,\dotsc$
abbreviated to~$a$ and~$b$, respectively,
the limit 
\begin{equation}
\label{S30V-defd}
\textstyle d(a,b)\,:=\,\lim_n \|a_n-b_n\|
\end{equation}
exists,
because the sequence  $\|a_1-b_1\|,\ \|a_2-b_2\|,\ \dotsc$
is Cauchy by
\begin{alignat*}{3}
\left|\,\|a_n-b_n\|\,-\,\|a_m-b_m\|\,\right|
\ &\leq\ 
\|\,(a_n-a_m)\,-\,(b_n-b_m)\,\|\\
\ &\leq\ \|a_n-a_m\|\,+\,\|b_n-b_m\|,
\end{alignat*}
where in the first step
we used the inequality  $\left|\|c\|-\|d\|\right|\leq \|c-d\|$
holding for all seminorms.

We claim that~\eqref{S30V-defd} defines
a pseudometric on the set of all Cauchy sequences on~$V$.
Indeed, given Cauchy sequences $a$, $b$, and~$c$ on~$V$,
we have:
\begin{enumerate}
\item
$d(a,a)=0$, since~$\|a_n-a_n\|=0$ for all~$n$;
\item
$d(a,b)=d(b,a)$, since~$\|a_n-b_n\|=\|b_n-a_n\|$
for all~$n$;
\item
$d(a,c)\leq d(a,b)+d(b,c)$---the triangle inequality---since
$\|a_n-c_n\|\leq \|a_n-b_n\|+\|b_n-c_n\|$
for all~$n$.
\end{enumerate}
\item\emph{(metric on~$\scrH$)}\label{S40Vmetric}
Note that given Cauchy sequences $a$, $a'$, $b$ and~$b'$ on~$V$
with $d(a,a')=0$ and~$d(b,b')=0$
we have $d(a,b)=d(a',b')$,
because by the triangle inequality
we have
$d(a,b) \leq d(a,a')+d(a',b')+d(b',b)
= d(a',b')$, and similarly $d(a',b')\leq d(a,b)$,
yielding~$d(a,b)=d(a',b')$.

Whence we may define a distance function~$d$ 
on~$\scrH$ by Equation~\eqref{S30V-defd} as well,
since two Cauchy sequences~$a$ and~$a'$
on~$V$ are considered equivalent in~$\scrH$
exactly when~$d(a,a')\equiv\lim_n\|a_n -a'_n\|=0$.

From what we already established it is clear that~$d$ gives a metric
on~$\scrH$.

\item \emph{(completeness of~$\scrH$)}
In order to show that~$\scrH$
is complete
we must prove that any
Cauchy sequence
$a_1,a_2,\dotsc$ over~$\scrH$
(so each~$a_n$ is a Cauchy sequence $a_{n1},a_{n2},\dotsc$
over~$V$) converges to some element~$b$ of~$\scrH$.

We may assume without loss of generality
that~$d(a_N,a_n)< 2^{-N}$
for all~$n\geq N$
by replacing~$a_1,a_2,\dotsc$
by an appropriate subsequence,
because if this subsequence converges to some~$b\in \scrH$,
then so will the original sequence.

We may also assume without loss of generality
that~$\|a_{nm}-a_{nM}\| \leq  2^{-M}$
for all~$m\geq M$ and~$n$
by replacing~$a_{n1},a_{n2},\dotsc$
by an appropriate subsequence,
because a subsequence is equivalent
to the original sequence.

We will momentarily show that~$a_{11},a_{22},\dotsc$
is a Cauchy sequence over~$V$
to which~$a_1,a_2,\dotsc$ converges,
but before we (and in order to) do this
note that given natural numbers~$n,m,s,t\geq N$,
\begin{alignat*}{8}
\|a_{ns}-a_{mt}\|\ &\leq\ 
\|a_{ns}-a_{nk}\|
\,&&+\,
\|a_{nk}-a_{mk}\|
\,&&+\,
\|a_{mk}-a_{mt}\|&& \\
\ &\leq\ 
 2^{-N}
&&+\, 2^{-N}
&&+\, 2^{-N}
\ &&=\ 3\cdot 2^{-N},
\end{alignat*}
for sufficiently large~$k$,
because 
$\textstyle{} \lim_k \|a_{nk}-a_{mk}\|
=d(a_n,a_m)
< 2^{-N}$.

It follows that~$a_{11},a_{22},\dotsc$
is Cauchy,
because given~$\varepsilon>0$
and~$N$ with $3\cdot 2^{-N}<\varepsilon$,
we have 
$\|a_{nn}-a_{mm}\|\leq 3\cdot 2^{-N}\leq \varepsilon$
for all~$n,m\geq N$.

Also~$\|a_{nn}-a_{nm}\|\leq \varepsilon$
for $n,m\geq N$,
which implies that $d(\,(a_{nn})_n,\, a_m\,)\leq \varepsilon$
for all~$m\geq N$,
and so~$a_1,a_2,\dotsc$ converges to~$(a_{nn})_n$.

Whence~$\scrH$ is complete.

\item
\label{S30Vdenseness}
\emph{(denseness of~$\eta(V)$)}
Given a Cauchy sequence~$a_1,a_2,\dotsc$ in~$V$
(that is, an element of~$\scrH$),
we claim that~$\eta(a_1)\,\eta(a_2),\,\dotsc$
converges to~$(a_n)_n$ in~$\scrH$.
Indeed, $d(\eta(a_m),(a_n)_n) = \lim_n\|a_m-a_n\|$
converges to~$0$ as~$m\to \infty$,
since~$a_1,a_2,\dotsc$ is Cauchy.

\item
\label{S30Visometry}
\emph{($\eta$ is an isometry,)}
because 
$d(\eta(a),\eta(b))
= \lim_n \|a-b\| = \|a-b\|$.
\item
\label{S30Vextension}
\emph{(extension property)}
We must show that that any
uniformly continuous map~$f\colon V\to Y$
into a complete metric space~$Y$
extends uniquely along~$\eta$ 
to a uniformly continuous map~$g\colon \scrH\to Y$,
but we'll prove the more general 
fact that any uniformly continuous map~$f\colon D\to Y$
to a complete metric space~$Y$
defined on a via an isometry $\iota\colon D\to X$ dense subset~$D$
of a complete metric space~$X$
extends uniquely to a uniformly continuous map~$g\colon X\to Y$.

Uniqueness of~$g$ is clear,
since for any~$x\in X$
there is a Cauchy sequence $\eta(d_1),\,\eta(d_2),\,\dotsc$
in~$\eta(D)$ 
with $x=\lim_n \eta(d_n)$, 
and so
\begin{equation}
\label{S30Vg}
\textstyle g(x)\ =\ \lim_n g(\eta(d_n))\ =\ \lim_n f(d_n)
\end{equation}
for any potential~$g$.

Concerning existence,
we wish to take equation~\eqref{S30Vg} as definition for~$g$.
To this end, note that the limit $\lim_n f(d_n)$ exists,
because $d_1,d_2,\dotsc$ being a Cauchy sequence
(just like its isometric image $\eta(d_1),\,\eta(d_2),\dotsc$)
is mapped by the uniformly continuous map~$f\colon D\to Y$
to a Cauchy sequence $f(d_1),\,f(d_2),\,\dotsc$.

We must also show that there is no ambiguity in our definition
of~$g$ in that if~$d_1',d_2',\dotsc$
is (possibly another) Cauchy sequence in~$D$
with~$x=\lim_n \eta(d_n')$,
then~$\lim_n f(d_n)=\lim_n f(d_n')$.

To this end we will prove the more general fact
that given~$\varepsilon>0$ and any $\delta>0$
with $\forall a,b\in D \,[\ d(a,b)\leq \delta
\implies d(f(a),f(b))\leq \varepsilon\ ]$
--- such~$\delta$ exist since~$f$ is uniformly continuous ---
we have
\begin{equation*}
\begin{alignedat}{3}
\textstyle
d(\,\lim_n\eta(a_n),&\,\textstyle \lim_n\eta(b_n)\,)\ <\  \delta\\
&\textstyle\implies\quad
d(\,\lim_n f(a_n),\,\lim_n f(b_n)\,)\ \leq \ \varepsilon,
\end{alignedat}
\end{equation*}
for any Cauchy sequences
$a_1,a_2,\dotsc$ and $b_1,b_2,\dotsc$
in~$D$,
for then we will immediately get
that~$g\colon X\to Y$
defined by~\eqref{S30Vg}
is uniformly continuous.

To begin, since
$d(\, \lim_n \eta(a_n),\,\lim_n \eta(b_n)\,)
\,<\,\delta$
 we have $d(a_k,b_\ell)\leq \delta$
for all sufficiently large~$k$ and~$\ell$,
and so~$d(f(a_k),f(b_\ell))\leq \varepsilon$
for those~$k$s and~$\ell$s,
and then  also:
\begin{equation*}
\begin{alignedat}{3}
d&\textstyle{}(\,\lim_n f(a_n),\,\lim_n f(b_n)\,)\\
\ &\textstyle\leq\ 
d(\,\lim_n f(a_n),\,f(a_k)\,)
\ +\ 
d(f(a_k),f(b_\ell))
\ +\ 
d(\,f(b_\ell),\,\lim_n f(b_n)\,)\\
\ &\textstyle\leq\ 
d(\,\lim_n f(a_n),\,f(a_k)\,)
\ +\ 
\varepsilon
\ +\ 
d(\,f(b_\ell),\,\lim_n f(b_n)\,)\\
\ &\textstyle\qquad\longrightarrow\ 0\ +\ \varepsilon \ +\ 0\quad\text{as $k,l\to\infty$.}
\end{alignedat}
\end{equation*}
Whence there is a unique uniformly continuous
map $g\colon X\to Y$
defined by~\eqref{S30Vg}.
Finally,
it is clear that $g(\eta(a))=f(a)$
for all~$a\in D$ ---
indeed, $\eta(a),\,\eta(a),\,\dotsc$
converges to~$\eta(a)$ in~$X$,
and so~$g(\eta(a))=\lim_n f(a)\equiv f(a)$
by definition of~$g$.

\item
\emph{($\mathscr{H}$ is a Hilbert space)}
By the general fact proven in point~\ref{S30Vextension} 
there are unique uniformly continuous maps
\begin{equation}
\label{S30VHops}
\begin{alignedat}{3}
+ &\colon &\scrH&\times \scrH\to \scrH\\
\,\cdot\, &\colon &\C&\times\scrH\to \scrH\\
\left<\,\cdot\,,\,\cdot\,\right>&\colon
&\scrH&\times\scrH\to \C
\end{alignedat}
\quad\text{with}\quad
\begin{alignedat}{3}
\eta(a)\,+\,\eta(b)\ &=\ \eta(a+b)\\
\lambda\,\cdot\,\eta(a)\ &=\ \eta(\lambda a) \\
\left<\,\eta(a),\,\eta(b)\,\right>\ &=\ \left<a,b\right>
\end{alignedat}
\end{equation}
for all~$a,b\in V$ and~$\lambda\in \C$,
since
$\eta\circ +\colon V\times V\to \scrH$,
$\eta\circ \cdot \colon \C\times V\to \scrH$,
and $\left<\,\cdot\,,\,\cdot\,\right>\colon V\times V\to \C$
are uniformly continuous, 
$\eta\times \eta\colon V\times V \to \scrH\times\scrH$, and
$\C\times \eta\colon \C\times V\to \C\times \scrH$
have dense image,
and $\C$ and~$\scrH$ are complete.

Any equation  $s(x_1,\dotsc,x_n)=t(x_1,\dotsc,x_n)$
involving these (and other continuous) operations
that holds for all $x_1,\dotsc,x_n\in V$
will hold for all $x_1,\dotsc,x_n\in \scrH$
as well,
since the continuous functions $s$ and~$t$
defined on $\scrH\times\dotsb \times\scrH$
are equal when equal
on the dense subset $V\times\dotsb\times V$.
Whence~$\scrH$ is a vector space.
Similarly,
any $\leq$-inequality between continuous operations
on~$V$ holds for~$\scrH$ as well,
which implies that~$\left<\,\cdot\,,\,\cdot\,\right>$
gives an inner product on~$\scrH$.
Since the equation $\left<x-y,x-y\right>=d(x,y)^2$
which holds on~$V$ holds on~$\scrH$,
we see that the metric induced by the inner product on~$\scrH$
coincides with the metric defined on~$\scrH$ in point~\ref{S40Vmetric}.
As a result, the inner product on~$\scrH$
is definite and complete,
and so~$\scrH$ is a Hilbert space.
\item
\emph{(extension of bounded linear maps)}
Let~$f\colon V\to\scrK$ be a bounded linear map
to a Hilbert space~$\scrK$.
We must show that there is a unique bounded linear map
$g\colon \scrH\to \scrK$ with $g\circ \eta = f$.
By~\ref{S30Vextension}
we know that there is a unique uniformly continuous map~$g$
with $g\circ \eta=f$,
so the only thing left to prove is that~$g$
is linear and bounded.
Since the equations and inequalities involved in~$g$ being linear
and bounded hold on~$\eta(V)$
(since~$f$ is linear and bounded,)
they hold on~$\scrH$ as well,
and thus~$g$ is linear and bounded.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-320.30}%
Let~$T\colon X\to Y$ be an adjointable operator
between pre-Hilbert $\scrA$-modules~$X$ and~$Y$.
\begin{enumerate}
\item
$T^{**}=T$,
because 
$\left<T^*y,x\right>
= \left<x,T^*y\right>^* 
= \left<Tx,y\right>^*
= \left<y,Tx\right>$
for all~$x\in X$ and~$y\in Y$.
\item
Let~$S\colon X\to Y$ be an adjointable operator too.
\begin{enumerate}
\item
$(T+S)^*=T^*+S^*$,
because $\left<(T+S)x,y\right>
= \left<Tx,y\right>+\left<Sx,y\right>
= \left<x,T^*y\right>+\left<x,S^*y\right>
= \left<x,(T^*+S^*)y\right>$
for all~$x\in X$ and $y\in Y$.
\item
$(\lambda T)^* = \smash{\overline{\lambda}}T^*$
for all~$\lambda\in \C$,
because $\left<\lambda Tx,y\right>
= \smash{\overline{\lambda}}\left<Tx,y\right>
= \smash{\overline{\lambda}}\left<x,T^*y\right>
= \left<x,\smash{\overline{\lambda}}T^*y\right>$
for all~$x\in X$ and $y\in Y$.
\end{enumerate}

\item
Let~$S$ now be an adjointable operator
$S\colon Y\to Z$
to a pre-Hilbert $\scrA$-module~$Z$.
Then~$(ST)^*=T^*S^*$,
because
$\left<STx,z\right>
= \left<Tx,S^*z\right>
= \left<x,T^*S^*z\right>$
for all~$x\in X$ and~$z\in Z$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-320.40}%
In general,
any closed submodule of a Hilbert $\scrA$-module
is a Hilbert $\scrA$-module.
The subset~$J$ of~$C[0,1]$,
being the kernel of the map miu-map $f\mapsto f(0)\colon C[0,1]\to\C$,
is a closed two-sided $C^*$-ideal,
and in particilar a closed submodule of
the Hilbert $C[0,1]$-module $C[0,1]$ itself.

It remains to be shown that $b\in J$ 
with $\left<b,a\right>=a$ for all~$a\in J$ are absent.
Suppose such~$b$ is given towards a contradiction,
and let~$a$ be an element of~$J$
with $a(x)\neq 0$ for all~$x\neq 0$
(taking, for example, $a(x)=x$ for all~$x\in [0,1]$.)
Since $a(x)= \smash{\overline{b(x)}}\,a(x)$
for all~$x\in [0,1]$,
we not only get $b(x)=1$
for all~$x\neq 0$,
but also~$b(0)=1$ by continuity of~$b$,
which contradicts that~$b\in J$.
\end{solution}
\begin{solution}{parsec-320.90}%
We prove the statements in a different order.
Let~$x,y\in X$.
\begin{enumerate}
\setcounter{enumi}{1}
\item
\label{S32IX-2}
$\left\|\left<x,y\right>\right\|\leq \|x\|\,\|y\|$
follows from  $\left<x,y\right>\left<y,x\right>
\leq \|y\|^2\left<x,x\right>$
(Cauchy--Schwarz)
since
$\|\left<x,y\right>\|^2
=\left\|\,\left<x,y\right>\,\left<y,x\right>\,\right\|
\leq \left\|y\right\|^2\,\left\|\left<x,x\right>\right\|
\equiv \|y\|^2\|x\|^2$
(using~\sref{positive-basic-2}.)

$\left\|bx\right\|=\|b\|\|x\|$ given~$b\in B$:
because $\left<x,x\right>\leq \left\|\left<x,x\right>\right\|
\equiv \|x\|^2$,
and
thus $b^*\left<x,x\right>b \leq b^*b\,\|x\|^2$
(see~\sref{astara-pos-basic-consequences}),
we have
$\|bx\|^2
\equiv \left\|\left<bx,bx\right>\right\|
= \left\|b^*\left<x,x\right>b\right\|
\leq \left\|b^*b\right\|\,\|x\|^2
\equiv \|b\|^2\|x\|^2$.

\setcounter{enumi}{0}
\item
The map $\|\,\cdot\,\|\colon X\to [0,\infty)$
is a norm, because:
\begin{enumerate}
\item
$\|x\|=0\implies x=0$,
since~$0=\|x\|^2\equiv\|\left<x,x\right>\|$,
so~$\left<x,x\right>=0$,
and thus~$x=0$;

\item
$\left\|\lambda x\right\|=\left|\lambda\right|\|x\|$
for all~$\lambda\in \C$,
being a special case of the second
result in point~\ref{S32IX-2}; and

\item
$\left\|x+y\right\|\leq\|x\|+\|y\|$, 
because
\begin{alignat*}{3}
\left\|x+y\right\|^2 \ &=\ \left\|\left<x+y,x+y\right>\right\|\\
&\equiv\ \left\|\,
\left<x,x\right>\,+\,
\left<x,y\right>\,+\,
\left<y,x\right>\,+\,
\left<y,y\right>\,\right\| \\
&\leq\ 
\left\|\left<x,x\right>\right\| \,+\, 
\left\|\left<x,y\right>\right\| \,+\, 
\left\|\left<y,x\right>\right\| \,+\, 
\left\|\left<y,y\right>\right\|\\
&=\ 
\|x\|^2 \,+\, 2\left\|\left<x,y\right>\right\| \,+\, \|y\|^2\\
&\leq\ 
\|x\|^2 \,+\, 2\|x\|\|y\| \,+\, \|y\|^2
&&\text{by point~\ref{S32IX-2}}\\
&\leq\ 
(\|x\|+\|y\|)^2.
\end{alignat*}
\end{enumerate}
\end{enumerate}
\end{solution}
\begin{solution}{parsec-320.120}%
$\|T^*T\|\leq \|T^*\|\|T\|=\|T\|^2$,
since $\|T^*\|=\|T\|$ by~\sref{parsec-320.100},
and 
$\|T\|^2 \leq \|T^*T \|$,
because $\|Tx\|^2
=\left\|\left<Tx,Tx\right>\right\|
= \left\|\left<x,T^*Tx\right>\right\|
\leq \|x\|^2 \|T^*T\|$
by~\sref{parsec-320.50} or~\sref{parsec-320.100}.
\end{solution}
\begin{solution}{parsec-320.150}%
(There is an erratum to the printed version of this exercise.)
\begin{enumerate}
\setcounter{enumi}{-1}
\item
Before we get to the claims
made in the exercise,
we'll show that the \emph{vector substates} of~$X$,
maps $\left<x,(\,\cdot\,)x\right>
\colon \scrB^a(X)\to \scrA$ with~$x\in (X)_{\leq 1}
\equiv
\{x\in X\colon \|x\|\leq 1\}$
are (just) separating,
that is,
given~$T\in \scrB^a(X)$ 
we will show that $T=0$ iff $\left<x,Tx\right>=0$
for all~$x\in (X)_{\leq 1}$.

Certainly, if~$T=0$, then~$\left<x,Tx\right>=0$ for all~$x\in (X)_{\leq 1}$.

For the other direction,
assume that~$\left<x,Tx\right>=0$ for all~$x\in (X)_{\leq 1}$
(and so by scaling for all $x\in X$ too.)
Then by polarization (c.f.~\sref{parsec-40.90})
we get
$\left<x,Ty\right>
= \frac{1}{4}\sum_{n=0}^3 i^n \left<i^nx+y,T(i^nx+y)\right>=0$
for all~$x,y\in X$.
In particular, 
$\left<Tx,Tx\right>=0$, so~$Tx=0$ for all~$x\in X$.
Thus~$T=0$.

\item
Let~$T\in\scrB^a(X)$ be given.
We must show that $T$ is self-adjoint
iff $\left<x,Tx\right>$ is self-adoint for all
$x\in (X)_{\leq 1}$.

Certainly, when~$T$ is self-adjoint,
we have $\left<x,Tx\right>^*
= \left<Tx,x\right>=\left<x,Tx\right>$.

Conversely, if~$\left<x,Tx\right>$ is self-adjoint for all
$x\in (X)_{\leq 1}$,
then $\left<x,Tx\right>
={\left<x,Tx\right>}^*
=\left<Tx,x\right>
=\left<x,T^*x\right>$,
so~$\left<x,(T-T^*)x\right>=0$
for all~$x\in (X)_{\leq 1}$,
which implies that~$T=T^*$,
because the vector substates are separating.

\item
We must show that the vector substates are order
separating.

Let~$T\in \scrB^a(X)$ be given.
It's clear that $T\geq 0$ 
implies that
$\left<x,Tx\right>\equiv \left<\smash{T^{\frac{1}{2}}x,
T^{\frac{1}{2}}x}\right> \geq 0$
for all~$x\in X$, and thus all $x\in (X)_{\leq 1}$ too.

For the converse,
suppose that~$\left<x,Tx\right>\geq 0$
for all~$x\in (X)_{\leq 1}$;
we must show that~$T\geq 0$.
Certainly, $T$ is self-adjoint,
because the $\left<x,Tx\right>\geq 0$ are self-adjoint.
Writing $T=T_+-T_-$
for positive $T_+$ and~$T_-$
with $T_+T_-=0$
(see~\sref{parsec-240.20}),
we need only show that~$T_-=0$.
Note that
 $TT_- = -T_-^2$,
and so
$0\leq\left<T_-x,T(T_-x)\right>
=-\left<x,T_-^3x\right>\leq 0$
for all~$x\in X$
using here that~$-T_-^3\leq 0$.
Whence $\left<x,T_-^3 x\right>=0$
for all~$x\in (X)_{\leq 1}$, 
so~$T_-^3=0$ (since the vector substates are separating,)
and thus~$T_-=0$.
\item
Let~$T\in\sa{\scrB^a(X)}$ be given;
we must show that $\|T\|=\sup_{x\in (X)_{\leq 1}} \|\left<x,Tx\right>\|$.
We cannot simply  apply~\sref{parsec-210.70},
because the  maps  $\left<x,(\,\cdot\,)x\right>$ 
not all unital.

Given~$x\in X$,
we have
$\|\left<x,Tx\right>\|\leq \|x\|\,\|Tx\|
\leq \|x\|^2\|T\| $,
and
whence $\sup_{x\in (X)_{\leq 1} } \|\left<x,Tx\right>\| \leq \|T\|$.

For the other direction,
note first that by scaling down~$T$ if necessary
we may assume without loss of generality that~$\|T\|\leq 1$.
Also 
recall that~$\|T\|=\|T_+\|\vee \|T_-\|$
(from the addendum to)
\sref{parsec-240.20},
so we must show that
$\|T_\pm\| \leq 
\sup_{x\in (X)_{\leq 1} } \|\left<x,Tx\right>\|$,
where~$\pm$ can be either~$+$ or~$-$.

By considering only $x$'s of the form
$T^\varepsilon_\pm y$ where~$y\in (X)_{\leq 1}$,
and~$\varepsilon>0$ a dyadic rational
we see that it suffices to show that
\begin{equation}
\label{S32XV3}
\textstyle \|T_\pm\| 
\ \leq\  \sup_{\varepsilon>0} \sup_{y\in (X)_{\leq 1}}
\|\left<T_\pm^\varepsilon y,T\,T_\pm^\varepsilon y\right>\|,
\end{equation}
using here that $\|T_\pm^\varepsilon y \|\leq 1$,
because $\|T_\pm\|\leq 1$ and~$\|y\|\leq 1$.

We claim that $T T_{\pm}^\varepsilon = \pm T_\pm T_{\pm}^\varepsilon$,
and for this
(since~$T=T_+-T_-$,)
it suffices to show that $T_\mp T_{\pm}^\varepsilon = 0$.
Surely, $T_\mp T_\pm = 0$ (since~$T_+T_-=0$.)
To get the equality for the other dyadic rationals $\varepsilon>0$
simply note that  $ab=0 \implies a\sqrt{b} = 0$
for all self-adjoint~$a$ and positive~$b$
from a $C^*$-algebra~$\scrA$,
because $\|a\sqrt{b}\|^2=\|aba\|=0$ when~$ab=0$.

Whence $
\left<T_\pm^\varepsilon y,
T T_\pm^\varepsilon y \right>
= \pm 
\left<T_\pm^\varepsilon y,
T_\pm T_\pm^\varepsilon y \right>
=
\pm
\left<\sqrt{T_\pm} T_\pm^\varepsilon y,
\sqrt{T_\pm} T_\pm^\varepsilon y \right>$,
and
$$
\sup_{y\in (X)_{\leq 1}}
\|\left<T_\pm^\varepsilon y,T\,T_\pm^\varepsilon y\right>\|
=\ 
\|\sqrt{T_\pm} T_\pm^\varepsilon\|^2
\ = \| T_\pm T_\pm^{2\varepsilon}\|
\ = \ \|T_\pm\|\, \|T_\pm\|^{2\varepsilon}.
$$
Upon taking the supremum over all dyadic $\varepsilon >0$,
we see that~\eqref{S32XV3}
holds (and is in fact an equality.)
\end{enumerate}
\end{solution}
\begin{solution}{parsec-330.10}%
\begin{enumerate}
\item
Let $A$ be an $M\times N$-matrix (see erratum).

Matrix multiplication by~$A$,
which we denote by $\underline{A}\colon \scrA^N\to\scrA^M$,
sends a vector~$v\in \scrA^N$
to $(\sum_{n=1}^N A_{mn}v_n)_{m=1}^M$,
and
can thus be expressed as the combination
$\underline{A}= \sum_{m=1}^M  \sum_{n=1}^N  \kappa_m \underline{A_{mn}} \pi_n $
of adjointable bounded module maps, 
where $\pi_n\colon \scrA^N\to \scrA$ is the $n$-th projection,
$\underline{A_{mn}}\colon \scrA\to\scrA$ sends~$a$ to $A_{mn} a$,
and $\kappa_m\in \scrA\to \scrA^M$ is the $m$-th coprojection,
making~$\underline{A}$ itself an adjointable bounded
module map, with adjoint
$\underline{A}^* 
= \sum_{m=1}^M \sum_{n=1}^N
\pi_n^* (\underline{A_{mn}})^* \kappa_m^*
= \sum_{m=1}^M \sum_{n=1}^N
\kappa_n \underline{A_{mn}^*} \pi_m
= \underline{A^*}$.

\item
The assignment $A\mapsto \underline{A}$ is clearly linear.

To see that~$A\mapsto \underline{A}$ is injective,
we must show that an  $M\times N$-matrix (see erratum) is zero
when $\underline{A}=0$.
This is easy enough: simply apply~$\overline{A}$
to the vector $e_n$ that is~$1$
in the $n$-th coordinate and~$0$ elsewhere,
to see that $0 = \underline{A}(e_n) = (A_{mn})_{m=1}^M$,
so~$A_{mn} = 0$ for all~$m$ (and~$n$), so indeed~$A=0$.

To establish surjectivety, let~$T\colon \scrA^N\to\scrA^M$ be a module map.
Then
with the~$e_n$s as defined above, we have $v=\sum_{n=1}^N e_n v_n$
for every vector $v\in \scrA^N$, and so
$\smash{Tv = \sum_{n=1}^N Te_nv_n
= ( \sum_{n=1}^N (Te_n)_m v_n )_{m=1}^M = \underline{A}(v)}$,
where $A$ is the $M\times N$ matrix
given by~$A_{mn} = (Te_n)_m $.

\item
Given~$v\in \scrA^K$,
we have 
\begin{alignat*}{3}
(\underline{A}\circ \underline{B})(v) 
&=\  \sum_{k=1}^K \underline{A}(B_{mk} v_k)_{m=1}^M \\
&=\  \sum_{k=1}^K\sum_{m=1}^M (A_{nm} B_{mk} v_k)_{n=1}^N \\
&=\ \bigl(\sum_{k=1}^K \bigl(\sum_{m=1}^M A_{nm} B_{mk}  \bigr)v_k\bigr)_{n=1}^N \ = \ \underline{AB}(v).
\end{alignat*}

\item
We already know
from~\sref{parsec-320.130}
that
$\scrB^a(\scrA^N)$
is a $C^*$-algebra
with composition as multiplication
and the adjoint as involution.
Since these operations are carried over to
matrix multiplication and the conjugate transpose, respectively,
under the inverse of $A\mapsto \underline{A}\colon 
M_N\scrA\longrightarrow \scrB^a(\scrA^N)$,
we see that~$M_N\scrA$ is a $C^*$-algebra
under those operations,
with as norm the operator norm.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-330.20}%
\begin{enumerate}
\item
\label{S33II1}
As a result of~\sref{parsec-320.150}
and~\sref{parsec-330.10}
the `vector' functionals on $M_N\scrA$,
i.e.~those of the form $A\mapsto a^* A a \colon M_N\scrA\to \scrA$
with~$a\in \scrA^N$,
are order separating.
(In fact, we get
that the subset of functionals with $a^*a\leq 1$ is already
order separating, but that is not needed here.)

Whence a matrix~$A\in M_N\scrA$ is positive
iff $0\leq a^* A a\equiv \sum_{i,j} a_i^* A_{ij} a_j$
for all~$a\in \scrA^N$
(by definition of order separating.)

\item
\label{S33II2}
The matrix $(\left<x_i,x_j\right>)_{i,j}$ is positive
by point~\sref{S33II1},
because $\sum_{i,j} a_i^* \left<x_i,x_j\right>a_j
=  \left<\,\smash{\sum_ix_i a_i,\,\sum_jx_j a_j\,}\right>\geq 0$
for all $a_1,\dotsc,a_N\in\scrA$.

\item
This follows immediately from point~\ref{S33II2}
by taking for~$X$ the pre-Hilbert $\scrA$-module~$\scrA$
(which has inner product $\left<a,b\right>=a^*b$.)
\end{enumerate}
\end{solution}
\begin{solution}{parsec-330.30}%
\begin{enumerate}
\item 
Since  $M_Nf = \sum_{i,j} \kappa_{ij}\circ f\circ \pi_{ij}$,
where  $\pi_{ij}\colon M_N\scrA\to \scrA$, 
$\kappa_{ij}\colon \scrB\to M_N\scrB$
are the $(i,j)$-th projection and coprojection, respectively,
which are clearly linear maps,
we see 
that $M_Nf$ is linear.
\item
When~$f$ is unital, $M_Nf$ clearly sends the identity matrix 
on~$M_N\scrA$ to the identity matrix on~$M_N\scrB$,
and is therefore unital.

Suppose that~$f$ is multiplicative,
and let~$A,B\in M_N\scrA$ be given.
Then since $(AB)_{ij} = \sum_k A_{ik} B_{kj}$
we have $((M_Nf)(AB))_{ij}
= f((AB)_{ij})
= \sum_k f(A_{ik})\,f(B_{kj})
= (\,(M_Nf)(A)\,(M_Nf)(B)\,)_{ij}$ for all~$i,j$,
and so~$M_Nf$ is multiplicative.

Suppose finally that~$f$ is involution preserving,
and let~$A\in M_N\scrA$ be given.
Then since $(A^*)_{ij}=A_{ji}^*$,
we have
$((M_Nf)(A^*))_{ij}
= f((A^*)_{ij})
= f(A_{ji})^*
= (\,(\,(M_Nf)(A)\,)^*\,)_{ij}$
for all~$i,j$,
so~$M_N f$ is involution preserving.
\item
Concerning the point mentioned in the erratum,
that~$M_Nf$ \emph{is}
bounded by~$N^2\|f\|$,
simply note that 
the norm of a matrix over a $C^*$-algebra
containing only one non-zero entry~$a$
is $\leq \|a\|$,
and any matrix is a sum of~$N^2$ of those.

Let~$\scrA$ be a $C^*$-algebra,
and let~$\op{\scrA}$ be the opposite of~$\scrA$,
that is, $\scrA$ in all respects, except the multiplication
on~$\op{\scrA}$ is given by 
$a\cdot_{\op{\scrA}} b = b\cdot_\scrA a$.

We claim that for the positive unital
linear map~$j_\scrA \colon a\mapsto a,\, \op{\scrA}\to\scrA$
the map $M_2 j_\scrA$ is
 positive iff~$\scrA$ is commutative.

Suppose that~$M_2 j_\scrA$ is positive.
We must show that~$\scrA$ is commutative.
Clearly, it suffices to show that all self-adjoint
elements $a,b\in \scrA$ commute,
and for this it suffices to show that all elements of~$\scrA$ 
are normal,
since, as you'll recall from~\sref{parsec-280.20},
self-adjoint elements~$a$ and~$b$ of~$\scrA$ commute
iff $c:=a+ib$ is normal,
that is, $c^*c=cc^*$.

Now, given~$a\in\scrA$
consider
the 
by~\sref{parsec-330.20} positive
matrix $(\begin{smallmatrix}1 & a \\ a^* & a^*a \end{smallmatrix})$
over~$\op{\scrA}$
which is sent by $M_2j_{\scrA}$,
writing $j:=j_{\scrA}$,
to the matrix  
$$
A\ :=\ 
\bigl(\begin{smallmatrix}j(1) & j(a) \\ j(a^*) & j(a^*a)\end{smallmatrix}\bigr)
\ =\
\bigl(\begin{smallmatrix}1 & j(a) \\ j(a)^* & j(a)j(a)^*\end{smallmatrix}\bigr)
\ =\
\bigl(\begin{smallmatrix}1 & a \\ a^* & aa^*\end{smallmatrix}\bigr)
$$
over~$\scrA$,
which is positive, because~$j_{\scrA}$ is completely positive.

Being positive, 
$A$ yields an $\scrA$-valued inner product
on~$\scrA^2$ given by
$$
\left<v,w\right>\ = \ v^* A w\ = \ 
v_1^* w_1 \,+\,
v_1^*a w_2 \,+\,
v_2^*a^*w_1 \,+\,
v_2^* aa^* w_2
$$
for all~$v,w\in \scrA^2$.
The Cauchy--Schwarz inequality~\sref{parsec-320.60}
now gives us 
$$
a^*\, a \,\equiv\, 
\left<(0,1),(1,0)\right>\,
\left<(1,0),(0,1)\right>\ \leq\, 
\|\left<(1,0),(1,0)\right>\|
\,\left<(0,1),(0,1)\right>
\,\equiv\, aa^*
$$
Since~$a\in \scrA$ was arbitrary,
we not only have $a^*a\leq aa^*$,
but also $aa^* = (a^*)^* a^* \leq a^* (a^*)^*=a^*a$,
and whence~$a^*a=aa^*$.

The converse,
that~$M_2j_\scrA$ is positive when~$\scrA$
is commutative, is obvious,
as then~$\scrA=\op{\scrA}$,
making $j_\scrA$ just the identity on~$\scrA$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-340.40}%
By definition (see~\sref{parsec-100.20})
the map $f\colon \scrA\to\scrB$
is completely positive iff point~2 of~\sref{parsec-340.20} holds
for all~$N$,
which is equivalent to~$M_Nf$ being positive for all~$N$
(point~1),
and equivalent to~$(f(a_i^* a_j))_{ij}$ being positive
in~$M_N\scrB$
for all~$a\in \scrA^N$ and~$N$ (point~3).

The composition of completely positive maps
$f\colon \scrA\to\scrB$
and~$g\colon \scrB\to\scrC$
between $C^*$-algebras
is completely positive,
because $M_N(g\circ f)=M_Ng\circ M_Nf$
being the composition of positive maps $M_Ng$
and~$M_Nf$ is positive.

Let~$f\colon \scrA\to\scrB$
be an mi-map;
we must show that~$f$ is completely positive.
By~\sref{parsec-330.30}(2)
we know that~$M_Nf$ is a mi-map,
and thus positive (by~\sref{parsec-250.20}(2).)
Whence~$f$ is completely positive.
\end{solution}
\begin{solution}{parsec-340.50}%
\begin{enumerate}
\item
$a^*(\,\cdot\,)a\colon \scrA\to\scrA$
is completely positive,
because $$\textstyle \sum_{i,j} b_i^* a^* a_i^* a_j a b_j
\,=\, \sum_{i,j} (a_iab_i)^*a_j a b_j
\,=\, (\sum_i a_iab_i)^*(\sum_j a_jab_j)\geq 0$$
for all $a_1,\dotsc,a_N,b_1,\dotsc,b_N\in \scrA$.
\item
$S^*(\,\cdot\,)S\colon \scrB^a(X)\to\scrB^a(Y)$
is completely positive,
because
\begin{alignat*}{3}
\textstyle
\sum_{i,j} B_i^* S^*(A_i^* A_j) S B_j
\,&\textstyle{}=\, \sum_{i,j} (A_i S B_i)^* (A_j S B_j)\\
\textstyle
\,&\textstyle{}=\, (\sum_i A_i S B_i)^* (\sum_j A_j S B_j)\geq 0
\end{alignat*}
for all $A_1,\dotsc,A_N\in \scrB^a(X)$
and $B_1,\dotsc,B_N\in \scrB^a(Y)$.
\item
$\left<x,(\,\cdot\,)x\right>\colon \scrB^a(X)\to\scrA$
is completely positive,
because
$$
\textstyle{}\sum_{i,j} b_i^*\left<x,A_i^* A_j x\right>b_j
=\sum_{i,j} b_i^*\left<A_i x , A_j x\right> b_j
= \left<\smash{\sum_i A_i x b_i,\sum_j A_j x b_j}\right> \geq 0$$
for all $A_1,\dotsc,A_N \in \scrB^a(X)$
and~$b_1,\dotsc, b_N\in \scrA$.
\end{enumerate}
\end{solution}
\begin{solution}{parsec-340.60}%
\TODO{}
\end{solution}
\end{document}
